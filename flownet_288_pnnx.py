import os
import numpy as np
import tempfile, zipfile
import torch
import torch.nn as nn
import torch.nn.functional as F
try:
    import torchvision
except:
    pass

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()

        self.backbone_conv1 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=3, kernel_size=(7,7), out_channels=64, padding=(3,3), padding_mode='zeros', stride=(2,2))
        self.backbone_norm1 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.backbone_relu1 = nn.ReLU()
        self.backbone_layer1_0_conv1 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer1_0_norm1 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.backbone_layer1_0_relu = nn.ReLU()
        self.backbone_layer1_0_conv2 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer1_0_norm2 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_0 = nn.ReLU()
        self.pnnx_unique_1 = nn.ReLU()
        self.backbone_layer1_1_conv1 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer1_1_norm1 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.backbone_layer1_1_relu = nn.ReLU()
        self.backbone_layer1_1_conv2 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer1_1_norm2 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_2 = nn.ReLU()
        self.pnnx_unique_3 = nn.ReLU()
        self.backbone_layer2_0_conv1 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=96, padding=(1,1), padding_mode='zeros', stride=(2,2))
        self.backbone_layer2_0_norm1 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.backbone_layer2_0_relu = nn.ReLU()
        self.backbone_layer2_0_conv2 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=96, kernel_size=(3,3), out_channels=96, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer2_0_norm2 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_4 = nn.ReLU()
        self.backbone_layer2_0_downsample_0 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=96, padding=(0,0), padding_mode='zeros', stride=(2,2))
        self.backbone_layer2_0_downsample_1 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_5 = nn.ReLU()
        self.backbone_layer2_1_conv1 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=96, kernel_size=(3,3), out_channels=96, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer2_1_norm1 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.backbone_layer2_1_relu = nn.ReLU()
        self.backbone_layer2_1_conv2 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=96, kernel_size=(3,3), out_channels=96, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer2_1_norm2 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_6 = nn.ReLU()
        self.pnnx_unique_7 = nn.ReLU()
        self.backbone_layer3_0_conv1 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=96, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer3_0_norm1 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.backbone_layer3_0_relu = nn.ReLU()
        self.backbone_layer3_0_conv2 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer3_0_norm2 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_8 = nn.ReLU()
        self.backbone_layer3_0_downsample_0 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=96, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.backbone_layer3_0_downsample_1 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_9 = nn.ReLU()
        self.backbone_layer3_1_conv1 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer3_1_norm1 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.backbone_layer3_1_relu = nn.ReLU()
        self.backbone_layer3_1_conv2 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.backbone_layer3_1_norm2 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_10 = nn.ReLU()
        self.pnnx_unique_11 = nn.ReLU()
        self.backbone_conv2 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_12 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=3, kernel_size=(7,7), out_channels=64, padding=(3,3), padding_mode='zeros', stride=(2,2))
        self.pnnx_unique_13 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_14 = nn.ReLU()
        self.pnnx_unique_15 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_16 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_17 = nn.ReLU()
        self.pnnx_unique_18 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_19 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_20 = nn.ReLU()
        self.pnnx_unique_21 = nn.ReLU()
        self.pnnx_unique_22 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_23 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_24 = nn.ReLU()
        self.pnnx_unique_25 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=64, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_26 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_27 = nn.ReLU()
        self.pnnx_unique_28 = nn.ReLU()
        self.pnnx_unique_29 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=64, kernel_size=(3,3), out_channels=96, padding=(1,1), padding_mode='zeros', stride=(2,2))
        self.pnnx_unique_30 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_31 = nn.ReLU()
        self.pnnx_unique_32 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=96, kernel_size=(3,3), out_channels=96, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_33 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_34 = nn.ReLU()
        self.pnnx_unique_35 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=64, kernel_size=(1,1), out_channels=96, padding=(0,0), padding_mode='zeros', stride=(2,2))
        self.pnnx_unique_36 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_37 = nn.ReLU()
        self.pnnx_unique_38 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=96, kernel_size=(3,3), out_channels=96, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_39 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_40 = nn.ReLU()
        self.pnnx_unique_41 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=96, kernel_size=(3,3), out_channels=96, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_42 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_43 = nn.ReLU()
        self.pnnx_unique_44 = nn.ReLU()
        self.pnnx_unique_45 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=96, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_46 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_47 = nn.ReLU()
        self.pnnx_unique_48 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_49 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_50 = nn.ReLU()
        self.pnnx_unique_51 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=96, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_52 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_53 = nn.ReLU()
        self.pnnx_unique_54 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_55 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_56 = nn.ReLU()
        self.pnnx_unique_57 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_58 = nn.InstanceNorm2d(affine=False, eps=0.000010, track_running_stats=False)
        self.pnnx_unique_59 = nn.ReLU()
        self.pnnx_unique_60 = nn.ReLU()
        self.pnnx_unique_61 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=128, kernel_size=(1,1), out_channels=128, padding=(0,0), padding_mode='zeros', stride=(1,1))
        self.conv2d_0 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(2,2))
        self.conv2d_2 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(2,2))
        self.transformer_layers_0_self_attn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_0_self_attn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_0_self_attn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_0_self_attn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_0_self_attn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_0_cross_attn_ffn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_0_cross_attn_ffn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_0_cross_attn_ffn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_0_cross_attn_ffn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_0_cross_attn_ffn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_0_cross_attn_ffn_mlp_0 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.transformer_layers_0_cross_attn_ffn_mlp_1 = nn.GELU()
        self.transformer_layers_0_cross_attn_ffn_mlp_2 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.transformer_layers_0_cross_attn_ffn_norm2 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_74 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_75 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_76 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_81 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_82 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_83 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_84 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_85 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_90 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_91 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_92 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_93 = nn.GELU()
        self.pnnx_unique_94 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_95 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_1_self_attn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_1_self_attn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_1_self_attn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_1_self_attn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_1_self_attn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_1_cross_attn_ffn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_1_cross_attn_ffn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_1_cross_attn_ffn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_1_cross_attn_ffn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_1_cross_attn_ffn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_1_cross_attn_ffn_mlp_0 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.transformer_layers_1_cross_attn_ffn_mlp_1 = nn.GELU()
        self.transformer_layers_1_cross_attn_ffn_mlp_2 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.transformer_layers_1_cross_attn_ffn_norm2 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_104 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_105 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_106 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_111 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_112 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_113 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_114 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_115 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_120 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_121 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_122 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_123 = nn.GELU()
        self.pnnx_unique_124 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_125 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_2_self_attn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_2_self_attn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_2_self_attn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_2_self_attn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_2_self_attn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_2_cross_attn_ffn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_2_cross_attn_ffn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_2_cross_attn_ffn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_2_cross_attn_ffn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_2_cross_attn_ffn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_2_cross_attn_ffn_mlp_0 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.transformer_layers_2_cross_attn_ffn_mlp_1 = nn.GELU()
        self.transformer_layers_2_cross_attn_ffn_mlp_2 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.transformer_layers_2_cross_attn_ffn_norm2 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_134 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_135 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_136 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_141 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_142 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_143 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_144 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_145 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_150 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_151 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_152 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_153 = nn.GELU()
        self.pnnx_unique_154 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_155 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_3_self_attn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_3_self_attn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_3_self_attn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_3_self_attn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_3_self_attn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_3_cross_attn_ffn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_3_cross_attn_ffn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_3_cross_attn_ffn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_3_cross_attn_ffn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_3_cross_attn_ffn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_3_cross_attn_ffn_mlp_0 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.transformer_layers_3_cross_attn_ffn_mlp_1 = nn.GELU()
        self.transformer_layers_3_cross_attn_ffn_mlp_2 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.transformer_layers_3_cross_attn_ffn_norm2 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_164 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_165 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_166 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_171 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_172 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_173 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_174 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_175 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_180 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_181 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_182 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_183 = nn.GELU()
        self.pnnx_unique_184 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_185 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_4_self_attn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_4_self_attn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_4_self_attn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_4_self_attn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_4_self_attn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_4_cross_attn_ffn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_4_cross_attn_ffn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_4_cross_attn_ffn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_4_cross_attn_ffn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_4_cross_attn_ffn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_4_cross_attn_ffn_mlp_0 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.transformer_layers_4_cross_attn_ffn_mlp_1 = nn.GELU()
        self.transformer_layers_4_cross_attn_ffn_mlp_2 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.transformer_layers_4_cross_attn_ffn_norm2 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_194 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_195 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_196 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_201 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_202 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_203 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_204 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_205 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_210 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_211 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_212 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_213 = nn.GELU()
        self.pnnx_unique_214 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_215 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_5_self_attn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_5_self_attn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_5_self_attn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_5_self_attn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_5_self_attn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_5_cross_attn_ffn_q_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_5_cross_attn_ffn_k_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_5_cross_attn_ffn_v_proj = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_5_cross_attn_ffn_merge = nn.Linear(bias=False, in_features=128, out_features=128)
        self.transformer_layers_5_cross_attn_ffn_norm1 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.transformer_layers_5_cross_attn_ffn_mlp_0 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.transformer_layers_5_cross_attn_ffn_mlp_1 = nn.GELU()
        self.transformer_layers_5_cross_attn_ffn_mlp_2 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.transformer_layers_5_cross_attn_ffn_norm2 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_224 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_225 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_226 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_231 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_232 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_233 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_234 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_235 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_240 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_241 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_242 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_243 = nn.GELU()
        self.pnnx_unique_244 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_245 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.feature_flow_attn_q_proj = nn.Linear(bias=True, in_features=128, out_features=128)
        self.feature_flow_attn_k_proj = nn.Linear(bias=True, in_features=128, out_features=128)
        self.conv2d_1 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.conv2d_3 = nn.Conv2d(bias=False, dilation=(1,1), groups=1, in_channels=128, kernel_size=(3,3), out_channels=128, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.pnnx_unique_251 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_252 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_253 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_258 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_259 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_260 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_261 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_262 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_267 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_268 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_269 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_270 = nn.GELU()
        self.pnnx_unique_271 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_272 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_273 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_274 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_275 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_280 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_281 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_282 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_283 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_284 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_289 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_290 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_291 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_292 = nn.GELU()
        self.pnnx_unique_293 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_294 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_295 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_296 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_297 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_302 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_303 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_304 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_305 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_306 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_311 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_312 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_313 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_314 = nn.GELU()
        self.pnnx_unique_315 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_316 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_317 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_318 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_319 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_324 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_325 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_326 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_327 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_328 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_333 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_334 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_335 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_336 = nn.GELU()
        self.pnnx_unique_337 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_338 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_339 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_340 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_341 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_346 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_347 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_348 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_349 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_350 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_355 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_356 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_357 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_358 = nn.GELU()
        self.pnnx_unique_359 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_360 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_361 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_362 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_363 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_368 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_369 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_370 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_371 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_372 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_377 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_378 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_379 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_380 = nn.GELU()
        self.pnnx_unique_381 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_382 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_383 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_384 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_385 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_390 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_391 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_392 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_393 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_394 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_399 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_400 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_401 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_402 = nn.GELU()
        self.pnnx_unique_403 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_404 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_405 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_406 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_407 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_412 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_413 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_414 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_415 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_416 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_421 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_422 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_423 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_424 = nn.GELU()
        self.pnnx_unique_425 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_426 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_427 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_428 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_429 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_434 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_435 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_436 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_437 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_438 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_443 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_444 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_445 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_446 = nn.GELU()
        self.pnnx_unique_447 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_448 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_449 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_450 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_451 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_456 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_457 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_458 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_459 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_460 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_465 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_466 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_467 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_468 = nn.GELU()
        self.pnnx_unique_469 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_470 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_471 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_472 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_473 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_478 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_479 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_480 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_481 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_482 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_487 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_488 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_489 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_490 = nn.GELU()
        self.pnnx_unique_491 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_492 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_493 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_494 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_495 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_500 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_501 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_502 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_503 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_504 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_509 = nn.Linear(bias=False, in_features=128, out_features=128)
        self.pnnx_unique_510 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_511 = nn.Linear(bias=False, in_features=256, out_features=1024)
        self.pnnx_unique_512 = nn.GELU()
        self.pnnx_unique_513 = nn.Linear(bias=False, in_features=1024, out_features=128)
        self.pnnx_unique_514 = nn.LayerNorm(elementwise_affine=True, eps=0.000010, normalized_shape=(128,))
        self.pnnx_unique_515 = nn.Linear(bias=True, in_features=128, out_features=128)
        self.pnnx_unique_516 = nn.Linear(bias=True, in_features=128, out_features=128)
        self.upsampler_0 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=130, kernel_size=(3,3), out_channels=256, padding=(1,1), padding_mode='zeros', stride=(1,1))
        self.upsampler_1 = nn.ReLU()
        self.upsampler_2 = nn.Conv2d(bias=True, dilation=(1,1), groups=1, in_channels=256, kernel_size=(1,1), out_channels=144, padding=(0,0), padding_mode='zeros', stride=(1,1))

        archive = zipfile.ZipFile('D:/60-fps-Project/VFI/GMFSS2NCNN/flownet_288.pnnx.bin', 'r')
        self.backbone_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.conv1.weight', (64,3,7,7), 'float32')
        self.backbone_layer1_0_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer1.0.conv1.weight', (64,64,3,3), 'float32')
        self.backbone_layer1_0_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer1.0.conv2.weight', (64,64,3,3), 'float32')
        self.backbone_layer1_1_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer1.1.conv1.weight', (64,64,3,3), 'float32')
        self.backbone_layer1_1_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer1.1.conv2.weight', (64,64,3,3), 'float32')
        self.backbone_layer2_0_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer2.0.conv1.weight', (96,64,3,3), 'float32')
        self.backbone_layer2_0_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer2.0.conv2.weight', (96,96,3,3), 'float32')
        self.backbone_layer2_0_downsample_0.bias = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer2.0.downsample.0.bias', (96), 'float32')
        self.backbone_layer2_0_downsample_0.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer2.0.downsample.0.weight', (96,64,1,1), 'float32')
        self.backbone_layer2_1_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer2.1.conv1.weight', (96,96,3,3), 'float32')
        self.backbone_layer2_1_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer2.1.conv2.weight', (96,96,3,3), 'float32')
        self.backbone_layer3_0_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer3.0.conv1.weight', (128,96,3,3), 'float32')
        self.backbone_layer3_0_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer3.0.conv2.weight', (128,128,3,3), 'float32')
        self.backbone_layer3_0_downsample_0.bias = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer3.0.downsample.0.bias', (128), 'float32')
        self.backbone_layer3_0_downsample_0.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer3.0.downsample.0.weight', (128,96,1,1), 'float32')
        self.backbone_layer3_1_conv1.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer3.1.conv1.weight', (128,128,3,3), 'float32')
        self.backbone_layer3_1_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.layer3.1.conv2.weight', (128,128,3,3), 'float32')
        self.backbone_conv2.bias = self.load_pnnx_bin_as_parameter(archive, 'backbone.conv2.bias', (128), 'float32')
        self.backbone_conv2.weight = self.load_pnnx_bin_as_parameter(archive, 'backbone.conv2.weight', (128,128,1,1), 'float32')
        self.pnnx_unique_12.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_12.weight', (64,3,7,7), 'float32')
        self.pnnx_unique_15.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_15.weight', (64,64,3,3), 'float32')
        self.pnnx_unique_18.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_18.weight', (64,64,3,3), 'float32')
        self.pnnx_unique_22.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_22.weight', (64,64,3,3), 'float32')
        self.pnnx_unique_25.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_25.weight', (64,64,3,3), 'float32')
        self.pnnx_unique_29.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_29.weight', (96,64,3,3), 'float32')
        self.pnnx_unique_32.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_32.weight', (96,96,3,3), 'float32')
        self.pnnx_unique_35.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_35.bias', (96), 'float32')
        self.pnnx_unique_35.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_35.weight', (96,64,1,1), 'float32')
        self.pnnx_unique_38.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_38.weight', (96,96,3,3), 'float32')
        self.pnnx_unique_41.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_41.weight', (96,96,3,3), 'float32')
        self.pnnx_unique_45.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_45.weight', (128,96,3,3), 'float32')
        self.pnnx_unique_48.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_48.weight', (128,128,3,3), 'float32')
        self.pnnx_unique_51.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_51.bias', (128), 'float32')
        self.pnnx_unique_51.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_51.weight', (128,96,1,1), 'float32')
        self.pnnx_unique_54.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_54.weight', (128,128,3,3), 'float32')
        self.pnnx_unique_57.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_57.weight', (128,128,3,3), 'float32')
        self.pnnx_unique_61.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_61.bias', (128), 'float32')
        self.pnnx_unique_61.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_61.weight', (128,128,1,1), 'float32')
        self.conv2d_0.weight = self.load_pnnx_bin_as_parameter(archive, 'conv2d_0.weight', (128,128,3,3), 'float32')
        self.conv2d_2.weight = self.load_pnnx_bin_as_parameter(archive, 'conv2d_2.weight', (128,128,3,3), 'float32')
        self.transformer_layers_0_self_attn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.self_attn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_0_self_attn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.self_attn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_0_self_attn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.self_attn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_0_self_attn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.self_attn.merge.weight', (128,128), 'float32')
        self.transformer_layers_0_self_attn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.self_attn.norm1.bias', (128), 'float32')
        self.transformer_layers_0_self_attn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.self_attn.norm1.weight', (128), 'float32')
        self.transformer_layers_0_cross_attn_ffn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.cross_attn_ffn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_0_cross_attn_ffn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.cross_attn_ffn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_0_cross_attn_ffn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.cross_attn_ffn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_0_cross_attn_ffn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.cross_attn_ffn.merge.weight', (128,128), 'float32')
        self.transformer_layers_0_cross_attn_ffn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.cross_attn_ffn.norm1.bias', (128), 'float32')
        self.transformer_layers_0_cross_attn_ffn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.cross_attn_ffn.norm1.weight', (128), 'float32')
        self.transformer_layers_0_cross_attn_ffn_mlp_0.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.cross_attn_ffn.mlp.0.weight', (1024,256), 'float32')
        self.transformer_layers_0_cross_attn_ffn_mlp_2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.cross_attn_ffn.mlp.2.weight', (128,1024), 'float32')
        self.transformer_layers_0_cross_attn_ffn_norm2.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.cross_attn_ffn.norm2.bias', (128), 'float32')
        self.transformer_layers_0_cross_attn_ffn_norm2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.0.cross_attn_ffn.norm2.weight', (128), 'float32')
        self.pnnx_unique_74.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_74.weight', (128,128), 'float32')
        self.pnnx_unique_75.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_75.weight', (128,128), 'float32')
        self.pnnx_unique_76.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_76.weight', (128,128), 'float32')
        self.pnnx_unique_81.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_81.weight', (128,128), 'float32')
        self.pnnx_unique_82.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_82.bias', (128), 'float32')
        self.pnnx_unique_82.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_82.weight', (128), 'float32')
        self.pnnx_unique_83.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_83.weight', (128,128), 'float32')
        self.pnnx_unique_84.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_84.weight', (128,128), 'float32')
        self.pnnx_unique_85.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_85.weight', (128,128), 'float32')
        self.pnnx_unique_90.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_90.weight', (128,128), 'float32')
        self.pnnx_unique_91.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_91.bias', (128), 'float32')
        self.pnnx_unique_91.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_91.weight', (128), 'float32')
        self.pnnx_unique_92.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_92.weight', (1024,256), 'float32')
        self.pnnx_unique_94.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_94.weight', (128,1024), 'float32')
        self.pnnx_unique_95.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_95.bias', (128), 'float32')
        self.pnnx_unique_95.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_95.weight', (128), 'float32')
        self.transformer_layers_1_self_attn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.self_attn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_1_self_attn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.self_attn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_1_self_attn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.self_attn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_1_self_attn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.self_attn.merge.weight', (128,128), 'float32')
        self.transformer_layers_1_self_attn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.self_attn.norm1.bias', (128), 'float32')
        self.transformer_layers_1_self_attn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.self_attn.norm1.weight', (128), 'float32')
        self.transformer_layers_1_cross_attn_ffn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.cross_attn_ffn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_1_cross_attn_ffn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.cross_attn_ffn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_1_cross_attn_ffn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.cross_attn_ffn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_1_cross_attn_ffn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.cross_attn_ffn.merge.weight', (128,128), 'float32')
        self.transformer_layers_1_cross_attn_ffn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.cross_attn_ffn.norm1.bias', (128), 'float32')
        self.transformer_layers_1_cross_attn_ffn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.cross_attn_ffn.norm1.weight', (128), 'float32')
        self.transformer_layers_1_cross_attn_ffn_mlp_0.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.cross_attn_ffn.mlp.0.weight', (1024,256), 'float32')
        self.transformer_layers_1_cross_attn_ffn_mlp_2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.cross_attn_ffn.mlp.2.weight', (128,1024), 'float32')
        self.transformer_layers_1_cross_attn_ffn_norm2.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.cross_attn_ffn.norm2.bias', (128), 'float32')
        self.transformer_layers_1_cross_attn_ffn_norm2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.1.cross_attn_ffn.norm2.weight', (128), 'float32')
        self.pnnx_unique_104.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_104.weight', (128,128), 'float32')
        self.pnnx_unique_105.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_105.weight', (128,128), 'float32')
        self.pnnx_unique_106.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_106.weight', (128,128), 'float32')
        self.pnnx_unique_111.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_111.weight', (128,128), 'float32')
        self.pnnx_unique_112.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_112.bias', (128), 'float32')
        self.pnnx_unique_112.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_112.weight', (128), 'float32')
        self.pnnx_unique_113.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_113.weight', (128,128), 'float32')
        self.pnnx_unique_114.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_114.weight', (128,128), 'float32')
        self.pnnx_unique_115.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_115.weight', (128,128), 'float32')
        self.pnnx_unique_120.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_120.weight', (128,128), 'float32')
        self.pnnx_unique_121.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_121.bias', (128), 'float32')
        self.pnnx_unique_121.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_121.weight', (128), 'float32')
        self.pnnx_unique_122.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_122.weight', (1024,256), 'float32')
        self.pnnx_unique_124.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_124.weight', (128,1024), 'float32')
        self.pnnx_unique_125.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_125.bias', (128), 'float32')
        self.pnnx_unique_125.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_125.weight', (128), 'float32')
        self.transformer_layers_2_self_attn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.self_attn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_2_self_attn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.self_attn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_2_self_attn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.self_attn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_2_self_attn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.self_attn.merge.weight', (128,128), 'float32')
        self.transformer_layers_2_self_attn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.self_attn.norm1.bias', (128), 'float32')
        self.transformer_layers_2_self_attn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.self_attn.norm1.weight', (128), 'float32')
        self.transformer_layers_2_cross_attn_ffn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.cross_attn_ffn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_2_cross_attn_ffn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.cross_attn_ffn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_2_cross_attn_ffn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.cross_attn_ffn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_2_cross_attn_ffn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.cross_attn_ffn.merge.weight', (128,128), 'float32')
        self.transformer_layers_2_cross_attn_ffn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.cross_attn_ffn.norm1.bias', (128), 'float32')
        self.transformer_layers_2_cross_attn_ffn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.cross_attn_ffn.norm1.weight', (128), 'float32')
        self.transformer_layers_2_cross_attn_ffn_mlp_0.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.cross_attn_ffn.mlp.0.weight', (1024,256), 'float32')
        self.transformer_layers_2_cross_attn_ffn_mlp_2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.cross_attn_ffn.mlp.2.weight', (128,1024), 'float32')
        self.transformer_layers_2_cross_attn_ffn_norm2.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.cross_attn_ffn.norm2.bias', (128), 'float32')
        self.transformer_layers_2_cross_attn_ffn_norm2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.2.cross_attn_ffn.norm2.weight', (128), 'float32')
        self.pnnx_unique_134.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_134.weight', (128,128), 'float32')
        self.pnnx_unique_135.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_135.weight', (128,128), 'float32')
        self.pnnx_unique_136.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_136.weight', (128,128), 'float32')
        self.pnnx_unique_141.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_141.weight', (128,128), 'float32')
        self.pnnx_unique_142.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_142.bias', (128), 'float32')
        self.pnnx_unique_142.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_142.weight', (128), 'float32')
        self.pnnx_unique_143.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_143.weight', (128,128), 'float32')
        self.pnnx_unique_144.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_144.weight', (128,128), 'float32')
        self.pnnx_unique_145.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_145.weight', (128,128), 'float32')
        self.pnnx_unique_150.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_150.weight', (128,128), 'float32')
        self.pnnx_unique_151.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_151.bias', (128), 'float32')
        self.pnnx_unique_151.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_151.weight', (128), 'float32')
        self.pnnx_unique_152.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_152.weight', (1024,256), 'float32')
        self.pnnx_unique_154.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_154.weight', (128,1024), 'float32')
        self.pnnx_unique_155.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_155.bias', (128), 'float32')
        self.pnnx_unique_155.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_155.weight', (128), 'float32')
        self.transformer_layers_3_self_attn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.self_attn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_3_self_attn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.self_attn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_3_self_attn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.self_attn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_3_self_attn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.self_attn.merge.weight', (128,128), 'float32')
        self.transformer_layers_3_self_attn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.self_attn.norm1.bias', (128), 'float32')
        self.transformer_layers_3_self_attn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.self_attn.norm1.weight', (128), 'float32')
        self.transformer_layers_3_cross_attn_ffn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.cross_attn_ffn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_3_cross_attn_ffn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.cross_attn_ffn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_3_cross_attn_ffn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.cross_attn_ffn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_3_cross_attn_ffn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.cross_attn_ffn.merge.weight', (128,128), 'float32')
        self.transformer_layers_3_cross_attn_ffn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.cross_attn_ffn.norm1.bias', (128), 'float32')
        self.transformer_layers_3_cross_attn_ffn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.cross_attn_ffn.norm1.weight', (128), 'float32')
        self.transformer_layers_3_cross_attn_ffn_mlp_0.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.cross_attn_ffn.mlp.0.weight', (1024,256), 'float32')
        self.transformer_layers_3_cross_attn_ffn_mlp_2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.cross_attn_ffn.mlp.2.weight', (128,1024), 'float32')
        self.transformer_layers_3_cross_attn_ffn_norm2.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.cross_attn_ffn.norm2.bias', (128), 'float32')
        self.transformer_layers_3_cross_attn_ffn_norm2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.3.cross_attn_ffn.norm2.weight', (128), 'float32')
        self.pnnx_unique_164.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_164.weight', (128,128), 'float32')
        self.pnnx_unique_165.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_165.weight', (128,128), 'float32')
        self.pnnx_unique_166.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_166.weight', (128,128), 'float32')
        self.pnnx_unique_171.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_171.weight', (128,128), 'float32')
        self.pnnx_unique_172.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_172.bias', (128), 'float32')
        self.pnnx_unique_172.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_172.weight', (128), 'float32')
        self.pnnx_unique_173.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_173.weight', (128,128), 'float32')
        self.pnnx_unique_174.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_174.weight', (128,128), 'float32')
        self.pnnx_unique_175.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_175.weight', (128,128), 'float32')
        self.pnnx_unique_180.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_180.weight', (128,128), 'float32')
        self.pnnx_unique_181.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_181.bias', (128), 'float32')
        self.pnnx_unique_181.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_181.weight', (128), 'float32')
        self.pnnx_unique_182.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_182.weight', (1024,256), 'float32')
        self.pnnx_unique_184.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_184.weight', (128,1024), 'float32')
        self.pnnx_unique_185.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_185.bias', (128), 'float32')
        self.pnnx_unique_185.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_185.weight', (128), 'float32')
        self.transformer_layers_4_self_attn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.self_attn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_4_self_attn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.self_attn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_4_self_attn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.self_attn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_4_self_attn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.self_attn.merge.weight', (128,128), 'float32')
        self.transformer_layers_4_self_attn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.self_attn.norm1.bias', (128), 'float32')
        self.transformer_layers_4_self_attn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.self_attn.norm1.weight', (128), 'float32')
        self.transformer_layers_4_cross_attn_ffn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.cross_attn_ffn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_4_cross_attn_ffn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.cross_attn_ffn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_4_cross_attn_ffn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.cross_attn_ffn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_4_cross_attn_ffn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.cross_attn_ffn.merge.weight', (128,128), 'float32')
        self.transformer_layers_4_cross_attn_ffn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.cross_attn_ffn.norm1.bias', (128), 'float32')
        self.transformer_layers_4_cross_attn_ffn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.cross_attn_ffn.norm1.weight', (128), 'float32')
        self.transformer_layers_4_cross_attn_ffn_mlp_0.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.cross_attn_ffn.mlp.0.weight', (1024,256), 'float32')
        self.transformer_layers_4_cross_attn_ffn_mlp_2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.cross_attn_ffn.mlp.2.weight', (128,1024), 'float32')
        self.transformer_layers_4_cross_attn_ffn_norm2.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.cross_attn_ffn.norm2.bias', (128), 'float32')
        self.transformer_layers_4_cross_attn_ffn_norm2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.4.cross_attn_ffn.norm2.weight', (128), 'float32')
        self.pnnx_unique_194.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_194.weight', (128,128), 'float32')
        self.pnnx_unique_195.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_195.weight', (128,128), 'float32')
        self.pnnx_unique_196.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_196.weight', (128,128), 'float32')
        self.pnnx_unique_201.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_201.weight', (128,128), 'float32')
        self.pnnx_unique_202.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_202.bias', (128), 'float32')
        self.pnnx_unique_202.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_202.weight', (128), 'float32')
        self.pnnx_unique_203.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_203.weight', (128,128), 'float32')
        self.pnnx_unique_204.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_204.weight', (128,128), 'float32')
        self.pnnx_unique_205.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_205.weight', (128,128), 'float32')
        self.pnnx_unique_210.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_210.weight', (128,128), 'float32')
        self.pnnx_unique_211.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_211.bias', (128), 'float32')
        self.pnnx_unique_211.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_211.weight', (128), 'float32')
        self.pnnx_unique_212.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_212.weight', (1024,256), 'float32')
        self.pnnx_unique_214.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_214.weight', (128,1024), 'float32')
        self.pnnx_unique_215.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_215.bias', (128), 'float32')
        self.pnnx_unique_215.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_215.weight', (128), 'float32')
        self.transformer_layers_5_self_attn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.self_attn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_5_self_attn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.self_attn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_5_self_attn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.self_attn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_5_self_attn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.self_attn.merge.weight', (128,128), 'float32')
        self.transformer_layers_5_self_attn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.self_attn.norm1.bias', (128), 'float32')
        self.transformer_layers_5_self_attn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.self_attn.norm1.weight', (128), 'float32')
        self.transformer_layers_5_cross_attn_ffn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.cross_attn_ffn.q_proj.weight', (128,128), 'float32')
        self.transformer_layers_5_cross_attn_ffn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.cross_attn_ffn.k_proj.weight', (128,128), 'float32')
        self.transformer_layers_5_cross_attn_ffn_v_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.cross_attn_ffn.v_proj.weight', (128,128), 'float32')
        self.transformer_layers_5_cross_attn_ffn_merge.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.cross_attn_ffn.merge.weight', (128,128), 'float32')
        self.transformer_layers_5_cross_attn_ffn_norm1.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.cross_attn_ffn.norm1.bias', (128), 'float32')
        self.transformer_layers_5_cross_attn_ffn_norm1.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.cross_attn_ffn.norm1.weight', (128), 'float32')
        self.transformer_layers_5_cross_attn_ffn_mlp_0.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.cross_attn_ffn.mlp.0.weight', (1024,256), 'float32')
        self.transformer_layers_5_cross_attn_ffn_mlp_2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.cross_attn_ffn.mlp.2.weight', (128,1024), 'float32')
        self.transformer_layers_5_cross_attn_ffn_norm2.bias = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.cross_attn_ffn.norm2.bias', (128), 'float32')
        self.transformer_layers_5_cross_attn_ffn_norm2.weight = self.load_pnnx_bin_as_parameter(archive, 'transformer.layers.5.cross_attn_ffn.norm2.weight', (128), 'float32')
        self.pnnx_unique_224.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_224.weight', (128,128), 'float32')
        self.pnnx_unique_225.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_225.weight', (128,128), 'float32')
        self.pnnx_unique_226.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_226.weight', (128,128), 'float32')
        self.pnnx_unique_231.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_231.weight', (128,128), 'float32')
        self.pnnx_unique_232.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_232.bias', (128), 'float32')
        self.pnnx_unique_232.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_232.weight', (128), 'float32')
        self.pnnx_unique_233.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_233.weight', (128,128), 'float32')
        self.pnnx_unique_234.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_234.weight', (128,128), 'float32')
        self.pnnx_unique_235.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_235.weight', (128,128), 'float32')
        self.pnnx_unique_240.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_240.weight', (128,128), 'float32')
        self.pnnx_unique_241.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_241.bias', (128), 'float32')
        self.pnnx_unique_241.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_241.weight', (128), 'float32')
        self.pnnx_unique_242.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_242.weight', (1024,256), 'float32')
        self.pnnx_unique_244.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_244.weight', (128,1024), 'float32')
        self.pnnx_unique_245.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_245.bias', (128), 'float32')
        self.pnnx_unique_245.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_245.weight', (128), 'float32')
        self.feature_flow_attn_q_proj.bias = self.load_pnnx_bin_as_parameter(archive, 'feature_flow_attn.q_proj.bias', (128), 'float32')
        self.feature_flow_attn_q_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'feature_flow_attn.q_proj.weight', (128,128), 'float32')
        self.feature_flow_attn_k_proj.bias = self.load_pnnx_bin_as_parameter(archive, 'feature_flow_attn.k_proj.bias', (128), 'float32')
        self.feature_flow_attn_k_proj.weight = self.load_pnnx_bin_as_parameter(archive, 'feature_flow_attn.k_proj.weight', (128,128), 'float32')
        self.conv2d_1.weight = self.load_pnnx_bin_as_parameter(archive, 'conv2d_1.weight', (128,128,3,3), 'float32')
        self.conv2d_3.weight = self.load_pnnx_bin_as_parameter(archive, 'conv2d_3.weight', (128,128,3,3), 'float32')
        self.pnnx_unique_251.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_251.weight', (128,128), 'float32')
        self.pnnx_unique_252.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_252.weight', (128,128), 'float32')
        self.pnnx_unique_253.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_253.weight', (128,128), 'float32')
        self.pnnx_unique_258.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_258.weight', (128,128), 'float32')
        self.pnnx_unique_259.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_259.bias', (128), 'float32')
        self.pnnx_unique_259.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_259.weight', (128), 'float32')
        self.pnnx_unique_260.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_260.weight', (128,128), 'float32')
        self.pnnx_unique_261.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_261.weight', (128,128), 'float32')
        self.pnnx_unique_262.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_262.weight', (128,128), 'float32')
        self.pnnx_unique_267.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_267.weight', (128,128), 'float32')
        self.pnnx_unique_268.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_268.bias', (128), 'float32')
        self.pnnx_unique_268.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_268.weight', (128), 'float32')
        self.pnnx_unique_269.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_269.weight', (1024,256), 'float32')
        self.pnnx_unique_271.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_271.weight', (128,1024), 'float32')
        self.pnnx_unique_272.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_272.bias', (128), 'float32')
        self.pnnx_unique_272.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_272.weight', (128), 'float32')
        self.pnnx_unique_273.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_273.weight', (128,128), 'float32')
        self.pnnx_unique_274.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_274.weight', (128,128), 'float32')
        self.pnnx_unique_275.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_275.weight', (128,128), 'float32')
        self.pnnx_unique_280.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_280.weight', (128,128), 'float32')
        self.pnnx_unique_281.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_281.bias', (128), 'float32')
        self.pnnx_unique_281.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_281.weight', (128), 'float32')
        self.pnnx_unique_282.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_282.weight', (128,128), 'float32')
        self.pnnx_unique_283.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_283.weight', (128,128), 'float32')
        self.pnnx_unique_284.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_284.weight', (128,128), 'float32')
        self.pnnx_unique_289.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_289.weight', (128,128), 'float32')
        self.pnnx_unique_290.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_290.bias', (128), 'float32')
        self.pnnx_unique_290.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_290.weight', (128), 'float32')
        self.pnnx_unique_291.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_291.weight', (1024,256), 'float32')
        self.pnnx_unique_293.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_293.weight', (128,1024), 'float32')
        self.pnnx_unique_294.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_294.bias', (128), 'float32')
        self.pnnx_unique_294.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_294.weight', (128), 'float32')
        self.pnnx_unique_295.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_295.weight', (128,128), 'float32')
        self.pnnx_unique_296.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_296.weight', (128,128), 'float32')
        self.pnnx_unique_297.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_297.weight', (128,128), 'float32')
        self.pnnx_unique_302.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_302.weight', (128,128), 'float32')
        self.pnnx_unique_303.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_303.bias', (128), 'float32')
        self.pnnx_unique_303.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_303.weight', (128), 'float32')
        self.pnnx_unique_304.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_304.weight', (128,128), 'float32')
        self.pnnx_unique_305.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_305.weight', (128,128), 'float32')
        self.pnnx_unique_306.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_306.weight', (128,128), 'float32')
        self.pnnx_unique_311.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_311.weight', (128,128), 'float32')
        self.pnnx_unique_312.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_312.bias', (128), 'float32')
        self.pnnx_unique_312.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_312.weight', (128), 'float32')
        self.pnnx_unique_313.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_313.weight', (1024,256), 'float32')
        self.pnnx_unique_315.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_315.weight', (128,1024), 'float32')
        self.pnnx_unique_316.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_316.bias', (128), 'float32')
        self.pnnx_unique_316.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_316.weight', (128), 'float32')
        self.pnnx_unique_317.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_317.weight', (128,128), 'float32')
        self.pnnx_unique_318.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_318.weight', (128,128), 'float32')
        self.pnnx_unique_319.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_319.weight', (128,128), 'float32')
        self.pnnx_unique_324.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_324.weight', (128,128), 'float32')
        self.pnnx_unique_325.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_325.bias', (128), 'float32')
        self.pnnx_unique_325.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_325.weight', (128), 'float32')
        self.pnnx_unique_326.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_326.weight', (128,128), 'float32')
        self.pnnx_unique_327.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_327.weight', (128,128), 'float32')
        self.pnnx_unique_328.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_328.weight', (128,128), 'float32')
        self.pnnx_unique_333.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_333.weight', (128,128), 'float32')
        self.pnnx_unique_334.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_334.bias', (128), 'float32')
        self.pnnx_unique_334.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_334.weight', (128), 'float32')
        self.pnnx_unique_335.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_335.weight', (1024,256), 'float32')
        self.pnnx_unique_337.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_337.weight', (128,1024), 'float32')
        self.pnnx_unique_338.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_338.bias', (128), 'float32')
        self.pnnx_unique_338.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_338.weight', (128), 'float32')
        self.pnnx_unique_339.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_339.weight', (128,128), 'float32')
        self.pnnx_unique_340.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_340.weight', (128,128), 'float32')
        self.pnnx_unique_341.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_341.weight', (128,128), 'float32')
        self.pnnx_unique_346.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_346.weight', (128,128), 'float32')
        self.pnnx_unique_347.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_347.bias', (128), 'float32')
        self.pnnx_unique_347.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_347.weight', (128), 'float32')
        self.pnnx_unique_348.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_348.weight', (128,128), 'float32')
        self.pnnx_unique_349.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_349.weight', (128,128), 'float32')
        self.pnnx_unique_350.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_350.weight', (128,128), 'float32')
        self.pnnx_unique_355.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_355.weight', (128,128), 'float32')
        self.pnnx_unique_356.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_356.bias', (128), 'float32')
        self.pnnx_unique_356.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_356.weight', (128), 'float32')
        self.pnnx_unique_357.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_357.weight', (1024,256), 'float32')
        self.pnnx_unique_359.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_359.weight', (128,1024), 'float32')
        self.pnnx_unique_360.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_360.bias', (128), 'float32')
        self.pnnx_unique_360.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_360.weight', (128), 'float32')
        self.pnnx_unique_361.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_361.weight', (128,128), 'float32')
        self.pnnx_unique_362.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_362.weight', (128,128), 'float32')
        self.pnnx_unique_363.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_363.weight', (128,128), 'float32')
        self.pnnx_unique_368.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_368.weight', (128,128), 'float32')
        self.pnnx_unique_369.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_369.bias', (128), 'float32')
        self.pnnx_unique_369.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_369.weight', (128), 'float32')
        self.pnnx_unique_370.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_370.weight', (128,128), 'float32')
        self.pnnx_unique_371.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_371.weight', (128,128), 'float32')
        self.pnnx_unique_372.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_372.weight', (128,128), 'float32')
        self.pnnx_unique_377.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_377.weight', (128,128), 'float32')
        self.pnnx_unique_378.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_378.bias', (128), 'float32')
        self.pnnx_unique_378.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_378.weight', (128), 'float32')
        self.pnnx_unique_379.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_379.weight', (1024,256), 'float32')
        self.pnnx_unique_381.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_381.weight', (128,1024), 'float32')
        self.pnnx_unique_382.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_382.bias', (128), 'float32')
        self.pnnx_unique_382.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_382.weight', (128), 'float32')
        self.pnnx_unique_383.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_383.weight', (128,128), 'float32')
        self.pnnx_unique_384.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_384.weight', (128,128), 'float32')
        self.pnnx_unique_385.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_385.weight', (128,128), 'float32')
        self.pnnx_unique_390.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_390.weight', (128,128), 'float32')
        self.pnnx_unique_391.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_391.bias', (128), 'float32')
        self.pnnx_unique_391.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_391.weight', (128), 'float32')
        self.pnnx_unique_392.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_392.weight', (128,128), 'float32')
        self.pnnx_unique_393.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_393.weight', (128,128), 'float32')
        self.pnnx_unique_394.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_394.weight', (128,128), 'float32')
        self.pnnx_unique_399.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_399.weight', (128,128), 'float32')
        self.pnnx_unique_400.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_400.bias', (128), 'float32')
        self.pnnx_unique_400.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_400.weight', (128), 'float32')
        self.pnnx_unique_401.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_401.weight', (1024,256), 'float32')
        self.pnnx_unique_403.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_403.weight', (128,1024), 'float32')
        self.pnnx_unique_404.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_404.bias', (128), 'float32')
        self.pnnx_unique_404.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_404.weight', (128), 'float32')
        self.pnnx_unique_405.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_405.weight', (128,128), 'float32')
        self.pnnx_unique_406.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_406.weight', (128,128), 'float32')
        self.pnnx_unique_407.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_407.weight', (128,128), 'float32')
        self.pnnx_unique_412.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_412.weight', (128,128), 'float32')
        self.pnnx_unique_413.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_413.bias', (128), 'float32')
        self.pnnx_unique_413.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_413.weight', (128), 'float32')
        self.pnnx_unique_414.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_414.weight', (128,128), 'float32')
        self.pnnx_unique_415.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_415.weight', (128,128), 'float32')
        self.pnnx_unique_416.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_416.weight', (128,128), 'float32')
        self.pnnx_unique_421.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_421.weight', (128,128), 'float32')
        self.pnnx_unique_422.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_422.bias', (128), 'float32')
        self.pnnx_unique_422.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_422.weight', (128), 'float32')
        self.pnnx_unique_423.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_423.weight', (1024,256), 'float32')
        self.pnnx_unique_425.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_425.weight', (128,1024), 'float32')
        self.pnnx_unique_426.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_426.bias', (128), 'float32')
        self.pnnx_unique_426.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_426.weight', (128), 'float32')
        self.pnnx_unique_427.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_427.weight', (128,128), 'float32')
        self.pnnx_unique_428.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_428.weight', (128,128), 'float32')
        self.pnnx_unique_429.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_429.weight', (128,128), 'float32')
        self.pnnx_unique_434.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_434.weight', (128,128), 'float32')
        self.pnnx_unique_435.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_435.bias', (128), 'float32')
        self.pnnx_unique_435.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_435.weight', (128), 'float32')
        self.pnnx_unique_436.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_436.weight', (128,128), 'float32')
        self.pnnx_unique_437.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_437.weight', (128,128), 'float32')
        self.pnnx_unique_438.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_438.weight', (128,128), 'float32')
        self.pnnx_unique_443.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_443.weight', (128,128), 'float32')
        self.pnnx_unique_444.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_444.bias', (128), 'float32')
        self.pnnx_unique_444.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_444.weight', (128), 'float32')
        self.pnnx_unique_445.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_445.weight', (1024,256), 'float32')
        self.pnnx_unique_447.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_447.weight', (128,1024), 'float32')
        self.pnnx_unique_448.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_448.bias', (128), 'float32')
        self.pnnx_unique_448.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_448.weight', (128), 'float32')
        self.pnnx_unique_449.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_449.weight', (128,128), 'float32')
        self.pnnx_unique_450.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_450.weight', (128,128), 'float32')
        self.pnnx_unique_451.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_451.weight', (128,128), 'float32')
        self.pnnx_unique_456.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_456.weight', (128,128), 'float32')
        self.pnnx_unique_457.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_457.bias', (128), 'float32')
        self.pnnx_unique_457.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_457.weight', (128), 'float32')
        self.pnnx_unique_458.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_458.weight', (128,128), 'float32')
        self.pnnx_unique_459.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_459.weight', (128,128), 'float32')
        self.pnnx_unique_460.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_460.weight', (128,128), 'float32')
        self.pnnx_unique_465.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_465.weight', (128,128), 'float32')
        self.pnnx_unique_466.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_466.bias', (128), 'float32')
        self.pnnx_unique_466.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_466.weight', (128), 'float32')
        self.pnnx_unique_467.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_467.weight', (1024,256), 'float32')
        self.pnnx_unique_469.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_469.weight', (128,1024), 'float32')
        self.pnnx_unique_470.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_470.bias', (128), 'float32')
        self.pnnx_unique_470.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_470.weight', (128), 'float32')
        self.pnnx_unique_471.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_471.weight', (128,128), 'float32')
        self.pnnx_unique_472.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_472.weight', (128,128), 'float32')
        self.pnnx_unique_473.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_473.weight', (128,128), 'float32')
        self.pnnx_unique_478.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_478.weight', (128,128), 'float32')
        self.pnnx_unique_479.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_479.bias', (128), 'float32')
        self.pnnx_unique_479.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_479.weight', (128), 'float32')
        self.pnnx_unique_480.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_480.weight', (128,128), 'float32')
        self.pnnx_unique_481.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_481.weight', (128,128), 'float32')
        self.pnnx_unique_482.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_482.weight', (128,128), 'float32')
        self.pnnx_unique_487.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_487.weight', (128,128), 'float32')
        self.pnnx_unique_488.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_488.bias', (128), 'float32')
        self.pnnx_unique_488.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_488.weight', (128), 'float32')
        self.pnnx_unique_489.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_489.weight', (1024,256), 'float32')
        self.pnnx_unique_491.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_491.weight', (128,1024), 'float32')
        self.pnnx_unique_492.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_492.bias', (128), 'float32')
        self.pnnx_unique_492.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_492.weight', (128), 'float32')
        self.pnnx_unique_493.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_493.weight', (128,128), 'float32')
        self.pnnx_unique_494.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_494.weight', (128,128), 'float32')
        self.pnnx_unique_495.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_495.weight', (128,128), 'float32')
        self.pnnx_unique_500.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_500.weight', (128,128), 'float32')
        self.pnnx_unique_501.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_501.bias', (128), 'float32')
        self.pnnx_unique_501.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_501.weight', (128), 'float32')
        self.pnnx_unique_502.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_502.weight', (128,128), 'float32')
        self.pnnx_unique_503.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_503.weight', (128,128), 'float32')
        self.pnnx_unique_504.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_504.weight', (128,128), 'float32')
        self.pnnx_unique_509.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_509.weight', (128,128), 'float32')
        self.pnnx_unique_510.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_510.bias', (128), 'float32')
        self.pnnx_unique_510.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_510.weight', (128), 'float32')
        self.pnnx_unique_511.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_511.weight', (1024,256), 'float32')
        self.pnnx_unique_513.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_513.weight', (128,1024), 'float32')
        self.pnnx_unique_514.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_514.bias', (128), 'float32')
        self.pnnx_unique_514.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_514.weight', (128), 'float32')
        self.pnnx_unique_515.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_515.bias', (128), 'float32')
        self.pnnx_unique_515.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_515.weight', (128,128), 'float32')
        self.pnnx_unique_516.bias = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_516.bias', (128), 'float32')
        self.pnnx_unique_516.weight = self.load_pnnx_bin_as_parameter(archive, 'pnnx_unique_516.weight', (128,128), 'float32')
        self.upsampler_0.bias = self.load_pnnx_bin_as_parameter(archive, 'upsampler.0.bias', (256), 'float32')
        self.upsampler_0.weight = self.load_pnnx_bin_as_parameter(archive, 'upsampler.0.weight', (256,130,3,3), 'float32')
        self.upsampler_2.bias = self.load_pnnx_bin_as_parameter(archive, 'upsampler.2.bias', (144), 'float32')
        self.upsampler_2.weight = self.load_pnnx_bin_as_parameter(archive, 'upsampler.2.weight', (144,256,1,1), 'float32')
        self.pnnx_fold_position_1_pnnx_fold_position_1 = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_position.1.pnnx_fold_position.1', (1,4,128,18,30), 'float32')
        self.pnnx_fold_position_1_1_pnnx_fold_position_1 = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_position.1_1.pnnx_fold_position.1', (1,4,128,18,30), 'float32')
        self.pnnx_fold_init_grid_1_pnnx_fold_init_grid_1 = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_init_grid.1.pnnx_fold_init_grid.1', (1,2,36,60), 'float32')
        self.pnnx_fold_grid_5_pnnx_fold_grid_5 = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_grid.5.pnnx_fold_grid.5', (1,2160,2), 'float32')
        self.pnnx_fold_352_pnnx_fold_352 = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_352.pnnx_fold_352', (1,2,72,120), 'float32')
        self.pnnx_fold_position0_1_pnnx_fold_position0_1 = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_position0.1.pnnx_fold_position0.1', (1,64,128,9,15), 'float32')
        self.pnnx_fold_position0_1_1_pnnx_fold_position0_1 = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_position0.1_1.pnnx_fold_position0.1', (1,64,128,9,15), 'float32')
        self.pnnx_fold_coords_init_1_pnnx_fold_coords_init_1 = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_coords_init.1.pnnx_fold_coords_init.1', (1,2,72,120), 'float32')
        self.pnnx_fold_sample_coords_1_pnnx_fold_sample_coords_1 = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_sample_coords.1.pnnx_fold_sample_coords.1', (1,8640,81,2), 'float32')
        self.pnnx_fold_grid_1_pnnx_fold_grid_1 = self.load_pnnx_bin_as_parameter(archive, 'pnnx_fold_grid.1.pnnx_fold_grid.1', (1,8640,81,2), 'float32')
        archive.close()

    def load_pnnx_bin_as_parameter(self, archive, key, shape, dtype, requires_grad=True):
        return nn.Parameter(self.load_pnnx_bin_as_tensor(archive, key, shape, dtype), requires_grad)

    def load_pnnx_bin_as_tensor(self, archive, key, shape, dtype):
        _, tmppath = tempfile.mkstemp()
        tmpf = open(tmppath, 'wb')
        with archive.open(key) as keyfile:
            tmpf.write(keyfile.read())
        tmpf.close()
        m = np.memmap(tmppath, dtype=dtype, mode='r', shape=shape).copy()
        os.remove(tmppath)
        return torch.from_numpy(m)

    def forward(self, v_0, v_1):
        v_2 = self.backbone_conv1(v_0)
        v_3 = self.backbone_norm1(v_2)
        v_4 = self.backbone_relu1(v_3)
        v_5 = self.backbone_layer1_0_conv1(v_4)
        v_6 = self.backbone_layer1_0_norm1(v_5)
        v_7 = self.backbone_layer1_0_relu(v_6)
        v_8 = self.backbone_layer1_0_conv2(v_7)
        v_9 = self.backbone_layer1_0_norm2(v_8)
        v_10 = self.pnnx_unique_0(v_9)
        v_11 = (v_4 + v_10)
        v_12 = self.pnnx_unique_1(v_11)
        v_13 = self.backbone_layer1_1_conv1(v_12)
        v_14 = self.backbone_layer1_1_norm1(v_13)
        v_15 = self.backbone_layer1_1_relu(v_14)
        v_16 = self.backbone_layer1_1_conv2(v_15)
        v_17 = self.backbone_layer1_1_norm2(v_16)
        v_18 = self.pnnx_unique_2(v_17)
        v_19 = (v_12 + v_18)
        v_20 = self.pnnx_unique_3(v_19)
        v_21 = self.backbone_layer2_0_conv1(v_20)
        v_22 = self.backbone_layer2_0_norm1(v_21)
        v_23 = self.backbone_layer2_0_relu(v_22)
        v_24 = self.backbone_layer2_0_conv2(v_23)
        v_25 = self.backbone_layer2_0_norm2(v_24)
        v_26 = self.pnnx_unique_4(v_25)
        v_27 = self.backbone_layer2_0_downsample_0(v_20)
        v_28 = self.backbone_layer2_0_downsample_1(v_27)
        v_29 = (v_28 + v_26)
        v_30 = self.pnnx_unique_5(v_29)
        v_31 = self.backbone_layer2_1_conv1(v_30)
        v_32 = self.backbone_layer2_1_norm1(v_31)
        v_33 = self.backbone_layer2_1_relu(v_32)
        v_34 = self.backbone_layer2_1_conv2(v_33)
        v_35 = self.backbone_layer2_1_norm2(v_34)
        v_36 = self.pnnx_unique_6(v_35)
        v_37 = (v_30 + v_36)
        v_38 = self.pnnx_unique_7(v_37)
        v_39 = self.backbone_layer3_0_conv1(v_38)
        v_40 = self.backbone_layer3_0_norm1(v_39)
        v_41 = self.backbone_layer3_0_relu(v_40)
        v_42 = self.backbone_layer3_0_conv2(v_41)
        v_43 = self.backbone_layer3_0_norm2(v_42)
        v_44 = self.pnnx_unique_8(v_43)
        v_45 = self.backbone_layer3_0_downsample_0(v_38)
        v_46 = self.backbone_layer3_0_downsample_1(v_45)
        v_47 = (v_46 + v_44)
        v_48 = self.pnnx_unique_9(v_47)
        v_49 = self.backbone_layer3_1_conv1(v_48)
        v_50 = self.backbone_layer3_1_norm1(v_49)
        v_51 = self.backbone_layer3_1_relu(v_50)
        v_52 = self.backbone_layer3_1_conv2(v_51)
        v_53 = self.backbone_layer3_1_norm2(v_52)
        v_54 = self.pnnx_unique_10(v_53)
        v_55 = (v_48 + v_54)
        v_56 = self.pnnx_unique_11(v_55)
        v_57 = self.backbone_conv2(v_56)
        v_58 = self.pnnx_unique_12(v_1)
        v_59 = self.pnnx_unique_13(v_58)
        v_60 = self.pnnx_unique_14(v_59)
        v_61 = self.pnnx_unique_15(v_60)
        v_62 = self.pnnx_unique_16(v_61)
        v_63 = self.pnnx_unique_17(v_62)
        v_64 = self.pnnx_unique_18(v_63)
        v_65 = self.pnnx_unique_19(v_64)
        v_66 = self.pnnx_unique_20(v_65)
        v_67 = (v_60 + v_66)
        v_68 = self.pnnx_unique_21(v_67)
        v_69 = self.pnnx_unique_22(v_68)
        v_70 = self.pnnx_unique_23(v_69)
        v_71 = self.pnnx_unique_24(v_70)
        v_72 = self.pnnx_unique_25(v_71)
        v_73 = self.pnnx_unique_26(v_72)
        v_74 = self.pnnx_unique_27(v_73)
        v_75 = (v_68 + v_74)
        v_76 = self.pnnx_unique_28(v_75)
        v_77 = self.pnnx_unique_29(v_76)
        v_78 = self.pnnx_unique_30(v_77)
        v_79 = self.pnnx_unique_31(v_78)
        v_80 = self.pnnx_unique_32(v_79)
        v_81 = self.pnnx_unique_33(v_80)
        v_82 = self.pnnx_unique_34(v_81)
        v_83 = self.pnnx_unique_35(v_76)
        v_84 = self.pnnx_unique_36(v_83)
        v_85 = (v_84 + v_82)
        v_86 = self.pnnx_unique_37(v_85)
        v_87 = self.pnnx_unique_38(v_86)
        v_88 = self.pnnx_unique_39(v_87)
        v_89 = self.pnnx_unique_40(v_88)
        v_90 = self.pnnx_unique_41(v_89)
        v_91 = self.pnnx_unique_42(v_90)
        v_92 = self.pnnx_unique_43(v_91)
        v_93 = (v_86 + v_92)
        v_94 = self.pnnx_unique_44(v_93)
        v_95 = self.pnnx_unique_45(v_94)
        v_96 = self.pnnx_unique_46(v_95)
        v_97 = self.pnnx_unique_47(v_96)
        v_98 = self.pnnx_unique_48(v_97)
        v_99 = self.pnnx_unique_49(v_98)
        v_100 = self.pnnx_unique_50(v_99)
        v_101 = self.pnnx_unique_51(v_94)
        v_102 = self.pnnx_unique_52(v_101)
        v_103 = (v_102 + v_100)
        v_104 = self.pnnx_unique_53(v_103)
        v_105 = self.pnnx_unique_54(v_104)
        v_106 = self.pnnx_unique_55(v_105)
        v_107 = self.pnnx_unique_56(v_106)
        v_108 = self.pnnx_unique_57(v_107)
        v_109 = self.pnnx_unique_58(v_108)
        v_110 = self.pnnx_unique_59(v_109)
        v_111 = (v_104 + v_110)
        v_112 = self.pnnx_unique_60(v_111)
        v_113 = self.pnnx_unique_61(v_112)
        v_114 = self.conv2d_0(v_57)
        v_115 = model.gmflow.utils.split_feature(v_114)
        v_116 = self.conv2d_2(v_113)
        v_117 = model.gmflow.utils.split_feature(v_116)
        v_118 = self.pnnx_fold_position_1_pnnx_fold_position_1
        v_119 = self.pnnx_fold_position_1_1_pnnx_fold_position_1
        v_120 = (v_115 + v_118)
        v_121 = (v_117 + v_119)
        v_122 = model.gmflow.utils.merge_splits(v_120)
        v_123 = model.gmflow.utils.merge_splits(v_121)
        v_124 = torch.flatten(input=v_122, end_dim=-1, start_dim=2)
        v_125 = torch.flatten(input=v_123, end_dim=-1, start_dim=2)
        v_126 = torch.permute(input=v_124, dims=(0,2,1))
        v_127 = self.transformer_layers_0_self_attn_q_proj(v_126)
        v_128 = self.transformer_layers_0_self_attn_k_proj(v_126)
        v_129 = self.transformer_layers_0_self_attn_v_proj(v_126)
        v_130 = v_127.view(1, 36, 60, 128)
        v_131 = v_128.view(1, 36, 60, 128)
        v_132 = v_129.view(1, 36, 60, 128)
        v_133 = torch.permute(input=v_130, dims=(0,3,1,2))
        v_134 = model.gmflow.utils.split_feature(v_133)
        v_135 = torch.permute(input=v_131, dims=(0,3,1,2))
        v_136 = model.gmflow.utils.split_feature(v_135)
        v_137 = torch.permute(input=v_132, dims=(0,3,1,2))
        v_138 = model.gmflow.utils.split_feature(v_137)
        v_139 = torch.permute(input=v_136, dims=(0,1,3,4,2))
        v_140 = v_139.view(1, 4, -1, 128)
        v_141 = torch.permute(input=v_134, dims=(0,1,3,4,2))
        v_142 = v_141.view(1, 4, -1, 128)
        v_143 = torch.permute(input=v_140, dims=(0,1,3,2))
        v_144 = torch.matmul(input=v_142, other=v_143)
        v_145 = (v_144 / 11.313708)
        v_146 = F.softmax(input=v_145, dim=-1)
        v_147 = torch.permute(input=v_138, dims=(0,1,3,4,2))
        v_148 = v_147.view(1, 4, -1, 128)
        v_149 = torch.matmul(input=v_146, other=v_148)
        v_150 = v_149.view(1, 4, 18, 30, 128)
        v_151 = torch.permute(input=v_150, dims=(0,1,4,2,3))
        v_152 = model.gmflow.utils.merge_splits(v_151)
        v_153 = torch.permute(input=v_152, dims=(0,2,3,1))
        v_154 = v_153.view(1, -1, 128)
        v_155 = self.transformer_layers_0_self_attn_merge(v_154)
        v_156 = self.transformer_layers_0_self_attn_norm1(v_155)
        v_157 = (v_126 + v_156)
        v_158 = self.transformer_layers_0_cross_attn_ffn_q_proj(v_157)
        v_159 = torch.permute(input=v_125, dims=(0,2,1))
        v_160 = self.transformer_layers_0_cross_attn_ffn_k_proj(v_159)
        v_161 = self.transformer_layers_0_cross_attn_ffn_v_proj(v_159)
        v_162 = v_158.view(1, 36, 60, 128)
        v_163 = v_160.view(1, 36, 60, 128)
        v_164 = v_161.view(1, 36, 60, 128)
        v_165 = torch.permute(input=v_162, dims=(0,3,1,2))
        v_166 = model.gmflow.utils.split_feature(v_165)
        v_167 = torch.permute(input=v_163, dims=(0,3,1,2))
        v_168 = model.gmflow.utils.split_feature(v_167)
        v_169 = torch.permute(input=v_164, dims=(0,3,1,2))
        v_170 = model.gmflow.utils.split_feature(v_169)
        v_171 = torch.permute(input=v_168, dims=(0,1,3,4,2))
        v_172 = v_171.view(1, 4, -1, 128)
        v_173 = torch.permute(input=v_166, dims=(0,1,3,4,2))
        v_174 = v_173.view(1, 4, -1, 128)
        v_175 = torch.permute(input=v_172, dims=(0,1,3,2))
        v_176 = torch.matmul(input=v_174, other=v_175)
        v_177 = (v_176 / 11.313708)
        v_178 = F.softmax(input=v_177, dim=-1)
        v_179 = torch.permute(input=v_170, dims=(0,1,3,4,2))
        v_180 = v_179.view(1, 4, -1, 128)
        v_181 = torch.matmul(input=v_178, other=v_180)
        v_182 = v_181.view(1, 4, 18, 30, 128)
        v_183 = torch.permute(input=v_182, dims=(0,1,4,2,3))
        v_184 = model.gmflow.utils.merge_splits(v_183)
        v_185 = torch.permute(input=v_184, dims=(0,2,3,1))
        v_186 = v_185.view(1, -1, 128)
        v_187 = self.transformer_layers_0_cross_attn_ffn_merge(v_186)
        v_188 = self.transformer_layers_0_cross_attn_ffn_norm1(v_187)
        v_189 = torch.cat((v_157, v_188), dim=-1)
        v_190 = self.transformer_layers_0_cross_attn_ffn_mlp_0(v_189)
        v_191 = self.transformer_layers_0_cross_attn_ffn_mlp_1(v_190)
        v_192 = self.transformer_layers_0_cross_attn_ffn_mlp_2(v_191)
        v_193 = self.transformer_layers_0_cross_attn_ffn_norm2(v_192)
        v_194 = (v_157 + v_193)
        v_195 = self.pnnx_unique_74(v_159)
        v_196 = self.pnnx_unique_75(v_159)
        v_197 = self.pnnx_unique_76(v_159)
        v_198 = v_195.view(1, 36, 60, 128)
        v_199 = v_196.view(1, 36, 60, 128)
        v_200 = v_197.view(1, 36, 60, 128)
        v_201 = torch.permute(input=v_198, dims=(0,3,1,2))
        v_202 = model.gmflow.utils.split_feature(v_201)
        v_203 = torch.permute(input=v_199, dims=(0,3,1,2))
        v_204 = model.gmflow.utils.split_feature(v_203)
        v_205 = torch.permute(input=v_200, dims=(0,3,1,2))
        v_206 = model.gmflow.utils.split_feature(v_205)
        v_207 = torch.permute(input=v_204, dims=(0,1,3,4,2))
        v_208 = v_207.view(1, 4, -1, 128)
        v_209 = torch.permute(input=v_202, dims=(0,1,3,4,2))
        v_210 = v_209.view(1, 4, -1, 128)
        v_211 = torch.permute(input=v_208, dims=(0,1,3,2))
        v_212 = torch.matmul(input=v_210, other=v_211)
        v_213 = (v_212 / 11.313708)
        v_214 = F.softmax(input=v_213, dim=-1)
        v_215 = torch.permute(input=v_206, dims=(0,1,3,4,2))
        v_216 = v_215.view(1, 4, -1, 128)
        v_217 = torch.matmul(input=v_214, other=v_216)
        v_218 = v_217.view(1, 4, 18, 30, 128)
        v_219 = torch.permute(input=v_218, dims=(0,1,4,2,3))
        v_220 = model.gmflow.utils.merge_splits(v_219)
        v_221 = torch.permute(input=v_220, dims=(0,2,3,1))
        v_222 = v_221.view(1, -1, 128)
        v_223 = self.pnnx_unique_81(v_222)
        v_224 = self.pnnx_unique_82(v_223)
        v_225 = (v_159 + v_224)
        v_226 = self.pnnx_unique_83(v_225)
        v_227 = self.pnnx_unique_84(v_126)
        v_228 = self.pnnx_unique_85(v_126)
        v_229 = v_226.view(1, 36, 60, 128)
        v_230 = v_227.view(1, 36, 60, 128)
        v_231 = v_228.view(1, 36, 60, 128)
        v_232 = torch.permute(input=v_229, dims=(0,3,1,2))
        v_233 = model.gmflow.utils.split_feature(v_232)
        v_234 = torch.permute(input=v_230, dims=(0,3,1,2))
        v_235 = model.gmflow.utils.split_feature(v_234)
        v_236 = torch.permute(input=v_231, dims=(0,3,1,2))
        v_237 = model.gmflow.utils.split_feature(v_236)
        v_238 = torch.permute(input=v_235, dims=(0,1,3,4,2))
        v_239 = v_238.view(1, 4, -1, 128)
        v_240 = torch.permute(input=v_233, dims=(0,1,3,4,2))
        v_241 = v_240.view(1, 4, -1, 128)
        v_242 = torch.permute(input=v_239, dims=(0,1,3,2))
        v_243 = torch.matmul(input=v_241, other=v_242)
        v_244 = (v_243 / 11.313708)
        v_245 = F.softmax(input=v_244, dim=-1)
        v_246 = torch.permute(input=v_237, dims=(0,1,3,4,2))
        v_247 = v_246.view(1, 4, -1, 128)
        v_248 = torch.matmul(input=v_245, other=v_247)
        v_249 = v_248.view(1, 4, 18, 30, 128)
        v_250 = torch.permute(input=v_249, dims=(0,1,4,2,3))
        v_251 = model.gmflow.utils.merge_splits(v_250)
        v_252 = torch.permute(input=v_251, dims=(0,2,3,1))
        v_253 = v_252.view(1, -1, 128)
        v_254 = self.pnnx_unique_90(v_253)
        v_255 = self.pnnx_unique_91(v_254)
        v_256 = torch.cat((v_225, v_255), dim=-1)
        v_257 = self.pnnx_unique_92(v_256)
        v_258 = self.pnnx_unique_93(v_257)
        v_259 = self.pnnx_unique_94(v_258)
        v_260 = self.pnnx_unique_95(v_259)
        v_261 = (v_225 + v_260)
        v_262 = self.transformer_layers_1_self_attn_q_proj(v_194)
        v_263 = self.transformer_layers_1_self_attn_k_proj(v_194)
        v_264 = self.transformer_layers_1_self_attn_v_proj(v_194)
        v_265 = v_262.view(1, 36, 60, 128)
        v_266 = v_263.view(1, 36, 60, 128)
        v_267 = v_264.view(1, 36, 60, 128)
        v_268 = torch.permute(input=v_265, dims=(0,3,1,2))
        v_269 = model.gmflow.utils.split_feature(v_268)
        v_270 = torch.permute(input=v_266, dims=(0,3,1,2))
        v_271 = model.gmflow.utils.split_feature(v_270)
        v_272 = torch.permute(input=v_267, dims=(0,3,1,2))
        v_273 = model.gmflow.utils.split_feature(v_272)
        v_274 = torch.permute(input=v_271, dims=(0,1,3,4,2))
        v_275 = v_274.view(1, 4, -1, 128)
        v_276 = torch.permute(input=v_269, dims=(0,1,3,4,2))
        v_277 = v_276.view(1, 4, -1, 128)
        v_278 = torch.permute(input=v_275, dims=(0,1,3,2))
        v_279 = torch.matmul(input=v_277, other=v_278)
        v_280 = (v_279 / 11.313708)
        v_281 = F.softmax(input=v_280, dim=-1)
        v_282 = torch.permute(input=v_273, dims=(0,1,3,4,2))
        v_283 = v_282.view(1, 4, -1, 128)
        v_284 = torch.matmul(input=v_281, other=v_283)
        v_285 = v_284.view(1, 4, 18, 30, 128)
        v_286 = torch.permute(input=v_285, dims=(0,1,4,2,3))
        v_287 = model.gmflow.utils.merge_splits(v_286)
        v_288 = torch.permute(input=v_287, dims=(0,2,3,1))
        v_289 = v_288.view(1, -1, 128)
        v_290 = self.transformer_layers_1_self_attn_merge(v_289)
        v_291 = self.transformer_layers_1_self_attn_norm1(v_290)
        v_292 = (v_194 + v_291)
        v_293 = self.transformer_layers_1_cross_attn_ffn_q_proj(v_292)
        v_294 = self.transformer_layers_1_cross_attn_ffn_k_proj(v_261)
        v_295 = self.transformer_layers_1_cross_attn_ffn_v_proj(v_261)
        v_296 = v_293.view(1, 36, 60, 128)
        v_297 = v_294.view(1, 36, 60, 128)
        v_298 = v_295.view(1, 36, 60, 128)
        v_299 = torch.permute(input=v_296, dims=(0,3,1,2))
        v_300 = model.gmflow.utils.split_feature(v_299)
        v_301 = torch.permute(input=v_297, dims=(0,3,1,2))
        v_302 = model.gmflow.utils.split_feature(v_301)
        v_303 = torch.permute(input=v_298, dims=(0,3,1,2))
        v_304 = model.gmflow.utils.split_feature(v_303)
        v_305 = torch.permute(input=v_302, dims=(0,1,3,4,2))
        v_306 = v_305.view(1, 4, -1, 128)
        v_307 = torch.permute(input=v_300, dims=(0,1,3,4,2))
        v_308 = v_307.view(1, 4, -1, 128)
        v_309 = torch.permute(input=v_306, dims=(0,1,3,2))
        v_310 = torch.matmul(input=v_308, other=v_309)
        v_311 = (v_310 / 11.313708)
        v_312 = F.softmax(input=v_311, dim=-1)
        v_313 = torch.permute(input=v_304, dims=(0,1,3,4,2))
        v_314 = v_313.view(1, 4, -1, 128)
        v_315 = torch.matmul(input=v_312, other=v_314)
        v_316 = v_315.view(1, 4, 18, 30, 128)
        v_317 = torch.permute(input=v_316, dims=(0,1,4,2,3))
        v_318 = model.gmflow.utils.merge_splits(v_317)
        v_319 = torch.permute(input=v_318, dims=(0,2,3,1))
        v_320 = v_319.view(1, -1, 128)
        v_321 = self.transformer_layers_1_cross_attn_ffn_merge(v_320)
        v_322 = self.transformer_layers_1_cross_attn_ffn_norm1(v_321)
        v_323 = torch.cat((v_292, v_322), dim=-1)
        v_324 = self.transformer_layers_1_cross_attn_ffn_mlp_0(v_323)
        v_325 = self.transformer_layers_1_cross_attn_ffn_mlp_1(v_324)
        v_326 = self.transformer_layers_1_cross_attn_ffn_mlp_2(v_325)
        v_327 = self.transformer_layers_1_cross_attn_ffn_norm2(v_326)
        v_328 = (v_292 + v_327)
        v_329 = self.pnnx_unique_104(v_261)
        v_330 = self.pnnx_unique_105(v_261)
        v_331 = self.pnnx_unique_106(v_261)
        v_332 = v_329.view(1, 36, 60, 128)
        v_333 = v_330.view(1, 36, 60, 128)
        v_334 = v_331.view(1, 36, 60, 128)
        v_335 = torch.permute(input=v_332, dims=(0,3,1,2))
        v_336 = model.gmflow.utils.split_feature(v_335)
        v_337 = torch.permute(input=v_333, dims=(0,3,1,2))
        v_338 = model.gmflow.utils.split_feature(v_337)
        v_339 = torch.permute(input=v_334, dims=(0,3,1,2))
        v_340 = model.gmflow.utils.split_feature(v_339)
        v_341 = torch.permute(input=v_338, dims=(0,1,3,4,2))
        v_342 = v_341.view(1, 4, -1, 128)
        v_343 = torch.permute(input=v_336, dims=(0,1,3,4,2))
        v_344 = v_343.view(1, 4, -1, 128)
        v_345 = torch.permute(input=v_342, dims=(0,1,3,2))
        v_346 = torch.matmul(input=v_344, other=v_345)
        v_347 = (v_346 / 11.313708)
        v_348 = F.softmax(input=v_347, dim=-1)
        v_349 = torch.permute(input=v_340, dims=(0,1,3,4,2))
        v_350 = v_349.view(1, 4, -1, 128)
        v_351 = torch.matmul(input=v_348, other=v_350)
        v_352 = v_351.view(1, 4, 18, 30, 128)
        v_353 = torch.permute(input=v_352, dims=(0,1,4,2,3))
        v_354 = model.gmflow.utils.merge_splits(v_353)
        v_355 = torch.permute(input=v_354, dims=(0,2,3,1))
        v_356 = v_355.view(1, -1, 128)
        v_357 = self.pnnx_unique_111(v_356)
        v_358 = self.pnnx_unique_112(v_357)
        v_359 = (v_261 + v_358)
        v_360 = self.pnnx_unique_113(v_359)
        v_361 = self.pnnx_unique_114(v_194)
        v_362 = self.pnnx_unique_115(v_194)
        v_363 = v_360.view(1, 36, 60, 128)
        v_364 = v_361.view(1, 36, 60, 128)
        v_365 = v_362.view(1, 36, 60, 128)
        v_366 = torch.permute(input=v_363, dims=(0,3,1,2))
        v_367 = model.gmflow.utils.split_feature(v_366)
        v_368 = torch.permute(input=v_364, dims=(0,3,1,2))
        v_369 = model.gmflow.utils.split_feature(v_368)
        v_370 = torch.permute(input=v_365, dims=(0,3,1,2))
        v_371 = model.gmflow.utils.split_feature(v_370)
        v_372 = torch.permute(input=v_369, dims=(0,1,3,4,2))
        v_373 = v_372.view(1, 4, -1, 128)
        v_374 = torch.permute(input=v_367, dims=(0,1,3,4,2))
        v_375 = v_374.view(1, 4, -1, 128)
        v_376 = torch.permute(input=v_373, dims=(0,1,3,2))
        v_377 = torch.matmul(input=v_375, other=v_376)
        v_378 = (v_377 / 11.313708)
        v_379 = F.softmax(input=v_378, dim=-1)
        v_380 = torch.permute(input=v_371, dims=(0,1,3,4,2))
        v_381 = v_380.view(1, 4, -1, 128)
        v_382 = torch.matmul(input=v_379, other=v_381)
        v_383 = v_382.view(1, 4, 18, 30, 128)
        v_384 = torch.permute(input=v_383, dims=(0,1,4,2,3))
        v_385 = model.gmflow.utils.merge_splits(v_384)
        v_386 = torch.permute(input=v_385, dims=(0,2,3,1))
        v_387 = v_386.view(1, -1, 128)
        v_388 = self.pnnx_unique_120(v_387)
        v_389 = self.pnnx_unique_121(v_388)
        v_390 = torch.cat((v_359, v_389), dim=-1)
        v_391 = self.pnnx_unique_122(v_390)
        v_392 = self.pnnx_unique_123(v_391)
        v_393 = self.pnnx_unique_124(v_392)
        v_394 = self.pnnx_unique_125(v_393)
        v_395 = (v_359 + v_394)
        v_396 = self.transformer_layers_2_self_attn_q_proj(v_328)
        v_397 = self.transformer_layers_2_self_attn_k_proj(v_328)
        v_398 = self.transformer_layers_2_self_attn_v_proj(v_328)
        v_399 = v_396.view(1, 36, 60, 128)
        v_400 = v_397.view(1, 36, 60, 128)
        v_401 = v_398.view(1, 36, 60, 128)
        v_402 = torch.permute(input=v_399, dims=(0,3,1,2))
        v_403 = model.gmflow.utils.split_feature(v_402)
        v_404 = torch.permute(input=v_400, dims=(0,3,1,2))
        v_405 = model.gmflow.utils.split_feature(v_404)
        v_406 = torch.permute(input=v_401, dims=(0,3,1,2))
        v_407 = model.gmflow.utils.split_feature(v_406)
        v_408 = torch.permute(input=v_405, dims=(0,1,3,4,2))
        v_409 = v_408.view(1, 4, -1, 128)
        v_410 = torch.permute(input=v_403, dims=(0,1,3,4,2))
        v_411 = v_410.view(1, 4, -1, 128)
        v_412 = torch.permute(input=v_409, dims=(0,1,3,2))
        v_413 = torch.matmul(input=v_411, other=v_412)
        v_414 = (v_413 / 11.313708)
        v_415 = F.softmax(input=v_414, dim=-1)
        v_416 = torch.permute(input=v_407, dims=(0,1,3,4,2))
        v_417 = v_416.view(1, 4, -1, 128)
        v_418 = torch.matmul(input=v_415, other=v_417)
        v_419 = v_418.view(1, 4, 18, 30, 128)
        v_420 = torch.permute(input=v_419, dims=(0,1,4,2,3))
        v_421 = model.gmflow.utils.merge_splits(v_420)
        v_422 = torch.permute(input=v_421, dims=(0,2,3,1))
        v_423 = v_422.view(1, -1, 128)
        v_424 = self.transformer_layers_2_self_attn_merge(v_423)
        v_425 = self.transformer_layers_2_self_attn_norm1(v_424)
        v_426 = (v_328 + v_425)
        v_427 = self.transformer_layers_2_cross_attn_ffn_q_proj(v_426)
        v_428 = self.transformer_layers_2_cross_attn_ffn_k_proj(v_395)
        v_429 = self.transformer_layers_2_cross_attn_ffn_v_proj(v_395)
        v_430 = v_427.view(1, 36, 60, 128)
        v_431 = v_428.view(1, 36, 60, 128)
        v_432 = v_429.view(1, 36, 60, 128)
        v_433 = torch.permute(input=v_430, dims=(0,3,1,2))
        v_434 = model.gmflow.utils.split_feature(v_433)
        v_435 = torch.permute(input=v_431, dims=(0,3,1,2))
        v_436 = model.gmflow.utils.split_feature(v_435)
        v_437 = torch.permute(input=v_432, dims=(0,3,1,2))
        v_438 = model.gmflow.utils.split_feature(v_437)
        v_439 = torch.permute(input=v_436, dims=(0,1,3,4,2))
        v_440 = v_439.view(1, 4, -1, 128)
        v_441 = torch.permute(input=v_434, dims=(0,1,3,4,2))
        v_442 = v_441.view(1, 4, -1, 128)
        v_443 = torch.permute(input=v_440, dims=(0,1,3,2))
        v_444 = torch.matmul(input=v_442, other=v_443)
        v_445 = (v_444 / 11.313708)
        v_446 = F.softmax(input=v_445, dim=-1)
        v_447 = torch.permute(input=v_438, dims=(0,1,3,4,2))
        v_448 = v_447.view(1, 4, -1, 128)
        v_449 = torch.matmul(input=v_446, other=v_448)
        v_450 = v_449.view(1, 4, 18, 30, 128)
        v_451 = torch.permute(input=v_450, dims=(0,1,4,2,3))
        v_452 = model.gmflow.utils.merge_splits(v_451)
        v_453 = torch.permute(input=v_452, dims=(0,2,3,1))
        v_454 = v_453.view(1, -1, 128)
        v_455 = self.transformer_layers_2_cross_attn_ffn_merge(v_454)
        v_456 = self.transformer_layers_2_cross_attn_ffn_norm1(v_455)
        v_457 = torch.cat((v_426, v_456), dim=-1)
        v_458 = self.transformer_layers_2_cross_attn_ffn_mlp_0(v_457)
        v_459 = self.transformer_layers_2_cross_attn_ffn_mlp_1(v_458)
        v_460 = self.transformer_layers_2_cross_attn_ffn_mlp_2(v_459)
        v_461 = self.transformer_layers_2_cross_attn_ffn_norm2(v_460)
        v_462 = (v_426 + v_461)
        v_463 = self.pnnx_unique_134(v_395)
        v_464 = self.pnnx_unique_135(v_395)
        v_465 = self.pnnx_unique_136(v_395)
        v_466 = v_463.view(1, 36, 60, 128)
        v_467 = v_464.view(1, 36, 60, 128)
        v_468 = v_465.view(1, 36, 60, 128)
        v_469 = torch.permute(input=v_466, dims=(0,3,1,2))
        v_470 = model.gmflow.utils.split_feature(v_469)
        v_471 = torch.permute(input=v_467, dims=(0,3,1,2))
        v_472 = model.gmflow.utils.split_feature(v_471)
        v_473 = torch.permute(input=v_468, dims=(0,3,1,2))
        v_474 = model.gmflow.utils.split_feature(v_473)
        v_475 = torch.permute(input=v_472, dims=(0,1,3,4,2))
        v_476 = v_475.view(1, 4, -1, 128)
        v_477 = torch.permute(input=v_470, dims=(0,1,3,4,2))
        v_478 = v_477.view(1, 4, -1, 128)
        v_479 = torch.permute(input=v_476, dims=(0,1,3,2))
        v_480 = torch.matmul(input=v_478, other=v_479)
        v_481 = (v_480 / 11.313708)
        v_482 = F.softmax(input=v_481, dim=-1)
        v_483 = torch.permute(input=v_474, dims=(0,1,3,4,2))
        v_484 = v_483.view(1, 4, -1, 128)
        v_485 = torch.matmul(input=v_482, other=v_484)
        v_486 = v_485.view(1, 4, 18, 30, 128)
        v_487 = torch.permute(input=v_486, dims=(0,1,4,2,3))
        v_488 = model.gmflow.utils.merge_splits(v_487)
        v_489 = torch.permute(input=v_488, dims=(0,2,3,1))
        v_490 = v_489.view(1, -1, 128)
        v_491 = self.pnnx_unique_141(v_490)
        v_492 = self.pnnx_unique_142(v_491)
        v_493 = (v_395 + v_492)
        v_494 = self.pnnx_unique_143(v_493)
        v_495 = self.pnnx_unique_144(v_328)
        v_496 = self.pnnx_unique_145(v_328)
        v_497 = v_494.view(1, 36, 60, 128)
        v_498 = v_495.view(1, 36, 60, 128)
        v_499 = v_496.view(1, 36, 60, 128)
        v_500 = torch.permute(input=v_497, dims=(0,3,1,2))
        v_501 = model.gmflow.utils.split_feature(v_500)
        v_502 = torch.permute(input=v_498, dims=(0,3,1,2))
        v_503 = model.gmflow.utils.split_feature(v_502)
        v_504 = torch.permute(input=v_499, dims=(0,3,1,2))
        v_505 = model.gmflow.utils.split_feature(v_504)
        v_506 = torch.permute(input=v_503, dims=(0,1,3,4,2))
        v_507 = v_506.view(1, 4, -1, 128)
        v_508 = torch.permute(input=v_501, dims=(0,1,3,4,2))
        v_509 = v_508.view(1, 4, -1, 128)
        v_510 = torch.permute(input=v_507, dims=(0,1,3,2))
        v_511 = torch.matmul(input=v_509, other=v_510)
        v_512 = (v_511 / 11.313708)
        v_513 = F.softmax(input=v_512, dim=-1)
        v_514 = torch.permute(input=v_505, dims=(0,1,3,4,2))
        v_515 = v_514.view(1, 4, -1, 128)
        v_516 = torch.matmul(input=v_513, other=v_515)
        v_517 = v_516.view(1, 4, 18, 30, 128)
        v_518 = torch.permute(input=v_517, dims=(0,1,4,2,3))
        v_519 = model.gmflow.utils.merge_splits(v_518)
        v_520 = torch.permute(input=v_519, dims=(0,2,3,1))
        v_521 = v_520.view(1, -1, 128)
        v_522 = self.pnnx_unique_150(v_521)
        v_523 = self.pnnx_unique_151(v_522)
        v_524 = torch.cat((v_493, v_523), dim=-1)
        v_525 = self.pnnx_unique_152(v_524)
        v_526 = self.pnnx_unique_153(v_525)
        v_527 = self.pnnx_unique_154(v_526)
        v_528 = self.pnnx_unique_155(v_527)
        v_529 = (v_493 + v_528)
        v_530 = self.transformer_layers_3_self_attn_q_proj(v_462)
        v_531 = self.transformer_layers_3_self_attn_k_proj(v_462)
        v_532 = self.transformer_layers_3_self_attn_v_proj(v_462)
        v_533 = v_530.view(1, 36, 60, 128)
        v_534 = v_531.view(1, 36, 60, 128)
        v_535 = v_532.view(1, 36, 60, 128)
        v_536 = torch.permute(input=v_533, dims=(0,3,1,2))
        v_537 = model.gmflow.utils.split_feature(v_536)
        v_538 = torch.permute(input=v_534, dims=(0,3,1,2))
        v_539 = model.gmflow.utils.split_feature(v_538)
        v_540 = torch.permute(input=v_535, dims=(0,3,1,2))
        v_541 = model.gmflow.utils.split_feature(v_540)
        v_542 = torch.permute(input=v_539, dims=(0,1,3,4,2))
        v_543 = v_542.view(1, 4, -1, 128)
        v_544 = torch.permute(input=v_537, dims=(0,1,3,4,2))
        v_545 = v_544.view(1, 4, -1, 128)
        v_546 = torch.permute(input=v_543, dims=(0,1,3,2))
        v_547 = torch.matmul(input=v_545, other=v_546)
        v_548 = (v_547 / 11.313708)
        v_549 = F.softmax(input=v_548, dim=-1)
        v_550 = torch.permute(input=v_541, dims=(0,1,3,4,2))
        v_551 = v_550.view(1, 4, -1, 128)
        v_552 = torch.matmul(input=v_549, other=v_551)
        v_553 = v_552.view(1, 4, 18, 30, 128)
        v_554 = torch.permute(input=v_553, dims=(0,1,4,2,3))
        v_555 = model.gmflow.utils.merge_splits(v_554)
        v_556 = torch.permute(input=v_555, dims=(0,2,3,1))
        v_557 = v_556.view(1, -1, 128)
        v_558 = self.transformer_layers_3_self_attn_merge(v_557)
        v_559 = self.transformer_layers_3_self_attn_norm1(v_558)
        v_560 = (v_462 + v_559)
        v_561 = self.transformer_layers_3_cross_attn_ffn_q_proj(v_560)
        v_562 = self.transformer_layers_3_cross_attn_ffn_k_proj(v_529)
        v_563 = self.transformer_layers_3_cross_attn_ffn_v_proj(v_529)
        v_564 = v_561.view(1, 36, 60, 128)
        v_565 = v_562.view(1, 36, 60, 128)
        v_566 = v_563.view(1, 36, 60, 128)
        v_567 = torch.permute(input=v_564, dims=(0,3,1,2))
        v_568 = model.gmflow.utils.split_feature(v_567)
        v_569 = torch.permute(input=v_565, dims=(0,3,1,2))
        v_570 = model.gmflow.utils.split_feature(v_569)
        v_571 = torch.permute(input=v_566, dims=(0,3,1,2))
        v_572 = model.gmflow.utils.split_feature(v_571)
        v_573 = torch.permute(input=v_570, dims=(0,1,3,4,2))
        v_574 = v_573.view(1, 4, -1, 128)
        v_575 = torch.permute(input=v_568, dims=(0,1,3,4,2))
        v_576 = v_575.view(1, 4, -1, 128)
        v_577 = torch.permute(input=v_574, dims=(0,1,3,2))
        v_578 = torch.matmul(input=v_576, other=v_577)
        v_579 = (v_578 / 11.313708)
        v_580 = F.softmax(input=v_579, dim=-1)
        v_581 = torch.permute(input=v_572, dims=(0,1,3,4,2))
        v_582 = v_581.view(1, 4, -1, 128)
        v_583 = torch.matmul(input=v_580, other=v_582)
        v_584 = v_583.view(1, 4, 18, 30, 128)
        v_585 = torch.permute(input=v_584, dims=(0,1,4,2,3))
        v_586 = model.gmflow.utils.merge_splits(v_585)
        v_587 = torch.permute(input=v_586, dims=(0,2,3,1))
        v_588 = v_587.view(1, -1, 128)
        v_589 = self.transformer_layers_3_cross_attn_ffn_merge(v_588)
        v_590 = self.transformer_layers_3_cross_attn_ffn_norm1(v_589)
        v_591 = torch.cat((v_560, v_590), dim=-1)
        v_592 = self.transformer_layers_3_cross_attn_ffn_mlp_0(v_591)
        v_593 = self.transformer_layers_3_cross_attn_ffn_mlp_1(v_592)
        v_594 = self.transformer_layers_3_cross_attn_ffn_mlp_2(v_593)
        v_595 = self.transformer_layers_3_cross_attn_ffn_norm2(v_594)
        v_596 = (v_560 + v_595)
        v_597 = self.pnnx_unique_164(v_529)
        v_598 = self.pnnx_unique_165(v_529)
        v_599 = self.pnnx_unique_166(v_529)
        v_600 = v_597.view(1, 36, 60, 128)
        v_601 = v_598.view(1, 36, 60, 128)
        v_602 = v_599.view(1, 36, 60, 128)
        v_603 = torch.permute(input=v_600, dims=(0,3,1,2))
        v_604 = model.gmflow.utils.split_feature(v_603)
        v_605 = torch.permute(input=v_601, dims=(0,3,1,2))
        v_606 = model.gmflow.utils.split_feature(v_605)
        v_607 = torch.permute(input=v_602, dims=(0,3,1,2))
        v_608 = model.gmflow.utils.split_feature(v_607)
        v_609 = torch.permute(input=v_606, dims=(0,1,3,4,2))
        v_610 = v_609.view(1, 4, -1, 128)
        v_611 = torch.permute(input=v_604, dims=(0,1,3,4,2))
        v_612 = v_611.view(1, 4, -1, 128)
        v_613 = torch.permute(input=v_610, dims=(0,1,3,2))
        v_614 = torch.matmul(input=v_612, other=v_613)
        v_615 = (v_614 / 11.313708)
        v_616 = F.softmax(input=v_615, dim=-1)
        v_617 = torch.permute(input=v_608, dims=(0,1,3,4,2))
        v_618 = v_617.view(1, 4, -1, 128)
        v_619 = torch.matmul(input=v_616, other=v_618)
        v_620 = v_619.view(1, 4, 18, 30, 128)
        v_621 = torch.permute(input=v_620, dims=(0,1,4,2,3))
        v_622 = model.gmflow.utils.merge_splits(v_621)
        v_623 = torch.permute(input=v_622, dims=(0,2,3,1))
        v_624 = v_623.view(1, -1, 128)
        v_625 = self.pnnx_unique_171(v_624)
        v_626 = self.pnnx_unique_172(v_625)
        v_627 = (v_529 + v_626)
        v_628 = self.pnnx_unique_173(v_627)
        v_629 = self.pnnx_unique_174(v_462)
        v_630 = self.pnnx_unique_175(v_462)
        v_631 = v_628.view(1, 36, 60, 128)
        v_632 = v_629.view(1, 36, 60, 128)
        v_633 = v_630.view(1, 36, 60, 128)
        v_634 = torch.permute(input=v_631, dims=(0,3,1,2))
        v_635 = model.gmflow.utils.split_feature(v_634)
        v_636 = torch.permute(input=v_632, dims=(0,3,1,2))
        v_637 = model.gmflow.utils.split_feature(v_636)
        v_638 = torch.permute(input=v_633, dims=(0,3,1,2))
        v_639 = model.gmflow.utils.split_feature(v_638)
        v_640 = torch.permute(input=v_637, dims=(0,1,3,4,2))
        v_641 = v_640.view(1, 4, -1, 128)
        v_642 = torch.permute(input=v_635, dims=(0,1,3,4,2))
        v_643 = v_642.view(1, 4, -1, 128)
        v_644 = torch.permute(input=v_641, dims=(0,1,3,2))
        v_645 = torch.matmul(input=v_643, other=v_644)
        v_646 = (v_645 / 11.313708)
        v_647 = F.softmax(input=v_646, dim=-1)
        v_648 = torch.permute(input=v_639, dims=(0,1,3,4,2))
        v_649 = v_648.view(1, 4, -1, 128)
        v_650 = torch.matmul(input=v_647, other=v_649)
        v_651 = v_650.view(1, 4, 18, 30, 128)
        v_652 = torch.permute(input=v_651, dims=(0,1,4,2,3))
        v_653 = model.gmflow.utils.merge_splits(v_652)
        v_654 = torch.permute(input=v_653, dims=(0,2,3,1))
        v_655 = v_654.view(1, -1, 128)
        v_656 = self.pnnx_unique_180(v_655)
        v_657 = self.pnnx_unique_181(v_656)
        v_658 = torch.cat((v_627, v_657), dim=-1)
        v_659 = self.pnnx_unique_182(v_658)
        v_660 = self.pnnx_unique_183(v_659)
        v_661 = self.pnnx_unique_184(v_660)
        v_662 = self.pnnx_unique_185(v_661)
        v_663 = (v_627 + v_662)
        v_664 = self.transformer_layers_4_self_attn_q_proj(v_596)
        v_665 = self.transformer_layers_4_self_attn_k_proj(v_596)
        v_666 = self.transformer_layers_4_self_attn_v_proj(v_596)
        v_667 = v_664.view(1, 36, 60, 128)
        v_668 = v_665.view(1, 36, 60, 128)
        v_669 = v_666.view(1, 36, 60, 128)
        v_670 = torch.permute(input=v_667, dims=(0,3,1,2))
        v_671 = model.gmflow.utils.split_feature(v_670)
        v_672 = torch.permute(input=v_668, dims=(0,3,1,2))
        v_673 = model.gmflow.utils.split_feature(v_672)
        v_674 = torch.permute(input=v_669, dims=(0,3,1,2))
        v_675 = model.gmflow.utils.split_feature(v_674)
        v_676 = torch.permute(input=v_673, dims=(0,1,3,4,2))
        v_677 = v_676.view(1, 4, -1, 128)
        v_678 = torch.permute(input=v_671, dims=(0,1,3,4,2))
        v_679 = v_678.view(1, 4, -1, 128)
        v_680 = torch.permute(input=v_677, dims=(0,1,3,2))
        v_681 = torch.matmul(input=v_679, other=v_680)
        v_682 = (v_681 / 11.313708)
        v_683 = F.softmax(input=v_682, dim=-1)
        v_684 = torch.permute(input=v_675, dims=(0,1,3,4,2))
        v_685 = v_684.view(1, 4, -1, 128)
        v_686 = torch.matmul(input=v_683, other=v_685)
        v_687 = v_686.view(1, 4, 18, 30, 128)
        v_688 = torch.permute(input=v_687, dims=(0,1,4,2,3))
        v_689 = model.gmflow.utils.merge_splits(v_688)
        v_690 = torch.permute(input=v_689, dims=(0,2,3,1))
        v_691 = v_690.view(1, -1, 128)
        v_692 = self.transformer_layers_4_self_attn_merge(v_691)
        v_693 = self.transformer_layers_4_self_attn_norm1(v_692)
        v_694 = (v_596 + v_693)
        v_695 = self.transformer_layers_4_cross_attn_ffn_q_proj(v_694)
        v_696 = self.transformer_layers_4_cross_attn_ffn_k_proj(v_663)
        v_697 = self.transformer_layers_4_cross_attn_ffn_v_proj(v_663)
        v_698 = v_695.view(1, 36, 60, 128)
        v_699 = v_696.view(1, 36, 60, 128)
        v_700 = v_697.view(1, 36, 60, 128)
        v_701 = torch.permute(input=v_698, dims=(0,3,1,2))
        v_702 = model.gmflow.utils.split_feature(v_701)
        v_703 = torch.permute(input=v_699, dims=(0,3,1,2))
        v_704 = model.gmflow.utils.split_feature(v_703)
        v_705 = torch.permute(input=v_700, dims=(0,3,1,2))
        v_706 = model.gmflow.utils.split_feature(v_705)
        v_707 = torch.permute(input=v_704, dims=(0,1,3,4,2))
        v_708 = v_707.view(1, 4, -1, 128)
        v_709 = torch.permute(input=v_702, dims=(0,1,3,4,2))
        v_710 = v_709.view(1, 4, -1, 128)
        v_711 = torch.permute(input=v_708, dims=(0,1,3,2))
        v_712 = torch.matmul(input=v_710, other=v_711)
        v_713 = (v_712 / 11.313708)
        v_714 = F.softmax(input=v_713, dim=-1)
        v_715 = torch.permute(input=v_706, dims=(0,1,3,4,2))
        v_716 = v_715.view(1, 4, -1, 128)
        v_717 = torch.matmul(input=v_714, other=v_716)
        v_718 = v_717.view(1, 4, 18, 30, 128)
        v_719 = torch.permute(input=v_718, dims=(0,1,4,2,3))
        v_720 = model.gmflow.utils.merge_splits(v_719)
        v_721 = torch.permute(input=v_720, dims=(0,2,3,1))
        v_722 = v_721.view(1, -1, 128)
        v_723 = self.transformer_layers_4_cross_attn_ffn_merge(v_722)
        v_724 = self.transformer_layers_4_cross_attn_ffn_norm1(v_723)
        v_725 = torch.cat((v_694, v_724), dim=-1)
        v_726 = self.transformer_layers_4_cross_attn_ffn_mlp_0(v_725)
        v_727 = self.transformer_layers_4_cross_attn_ffn_mlp_1(v_726)
        v_728 = self.transformer_layers_4_cross_attn_ffn_mlp_2(v_727)
        v_729 = self.transformer_layers_4_cross_attn_ffn_norm2(v_728)
        v_730 = (v_694 + v_729)
        v_731 = self.pnnx_unique_194(v_663)
        v_732 = self.pnnx_unique_195(v_663)
        v_733 = self.pnnx_unique_196(v_663)
        v_734 = v_731.view(1, 36, 60, 128)
        v_735 = v_732.view(1, 36, 60, 128)
        v_736 = v_733.view(1, 36, 60, 128)
        v_737 = torch.permute(input=v_734, dims=(0,3,1,2))
        v_738 = model.gmflow.utils.split_feature(v_737)
        v_739 = torch.permute(input=v_735, dims=(0,3,1,2))
        v_740 = model.gmflow.utils.split_feature(v_739)
        v_741 = torch.permute(input=v_736, dims=(0,3,1,2))
        v_742 = model.gmflow.utils.split_feature(v_741)
        v_743 = torch.permute(input=v_740, dims=(0,1,3,4,2))
        v_744 = v_743.view(1, 4, -1, 128)
        v_745 = torch.permute(input=v_738, dims=(0,1,3,4,2))
        v_746 = v_745.view(1, 4, -1, 128)
        v_747 = torch.permute(input=v_744, dims=(0,1,3,2))
        v_748 = torch.matmul(input=v_746, other=v_747)
        v_749 = (v_748 / 11.313708)
        v_750 = F.softmax(input=v_749, dim=-1)
        v_751 = torch.permute(input=v_742, dims=(0,1,3,4,2))
        v_752 = v_751.view(1, 4, -1, 128)
        v_753 = torch.matmul(input=v_750, other=v_752)
        v_754 = v_753.view(1, 4, 18, 30, 128)
        v_755 = torch.permute(input=v_754, dims=(0,1,4,2,3))
        v_756 = model.gmflow.utils.merge_splits(v_755)
        v_757 = torch.permute(input=v_756, dims=(0,2,3,1))
        v_758 = v_757.view(1, -1, 128)
        v_759 = self.pnnx_unique_201(v_758)
        v_760 = self.pnnx_unique_202(v_759)
        v_761 = (v_663 + v_760)
        v_762 = self.pnnx_unique_203(v_761)
        v_763 = self.pnnx_unique_204(v_596)
        v_764 = self.pnnx_unique_205(v_596)
        v_765 = v_762.view(1, 36, 60, 128)
        v_766 = v_763.view(1, 36, 60, 128)
        v_767 = v_764.view(1, 36, 60, 128)
        v_768 = torch.permute(input=v_765, dims=(0,3,1,2))
        v_769 = model.gmflow.utils.split_feature(v_768)
        v_770 = torch.permute(input=v_766, dims=(0,3,1,2))
        v_771 = model.gmflow.utils.split_feature(v_770)
        v_772 = torch.permute(input=v_767, dims=(0,3,1,2))
        v_773 = model.gmflow.utils.split_feature(v_772)
        v_774 = torch.permute(input=v_771, dims=(0,1,3,4,2))
        v_775 = v_774.view(1, 4, -1, 128)
        v_776 = torch.permute(input=v_769, dims=(0,1,3,4,2))
        v_777 = v_776.view(1, 4, -1, 128)
        v_778 = torch.permute(input=v_775, dims=(0,1,3,2))
        v_779 = torch.matmul(input=v_777, other=v_778)
        v_780 = (v_779 / 11.313708)
        v_781 = F.softmax(input=v_780, dim=-1)
        v_782 = torch.permute(input=v_773, dims=(0,1,3,4,2))
        v_783 = v_782.view(1, 4, -1, 128)
        v_784 = torch.matmul(input=v_781, other=v_783)
        v_785 = v_784.view(1, 4, 18, 30, 128)
        v_786 = torch.permute(input=v_785, dims=(0,1,4,2,3))
        v_787 = model.gmflow.utils.merge_splits(v_786)
        v_788 = torch.permute(input=v_787, dims=(0,2,3,1))
        v_789 = v_788.view(1, -1, 128)
        v_790 = self.pnnx_unique_210(v_789)
        v_791 = self.pnnx_unique_211(v_790)
        v_792 = torch.cat((v_761, v_791), dim=-1)
        v_793 = self.pnnx_unique_212(v_792)
        v_794 = self.pnnx_unique_213(v_793)
        v_795 = self.pnnx_unique_214(v_794)
        v_796 = self.pnnx_unique_215(v_795)
        v_797 = (v_761 + v_796)
        v_798 = self.transformer_layers_5_self_attn_q_proj(v_730)
        v_799 = self.transformer_layers_5_self_attn_k_proj(v_730)
        v_800 = self.transformer_layers_5_self_attn_v_proj(v_730)
        v_801 = v_798.view(1, 36, 60, 128)
        v_802 = v_799.view(1, 36, 60, 128)
        v_803 = v_800.view(1, 36, 60, 128)
        v_804 = torch.permute(input=v_801, dims=(0,3,1,2))
        v_805 = model.gmflow.utils.split_feature(v_804)
        v_806 = torch.permute(input=v_802, dims=(0,3,1,2))
        v_807 = model.gmflow.utils.split_feature(v_806)
        v_808 = torch.permute(input=v_803, dims=(0,3,1,2))
        v_809 = model.gmflow.utils.split_feature(v_808)
        v_810 = torch.permute(input=v_807, dims=(0,1,3,4,2))
        v_811 = v_810.view(1, 4, -1, 128)
        v_812 = torch.permute(input=v_805, dims=(0,1,3,4,2))
        v_813 = v_812.view(1, 4, -1, 128)
        v_814 = torch.permute(input=v_811, dims=(0,1,3,2))
        v_815 = torch.matmul(input=v_813, other=v_814)
        v_816 = (v_815 / 11.313708)
        v_817 = F.softmax(input=v_816, dim=-1)
        v_818 = torch.permute(input=v_809, dims=(0,1,3,4,2))
        v_819 = v_818.view(1, 4, -1, 128)
        v_820 = torch.matmul(input=v_817, other=v_819)
        v_821 = v_820.view(1, 4, 18, 30, 128)
        v_822 = torch.permute(input=v_821, dims=(0,1,4,2,3))
        v_823 = model.gmflow.utils.merge_splits(v_822)
        v_824 = torch.permute(input=v_823, dims=(0,2,3,1))
        v_825 = v_824.view(1, -1, 128)
        v_826 = self.transformer_layers_5_self_attn_merge(v_825)
        v_827 = self.transformer_layers_5_self_attn_norm1(v_826)
        v_828 = (v_730 + v_827)
        v_829 = self.transformer_layers_5_cross_attn_ffn_q_proj(v_828)
        v_830 = self.transformer_layers_5_cross_attn_ffn_k_proj(v_797)
        v_831 = self.transformer_layers_5_cross_attn_ffn_v_proj(v_797)
        v_832 = v_829.view(1, 36, 60, 128)
        v_833 = v_830.view(1, 36, 60, 128)
        v_834 = v_831.view(1, 36, 60, 128)
        v_835 = torch.permute(input=v_832, dims=(0,3,1,2))
        v_836 = model.gmflow.utils.split_feature(v_835)
        v_837 = torch.permute(input=v_833, dims=(0,3,1,2))
        v_838 = model.gmflow.utils.split_feature(v_837)
        v_839 = torch.permute(input=v_834, dims=(0,3,1,2))
        v_840 = model.gmflow.utils.split_feature(v_839)
        v_841 = torch.permute(input=v_838, dims=(0,1,3,4,2))
        v_842 = v_841.view(1, 4, -1, 128)
        v_843 = torch.permute(input=v_836, dims=(0,1,3,4,2))
        v_844 = v_843.view(1, 4, -1, 128)
        v_845 = torch.permute(input=v_842, dims=(0,1,3,2))
        v_846 = torch.matmul(input=v_844, other=v_845)
        v_847 = (v_846 / 11.313708)
        v_848 = F.softmax(input=v_847, dim=-1)
        v_849 = torch.permute(input=v_840, dims=(0,1,3,4,2))
        v_850 = v_849.view(1, 4, -1, 128)
        v_851 = torch.matmul(input=v_848, other=v_850)
        v_852 = v_851.view(1, 4, 18, 30, 128)
        v_853 = torch.permute(input=v_852, dims=(0,1,4,2,3))
        v_854 = model.gmflow.utils.merge_splits(v_853)
        v_855 = torch.permute(input=v_854, dims=(0,2,3,1))
        v_856 = v_855.view(1, -1, 128)
        v_857 = self.transformer_layers_5_cross_attn_ffn_merge(v_856)
        v_858 = self.transformer_layers_5_cross_attn_ffn_norm1(v_857)
        v_859 = torch.cat((v_828, v_858), dim=-1)
        v_860 = self.transformer_layers_5_cross_attn_ffn_mlp_0(v_859)
        v_861 = self.transformer_layers_5_cross_attn_ffn_mlp_1(v_860)
        v_862 = self.transformer_layers_5_cross_attn_ffn_mlp_2(v_861)
        v_863 = self.transformer_layers_5_cross_attn_ffn_norm2(v_862)
        v_864 = (v_828 + v_863)
        v_865 = self.pnnx_unique_224(v_797)
        v_866 = self.pnnx_unique_225(v_797)
        v_867 = self.pnnx_unique_226(v_797)
        v_868 = v_865.view(1, 36, 60, 128)
        v_869 = v_866.view(1, 36, 60, 128)
        v_870 = v_867.view(1, 36, 60, 128)
        v_871 = torch.permute(input=v_868, dims=(0,3,1,2))
        v_872 = model.gmflow.utils.split_feature(v_871)
        v_873 = torch.permute(input=v_869, dims=(0,3,1,2))
        v_874 = model.gmflow.utils.split_feature(v_873)
        v_875 = torch.permute(input=v_870, dims=(0,3,1,2))
        v_876 = model.gmflow.utils.split_feature(v_875)
        v_877 = torch.permute(input=v_874, dims=(0,1,3,4,2))
        v_878 = v_877.view(1, 4, -1, 128)
        v_879 = torch.permute(input=v_872, dims=(0,1,3,4,2))
        v_880 = v_879.view(1, 4, -1, 128)
        v_881 = torch.permute(input=v_878, dims=(0,1,3,2))
        v_882 = torch.matmul(input=v_880, other=v_881)
        v_883 = (v_882 / 11.313708)
        v_884 = F.softmax(input=v_883, dim=-1)
        v_885 = torch.permute(input=v_876, dims=(0,1,3,4,2))
        v_886 = v_885.view(1, 4, -1, 128)
        v_887 = torch.matmul(input=v_884, other=v_886)
        v_888 = v_887.view(1, 4, 18, 30, 128)
        v_889 = torch.permute(input=v_888, dims=(0,1,4,2,3))
        v_890 = model.gmflow.utils.merge_splits(v_889)
        v_891 = torch.permute(input=v_890, dims=(0,2,3,1))
        v_892 = v_891.view(1, -1, 128)
        v_893 = self.pnnx_unique_231(v_892)
        v_894 = self.pnnx_unique_232(v_893)
        v_895 = (v_797 + v_894)
        v_896 = self.pnnx_unique_233(v_895)
        v_897 = self.pnnx_unique_234(v_730)
        v_898 = self.pnnx_unique_235(v_730)
        v_899 = v_896.view(1, 36, 60, 128)
        v_900 = v_897.view(1, 36, 60, 128)
        v_901 = v_898.view(1, 36, 60, 128)
        v_902 = torch.permute(input=v_899, dims=(0,3,1,2))
        v_903 = model.gmflow.utils.split_feature(v_902)
        v_904 = torch.permute(input=v_900, dims=(0,3,1,2))
        v_905 = model.gmflow.utils.split_feature(v_904)
        v_906 = torch.permute(input=v_901, dims=(0,3,1,2))
        v_907 = model.gmflow.utils.split_feature(v_906)
        v_908 = torch.permute(input=v_905, dims=(0,1,3,4,2))
        v_909 = v_908.view(1, 4, -1, 128)
        v_910 = torch.permute(input=v_903, dims=(0,1,3,4,2))
        v_911 = v_910.view(1, 4, -1, 128)
        v_912 = torch.permute(input=v_909, dims=(0,1,3,2))
        v_913 = torch.matmul(input=v_911, other=v_912)
        v_914 = (v_913 / 11.313708)
        v_915 = F.softmax(input=v_914, dim=-1)
        v_916 = torch.permute(input=v_907, dims=(0,1,3,4,2))
        v_917 = v_916.view(1, 4, -1, 128)
        v_918 = torch.matmul(input=v_915, other=v_917)
        v_919 = v_918.view(1, 4, 18, 30, 128)
        v_920 = torch.permute(input=v_919, dims=(0,1,4,2,3))
        v_921 = model.gmflow.utils.merge_splits(v_920)
        v_922 = torch.permute(input=v_921, dims=(0,2,3,1))
        v_923 = v_922.view(1, -1, 128)
        v_924 = self.pnnx_unique_240(v_923)
        v_925 = self.pnnx_unique_241(v_924)
        v_926 = torch.cat((v_895, v_925), dim=-1)
        v_927 = self.pnnx_unique_242(v_926)
        v_928 = self.pnnx_unique_243(v_927)
        v_929 = self.pnnx_unique_244(v_928)
        v_930 = self.pnnx_unique_245(v_929)
        v_931 = (v_895 + v_930)
        v_932 = v_864.view(1, 36, 60, 128)
        v_933 = v_931.view(1, 36, 60, 128)
        v_934 = torch.permute(input=v_933, dims=(0,3,1,2))
        v_935 = torch.permute(input=v_932, dims=(0,3,1,2))
        v_936 = v_935.contiguous(memory_format=torch.contiguous_format)
        v_937 = v_936.view(1, 128, -1)
        v_938 = torch.permute(input=v_937, dims=(0,2,1))
        v_939 = v_934.reshape(1, 128, -1)
        v_940 = torch.matmul(input=v_938, other=v_939)
        v_941 = v_940.view(1, 36, 60, 36, 60)
        v_942 = (v_941 / 11.313708)
        v_943 = self.pnnx_fold_init_grid_1_pnnx_fold_init_grid_1
        v_944 = v_942.view(1, 2160, 2160)
        v_945 = F.softmax(input=v_944, dim=-1)
        v_946 = self.pnnx_fold_grid_5_pnnx_fold_grid_5
        v_947 = torch.matmul(input=v_945, other=v_946)
        v_948 = v_947.view(1, 36, 60, 2)
        v_949 = torch.permute(input=v_948, dims=(0,3,1,2))
        v_950 = (v_949 - v_943)
        v_951 = v_936.view(1, 128, 2160)
        v_952 = torch.permute(input=v_951, dims=(0,2,1))
        v_953 = self.feature_flow_attn_q_proj(v_952)
        v_954 = self.feature_flow_attn_k_proj(v_953)
        v_955 = v_950.view(1, 2, 2160)
        v_956 = torch.permute(input=v_954, dims=(0,2,1))
        v_957 = torch.matmul(input=v_953, other=v_956)
        v_958 = (v_957 / 11.313708)
        v_959 = F.softmax(input=v_958, dim=-1)
        v_960 = torch.permute(input=v_955, dims=(0,2,1))
        v_961 = torch.matmul(input=v_959, other=v_960)
        v_962 = v_961.view(1, 36, 60, 2)
        v_963 = torch.permute(input=v_962, dims=(0,3,1,2))
        v_964 = F.upsample(input=v_963, align_corners=True, mode='bilinear', scale_factor=(2.000000,2.000000))
        v_965 = (v_964 * 2)
        v_966 = self.pnnx_fold_352_pnnx_fold_352
        v_967 = (v_966 + v_965)
        v_968, v_969 = torch.unbind(v_967, dim=1)
        v_970 = (((v_968 * 2) / 119.000000) - 1)
        v_971 = (((v_969 * 2) / 71.000000) - 1)
        v_972 = torch.unsqueeze(input=v_971, dim=3)
        v_973 = torch.unsqueeze(input=v_970, dim=3)
        v_974 = self.conv2d_1(v_57)
        v_975 = model.gmflow.utils.split_feature(v_974)
        v_976 = torch.cat((v_973, v_972), dim=3)
        v_977 = self.conv2d_3(v_113)
        v_978 = F.grid_sample(input=v_977, grid=v_976, align_corners=True, mode='bilinear', padding_mode='zeros')
        v_979 = model.gmflow.utils.split_feature(v_978)
        v_980 = self.pnnx_fold_position0_1_pnnx_fold_position0_1
        v_981 = self.pnnx_fold_position0_1_1_pnnx_fold_position0_1
        v_982 = (v_975 + v_980)
        v_983 = (v_979 + v_981)
        v_984 = model.gmflow.utils.merge_splits(v_982)
        v_985 = model.gmflow.utils.merge_splits(v_983)
        v_986 = torch.flatten(input=v_984, end_dim=-1, start_dim=2)
        v_987 = torch.flatten(input=v_985, end_dim=-1, start_dim=2)
        v_988 = torch.permute(input=v_986, dims=(0,2,1))
        v_989 = self.pnnx_unique_251(v_988)
        v_990 = self.pnnx_unique_252(v_988)
        v_991 = self.pnnx_unique_253(v_988)
        v_992 = v_989.view(1, 72, 120, 128)
        v_993 = v_990.view(1, 72, 120, 128)
        v_994 = v_991.view(1, 72, 120, 128)
        v_995 = torch.permute(input=v_992, dims=(0,3,1,2))
        v_996 = model.gmflow.utils.split_feature(v_995)
        v_997 = torch.permute(input=v_993, dims=(0,3,1,2))
        v_998 = model.gmflow.utils.split_feature(v_997)
        v_999 = torch.permute(input=v_994, dims=(0,3,1,2))
        v_1000 = model.gmflow.utils.split_feature(v_999)
        v_1001 = torch.permute(input=v_998, dims=(0,1,3,4,2))
        v_1002 = v_1001.view(1, 64, -1, 128)
        v_1003 = torch.permute(input=v_996, dims=(0,1,3,4,2))
        v_1004 = v_1003.view(1, 64, -1, 128)
        v_1005 = torch.permute(input=v_1002, dims=(0,1,3,2))
        v_1006 = torch.matmul(input=v_1004, other=v_1005)
        v_1007 = (v_1006 / 11.313708)
        v_1008 = F.softmax(input=v_1007, dim=-1)
        v_1009 = torch.permute(input=v_1000, dims=(0,1,3,4,2))
        v_1010 = v_1009.view(1, 64, -1, 128)
        v_1011 = torch.matmul(input=v_1008, other=v_1010)
        v_1012 = v_1011.view(1, 64, 9, 15, 128)
        v_1013 = torch.permute(input=v_1012, dims=(0,1,4,2,3))
        v_1014 = model.gmflow.utils.merge_splits(v_1013)
        v_1015 = torch.permute(input=v_1014, dims=(0,2,3,1))
        v_1016 = v_1015.view(1, -1, 128)
        v_1017 = self.pnnx_unique_258(v_1016)
        v_1018 = self.pnnx_unique_259(v_1017)
        v_1019 = (v_988 + v_1018)
        v_1020 = self.pnnx_unique_260(v_1019)
        v_1021 = torch.permute(input=v_987, dims=(0,2,1))
        v_1022 = self.pnnx_unique_261(v_1021)
        v_1023 = self.pnnx_unique_262(v_1021)
        v_1024 = v_1020.view(1, 72, 120, 128)
        v_1025 = v_1022.view(1, 72, 120, 128)
        v_1026 = v_1023.view(1, 72, 120, 128)
        v_1027 = torch.permute(input=v_1024, dims=(0,3,1,2))
        v_1028 = model.gmflow.utils.split_feature(v_1027)
        v_1029 = torch.permute(input=v_1025, dims=(0,3,1,2))
        v_1030 = model.gmflow.utils.split_feature(v_1029)
        v_1031 = torch.permute(input=v_1026, dims=(0,3,1,2))
        v_1032 = model.gmflow.utils.split_feature(v_1031)
        v_1033 = torch.permute(input=v_1030, dims=(0,1,3,4,2))
        v_1034 = v_1033.view(1, 64, -1, 128)
        v_1035 = torch.permute(input=v_1028, dims=(0,1,3,4,2))
        v_1036 = v_1035.view(1, 64, -1, 128)
        v_1037 = torch.permute(input=v_1034, dims=(0,1,3,2))
        v_1038 = torch.matmul(input=v_1036, other=v_1037)
        v_1039 = (v_1038 / 11.313708)
        v_1040 = F.softmax(input=v_1039, dim=-1)
        v_1041 = torch.permute(input=v_1032, dims=(0,1,3,4,2))
        v_1042 = v_1041.view(1, 64, -1, 128)
        v_1043 = torch.matmul(input=v_1040, other=v_1042)
        v_1044 = v_1043.view(1, 64, 9, 15, 128)
        v_1045 = torch.permute(input=v_1044, dims=(0,1,4,2,3))
        v_1046 = model.gmflow.utils.merge_splits(v_1045)
        v_1047 = torch.permute(input=v_1046, dims=(0,2,3,1))
        v_1048 = v_1047.view(1, -1, 128)
        v_1049 = self.pnnx_unique_267(v_1048)
        v_1050 = self.pnnx_unique_268(v_1049)
        v_1051 = torch.cat((v_1019, v_1050), dim=-1)
        v_1052 = self.pnnx_unique_269(v_1051)
        v_1053 = self.pnnx_unique_270(v_1052)
        v_1054 = self.pnnx_unique_271(v_1053)
        v_1055 = self.pnnx_unique_272(v_1054)
        v_1056 = (v_1019 + v_1055)
        v_1057 = self.pnnx_unique_273(v_1021)
        v_1058 = self.pnnx_unique_274(v_1021)
        v_1059 = self.pnnx_unique_275(v_1021)
        v_1060 = v_1057.view(1, 72, 120, 128)
        v_1061 = v_1058.view(1, 72, 120, 128)
        v_1062 = v_1059.view(1, 72, 120, 128)
        v_1063 = torch.permute(input=v_1060, dims=(0,3,1,2))
        v_1064 = model.gmflow.utils.split_feature(v_1063)
        v_1065 = torch.permute(input=v_1061, dims=(0,3,1,2))
        v_1066 = model.gmflow.utils.split_feature(v_1065)
        v_1067 = torch.permute(input=v_1062, dims=(0,3,1,2))
        v_1068 = model.gmflow.utils.split_feature(v_1067)
        v_1069 = torch.permute(input=v_1066, dims=(0,1,3,4,2))
        v_1070 = v_1069.view(1, 64, -1, 128)
        v_1071 = torch.permute(input=v_1064, dims=(0,1,3,4,2))
        v_1072 = v_1071.view(1, 64, -1, 128)
        v_1073 = torch.permute(input=v_1070, dims=(0,1,3,2))
        v_1074 = torch.matmul(input=v_1072, other=v_1073)
        v_1075 = (v_1074 / 11.313708)
        v_1076 = F.softmax(input=v_1075, dim=-1)
        v_1077 = torch.permute(input=v_1068, dims=(0,1,3,4,2))
        v_1078 = v_1077.view(1, 64, -1, 128)
        v_1079 = torch.matmul(input=v_1076, other=v_1078)
        v_1080 = v_1079.view(1, 64, 9, 15, 128)
        v_1081 = torch.permute(input=v_1080, dims=(0,1,4,2,3))
        v_1082 = model.gmflow.utils.merge_splits(v_1081)
        v_1083 = torch.permute(input=v_1082, dims=(0,2,3,1))
        v_1084 = v_1083.view(1, -1, 128)
        v_1085 = self.pnnx_unique_280(v_1084)
        v_1086 = self.pnnx_unique_281(v_1085)
        v_1087 = (v_1021 + v_1086)
        v_1088 = self.pnnx_unique_282(v_1087)
        v_1089 = self.pnnx_unique_283(v_988)
        v_1090 = self.pnnx_unique_284(v_988)
        v_1091 = v_1088.view(1, 72, 120, 128)
        v_1092 = v_1089.view(1, 72, 120, 128)
        v_1093 = v_1090.view(1, 72, 120, 128)
        v_1094 = torch.permute(input=v_1091, dims=(0,3,1,2))
        v_1095 = model.gmflow.utils.split_feature(v_1094)
        v_1096 = torch.permute(input=v_1092, dims=(0,3,1,2))
        v_1097 = model.gmflow.utils.split_feature(v_1096)
        v_1098 = torch.permute(input=v_1093, dims=(0,3,1,2))
        v_1099 = model.gmflow.utils.split_feature(v_1098)
        v_1100 = torch.permute(input=v_1097, dims=(0,1,3,4,2))
        v_1101 = v_1100.view(1, 64, -1, 128)
        v_1102 = torch.permute(input=v_1095, dims=(0,1,3,4,2))
        v_1103 = v_1102.view(1, 64, -1, 128)
        v_1104 = torch.permute(input=v_1101, dims=(0,1,3,2))
        v_1105 = torch.matmul(input=v_1103, other=v_1104)
        v_1106 = (v_1105 / 11.313708)
        v_1107 = F.softmax(input=v_1106, dim=-1)
        v_1108 = torch.permute(input=v_1099, dims=(0,1,3,4,2))
        v_1109 = v_1108.view(1, 64, -1, 128)
        v_1110 = torch.matmul(input=v_1107, other=v_1109)
        v_1111 = v_1110.view(1, 64, 9, 15, 128)
        v_1112 = torch.permute(input=v_1111, dims=(0,1,4,2,3))
        v_1113 = model.gmflow.utils.merge_splits(v_1112)
        v_1114 = torch.permute(input=v_1113, dims=(0,2,3,1))
        v_1115 = v_1114.view(1, -1, 128)
        v_1116 = self.pnnx_unique_289(v_1115)
        v_1117 = self.pnnx_unique_290(v_1116)
        v_1118 = torch.cat((v_1087, v_1117), dim=-1)
        v_1119 = self.pnnx_unique_291(v_1118)
        v_1120 = self.pnnx_unique_292(v_1119)
        v_1121 = self.pnnx_unique_293(v_1120)
        v_1122 = self.pnnx_unique_294(v_1121)
        v_1123 = (v_1087 + v_1122)
        v_1124 = self.pnnx_unique_295(v_1056)
        v_1125 = self.pnnx_unique_296(v_1056)
        v_1126 = self.pnnx_unique_297(v_1056)
        v_1127 = v_1124.view(1, 72, 120, 128)
        v_1128 = v_1125.view(1, 72, 120, 128)
        v_1129 = v_1126.view(1, 72, 120, 128)
        v_1130 = torch.permute(input=v_1127, dims=(0,3,1,2))
        v_1131 = model.gmflow.utils.split_feature(v_1130)
        v_1132 = torch.permute(input=v_1128, dims=(0,3,1,2))
        v_1133 = model.gmflow.utils.split_feature(v_1132)
        v_1134 = torch.permute(input=v_1129, dims=(0,3,1,2))
        v_1135 = model.gmflow.utils.split_feature(v_1134)
        v_1136 = torch.permute(input=v_1133, dims=(0,1,3,4,2))
        v_1137 = v_1136.view(1, 64, -1, 128)
        v_1138 = torch.permute(input=v_1131, dims=(0,1,3,4,2))
        v_1139 = v_1138.view(1, 64, -1, 128)
        v_1140 = torch.permute(input=v_1137, dims=(0,1,3,2))
        v_1141 = torch.matmul(input=v_1139, other=v_1140)
        v_1142 = (v_1141 / 11.313708)
        v_1143 = F.softmax(input=v_1142, dim=-1)
        v_1144 = torch.permute(input=v_1135, dims=(0,1,3,4,2))
        v_1145 = v_1144.view(1, 64, -1, 128)
        v_1146 = torch.matmul(input=v_1143, other=v_1145)
        v_1147 = v_1146.view(1, 64, 9, 15, 128)
        v_1148 = torch.permute(input=v_1147, dims=(0,1,4,2,3))
        v_1149 = model.gmflow.utils.merge_splits(v_1148)
        v_1150 = torch.permute(input=v_1149, dims=(0,2,3,1))
        v_1151 = v_1150.view(1, -1, 128)
        v_1152 = self.pnnx_unique_302(v_1151)
        v_1153 = self.pnnx_unique_303(v_1152)
        v_1154 = (v_1056 + v_1153)
        v_1155 = self.pnnx_unique_304(v_1154)
        v_1156 = self.pnnx_unique_305(v_1123)
        v_1157 = self.pnnx_unique_306(v_1123)
        v_1158 = v_1155.view(1, 72, 120, 128)
        v_1159 = v_1156.view(1, 72, 120, 128)
        v_1160 = v_1157.view(1, 72, 120, 128)
        v_1161 = torch.permute(input=v_1158, dims=(0,3,1,2))
        v_1162 = model.gmflow.utils.split_feature(v_1161)
        v_1163 = torch.permute(input=v_1159, dims=(0,3,1,2))
        v_1164 = model.gmflow.utils.split_feature(v_1163)
        v_1165 = torch.permute(input=v_1160, dims=(0,3,1,2))
        v_1166 = model.gmflow.utils.split_feature(v_1165)
        v_1167 = torch.permute(input=v_1164, dims=(0,1,3,4,2))
        v_1168 = v_1167.view(1, 64, -1, 128)
        v_1169 = torch.permute(input=v_1162, dims=(0,1,3,4,2))
        v_1170 = v_1169.view(1, 64, -1, 128)
        v_1171 = torch.permute(input=v_1168, dims=(0,1,3,2))
        v_1172 = torch.matmul(input=v_1170, other=v_1171)
        v_1173 = (v_1172 / 11.313708)
        v_1174 = F.softmax(input=v_1173, dim=-1)
        v_1175 = torch.permute(input=v_1166, dims=(0,1,3,4,2))
        v_1176 = v_1175.view(1, 64, -1, 128)
        v_1177 = torch.matmul(input=v_1174, other=v_1176)
        v_1178 = v_1177.view(1, 64, 9, 15, 128)
        v_1179 = torch.permute(input=v_1178, dims=(0,1,4,2,3))
        v_1180 = model.gmflow.utils.merge_splits(v_1179)
        v_1181 = torch.permute(input=v_1180, dims=(0,2,3,1))
        v_1182 = v_1181.view(1, -1, 128)
        v_1183 = self.pnnx_unique_311(v_1182)
        v_1184 = self.pnnx_unique_312(v_1183)
        v_1185 = torch.cat((v_1154, v_1184), dim=-1)
        v_1186 = self.pnnx_unique_313(v_1185)
        v_1187 = self.pnnx_unique_314(v_1186)
        v_1188 = self.pnnx_unique_315(v_1187)
        v_1189 = self.pnnx_unique_316(v_1188)
        v_1190 = (v_1154 + v_1189)
        v_1191 = self.pnnx_unique_317(v_1123)
        v_1192 = self.pnnx_unique_318(v_1123)
        v_1193 = self.pnnx_unique_319(v_1123)
        v_1194 = v_1191.view(1, 72, 120, 128)
        v_1195 = v_1192.view(1, 72, 120, 128)
        v_1196 = v_1193.view(1, 72, 120, 128)
        v_1197 = torch.permute(input=v_1194, dims=(0,3,1,2))
        v_1198 = model.gmflow.utils.split_feature(v_1197)
        v_1199 = torch.permute(input=v_1195, dims=(0,3,1,2))
        v_1200 = model.gmflow.utils.split_feature(v_1199)
        v_1201 = torch.permute(input=v_1196, dims=(0,3,1,2))
        v_1202 = model.gmflow.utils.split_feature(v_1201)
        v_1203 = torch.permute(input=v_1200, dims=(0,1,3,4,2))
        v_1204 = v_1203.view(1, 64, -1, 128)
        v_1205 = torch.permute(input=v_1198, dims=(0,1,3,4,2))
        v_1206 = v_1205.view(1, 64, -1, 128)
        v_1207 = torch.permute(input=v_1204, dims=(0,1,3,2))
        v_1208 = torch.matmul(input=v_1206, other=v_1207)
        v_1209 = (v_1208 / 11.313708)
        v_1210 = F.softmax(input=v_1209, dim=-1)
        v_1211 = torch.permute(input=v_1202, dims=(0,1,3,4,2))
        v_1212 = v_1211.view(1, 64, -1, 128)
        v_1213 = torch.matmul(input=v_1210, other=v_1212)
        v_1214 = v_1213.view(1, 64, 9, 15, 128)
        v_1215 = torch.permute(input=v_1214, dims=(0,1,4,2,3))
        v_1216 = model.gmflow.utils.merge_splits(v_1215)
        v_1217 = torch.permute(input=v_1216, dims=(0,2,3,1))
        v_1218 = v_1217.view(1, -1, 128)
        v_1219 = self.pnnx_unique_324(v_1218)
        v_1220 = self.pnnx_unique_325(v_1219)
        v_1221 = (v_1123 + v_1220)
        v_1222 = self.pnnx_unique_326(v_1221)
        v_1223 = self.pnnx_unique_327(v_1056)
        v_1224 = self.pnnx_unique_328(v_1056)
        v_1225 = v_1222.view(1, 72, 120, 128)
        v_1226 = v_1223.view(1, 72, 120, 128)
        v_1227 = v_1224.view(1, 72, 120, 128)
        v_1228 = torch.permute(input=v_1225, dims=(0,3,1,2))
        v_1229 = model.gmflow.utils.split_feature(v_1228)
        v_1230 = torch.permute(input=v_1226, dims=(0,3,1,2))
        v_1231 = model.gmflow.utils.split_feature(v_1230)
        v_1232 = torch.permute(input=v_1227, dims=(0,3,1,2))
        v_1233 = model.gmflow.utils.split_feature(v_1232)
        v_1234 = torch.permute(input=v_1231, dims=(0,1,3,4,2))
        v_1235 = v_1234.view(1, 64, -1, 128)
        v_1236 = torch.permute(input=v_1229, dims=(0,1,3,4,2))
        v_1237 = v_1236.view(1, 64, -1, 128)
        v_1238 = torch.permute(input=v_1235, dims=(0,1,3,2))
        v_1239 = torch.matmul(input=v_1237, other=v_1238)
        v_1240 = (v_1239 / 11.313708)
        v_1241 = F.softmax(input=v_1240, dim=-1)
        v_1242 = torch.permute(input=v_1233, dims=(0,1,3,4,2))
        v_1243 = v_1242.view(1, 64, -1, 128)
        v_1244 = torch.matmul(input=v_1241, other=v_1243)
        v_1245 = v_1244.view(1, 64, 9, 15, 128)
        v_1246 = torch.permute(input=v_1245, dims=(0,1,4,2,3))
        v_1247 = model.gmflow.utils.merge_splits(v_1246)
        v_1248 = torch.permute(input=v_1247, dims=(0,2,3,1))
        v_1249 = v_1248.view(1, -1, 128)
        v_1250 = self.pnnx_unique_333(v_1249)
        v_1251 = self.pnnx_unique_334(v_1250)
        v_1252 = torch.cat((v_1221, v_1251), dim=-1)
        v_1253 = self.pnnx_unique_335(v_1252)
        v_1254 = self.pnnx_unique_336(v_1253)
        v_1255 = self.pnnx_unique_337(v_1254)
        v_1256 = self.pnnx_unique_338(v_1255)
        v_1257 = (v_1221 + v_1256)
        v_1258 = self.pnnx_unique_339(v_1190)
        v_1259 = self.pnnx_unique_340(v_1190)
        v_1260 = self.pnnx_unique_341(v_1190)
        v_1261 = v_1258.view(1, 72, 120, 128)
        v_1262 = v_1259.view(1, 72, 120, 128)
        v_1263 = v_1260.view(1, 72, 120, 128)
        v_1264 = torch.permute(input=v_1261, dims=(0,3,1,2))
        v_1265 = model.gmflow.utils.split_feature(v_1264)
        v_1266 = torch.permute(input=v_1262, dims=(0,3,1,2))
        v_1267 = model.gmflow.utils.split_feature(v_1266)
        v_1268 = torch.permute(input=v_1263, dims=(0,3,1,2))
        v_1269 = model.gmflow.utils.split_feature(v_1268)
        v_1270 = torch.permute(input=v_1267, dims=(0,1,3,4,2))
        v_1271 = v_1270.view(1, 64, -1, 128)
        v_1272 = torch.permute(input=v_1265, dims=(0,1,3,4,2))
        v_1273 = v_1272.view(1, 64, -1, 128)
        v_1274 = torch.permute(input=v_1271, dims=(0,1,3,2))
        v_1275 = torch.matmul(input=v_1273, other=v_1274)
        v_1276 = (v_1275 / 11.313708)
        v_1277 = F.softmax(input=v_1276, dim=-1)
        v_1278 = torch.permute(input=v_1269, dims=(0,1,3,4,2))
        v_1279 = v_1278.view(1, 64, -1, 128)
        v_1280 = torch.matmul(input=v_1277, other=v_1279)
        v_1281 = v_1280.view(1, 64, 9, 15, 128)
        v_1282 = torch.permute(input=v_1281, dims=(0,1,4,2,3))
        v_1283 = model.gmflow.utils.merge_splits(v_1282)
        v_1284 = torch.permute(input=v_1283, dims=(0,2,3,1))
        v_1285 = v_1284.view(1, -1, 128)
        v_1286 = self.pnnx_unique_346(v_1285)
        v_1287 = self.pnnx_unique_347(v_1286)
        v_1288 = (v_1190 + v_1287)
        v_1289 = self.pnnx_unique_348(v_1288)
        v_1290 = self.pnnx_unique_349(v_1257)
        v_1291 = self.pnnx_unique_350(v_1257)
        v_1292 = v_1289.view(1, 72, 120, 128)
        v_1293 = v_1290.view(1, 72, 120, 128)
        v_1294 = v_1291.view(1, 72, 120, 128)
        v_1295 = torch.permute(input=v_1292, dims=(0,3,1,2))
        v_1296 = model.gmflow.utils.split_feature(v_1295)
        v_1297 = torch.permute(input=v_1293, dims=(0,3,1,2))
        v_1298 = model.gmflow.utils.split_feature(v_1297)
        v_1299 = torch.permute(input=v_1294, dims=(0,3,1,2))
        v_1300 = model.gmflow.utils.split_feature(v_1299)
        v_1301 = torch.permute(input=v_1298, dims=(0,1,3,4,2))
        v_1302 = v_1301.view(1, 64, -1, 128)
        v_1303 = torch.permute(input=v_1296, dims=(0,1,3,4,2))
        v_1304 = v_1303.view(1, 64, -1, 128)
        v_1305 = torch.permute(input=v_1302, dims=(0,1,3,2))
        v_1306 = torch.matmul(input=v_1304, other=v_1305)
        v_1307 = (v_1306 / 11.313708)
        v_1308 = F.softmax(input=v_1307, dim=-1)
        v_1309 = torch.permute(input=v_1300, dims=(0,1,3,4,2))
        v_1310 = v_1309.view(1, 64, -1, 128)
        v_1311 = torch.matmul(input=v_1308, other=v_1310)
        v_1312 = v_1311.view(1, 64, 9, 15, 128)
        v_1313 = torch.permute(input=v_1312, dims=(0,1,4,2,3))
        v_1314 = model.gmflow.utils.merge_splits(v_1313)
        v_1315 = torch.permute(input=v_1314, dims=(0,2,3,1))
        v_1316 = v_1315.view(1, -1, 128)
        v_1317 = self.pnnx_unique_355(v_1316)
        v_1318 = self.pnnx_unique_356(v_1317)
        v_1319 = torch.cat((v_1288, v_1318), dim=-1)
        v_1320 = self.pnnx_unique_357(v_1319)
        v_1321 = self.pnnx_unique_358(v_1320)
        v_1322 = self.pnnx_unique_359(v_1321)
        v_1323 = self.pnnx_unique_360(v_1322)
        v_1324 = (v_1288 + v_1323)
        v_1325 = self.pnnx_unique_361(v_1257)
        v_1326 = self.pnnx_unique_362(v_1257)
        v_1327 = self.pnnx_unique_363(v_1257)
        v_1328 = v_1325.view(1, 72, 120, 128)
        v_1329 = v_1326.view(1, 72, 120, 128)
        v_1330 = v_1327.view(1, 72, 120, 128)
        v_1331 = torch.permute(input=v_1328, dims=(0,3,1,2))
        v_1332 = model.gmflow.utils.split_feature(v_1331)
        v_1333 = torch.permute(input=v_1329, dims=(0,3,1,2))
        v_1334 = model.gmflow.utils.split_feature(v_1333)
        v_1335 = torch.permute(input=v_1330, dims=(0,3,1,2))
        v_1336 = model.gmflow.utils.split_feature(v_1335)
        v_1337 = torch.permute(input=v_1334, dims=(0,1,3,4,2))
        v_1338 = v_1337.view(1, 64, -1, 128)
        v_1339 = torch.permute(input=v_1332, dims=(0,1,3,4,2))
        v_1340 = v_1339.view(1, 64, -1, 128)
        v_1341 = torch.permute(input=v_1338, dims=(0,1,3,2))
        v_1342 = torch.matmul(input=v_1340, other=v_1341)
        v_1343 = (v_1342 / 11.313708)
        v_1344 = F.softmax(input=v_1343, dim=-1)
        v_1345 = torch.permute(input=v_1336, dims=(0,1,3,4,2))
        v_1346 = v_1345.view(1, 64, -1, 128)
        v_1347 = torch.matmul(input=v_1344, other=v_1346)
        v_1348 = v_1347.view(1, 64, 9, 15, 128)
        v_1349 = torch.permute(input=v_1348, dims=(0,1,4,2,3))
        v_1350 = model.gmflow.utils.merge_splits(v_1349)
        v_1351 = torch.permute(input=v_1350, dims=(0,2,3,1))
        v_1352 = v_1351.view(1, -1, 128)
        v_1353 = self.pnnx_unique_368(v_1352)
        v_1354 = self.pnnx_unique_369(v_1353)
        v_1355 = (v_1257 + v_1354)
        v_1356 = self.pnnx_unique_370(v_1355)
        v_1357 = self.pnnx_unique_371(v_1190)
        v_1358 = self.pnnx_unique_372(v_1190)
        v_1359 = v_1356.view(1, 72, 120, 128)
        v_1360 = v_1357.view(1, 72, 120, 128)
        v_1361 = v_1358.view(1, 72, 120, 128)
        v_1362 = torch.permute(input=v_1359, dims=(0,3,1,2))
        v_1363 = model.gmflow.utils.split_feature(v_1362)
        v_1364 = torch.permute(input=v_1360, dims=(0,3,1,2))
        v_1365 = model.gmflow.utils.split_feature(v_1364)
        v_1366 = torch.permute(input=v_1361, dims=(0,3,1,2))
        v_1367 = model.gmflow.utils.split_feature(v_1366)
        v_1368 = torch.permute(input=v_1365, dims=(0,1,3,4,2))
        v_1369 = v_1368.view(1, 64, -1, 128)
        v_1370 = torch.permute(input=v_1363, dims=(0,1,3,4,2))
        v_1371 = v_1370.view(1, 64, -1, 128)
        v_1372 = torch.permute(input=v_1369, dims=(0,1,3,2))
        v_1373 = torch.matmul(input=v_1371, other=v_1372)
        v_1374 = (v_1373 / 11.313708)
        v_1375 = F.softmax(input=v_1374, dim=-1)
        v_1376 = torch.permute(input=v_1367, dims=(0,1,3,4,2))
        v_1377 = v_1376.view(1, 64, -1, 128)
        v_1378 = torch.matmul(input=v_1375, other=v_1377)
        v_1379 = v_1378.view(1, 64, 9, 15, 128)
        v_1380 = torch.permute(input=v_1379, dims=(0,1,4,2,3))
        v_1381 = model.gmflow.utils.merge_splits(v_1380)
        v_1382 = torch.permute(input=v_1381, dims=(0,2,3,1))
        v_1383 = v_1382.view(1, -1, 128)
        v_1384 = self.pnnx_unique_377(v_1383)
        v_1385 = self.pnnx_unique_378(v_1384)
        v_1386 = torch.cat((v_1355, v_1385), dim=-1)
        v_1387 = self.pnnx_unique_379(v_1386)
        v_1388 = self.pnnx_unique_380(v_1387)
        v_1389 = self.pnnx_unique_381(v_1388)
        v_1390 = self.pnnx_unique_382(v_1389)
        v_1391 = (v_1355 + v_1390)
        v_1392 = self.pnnx_unique_383(v_1324)
        v_1393 = self.pnnx_unique_384(v_1324)
        v_1394 = self.pnnx_unique_385(v_1324)
        v_1395 = v_1392.view(1, 72, 120, 128)
        v_1396 = v_1393.view(1, 72, 120, 128)
        v_1397 = v_1394.view(1, 72, 120, 128)
        v_1398 = torch.permute(input=v_1395, dims=(0,3,1,2))
        v_1399 = model.gmflow.utils.split_feature(v_1398)
        v_1400 = torch.permute(input=v_1396, dims=(0,3,1,2))
        v_1401 = model.gmflow.utils.split_feature(v_1400)
        v_1402 = torch.permute(input=v_1397, dims=(0,3,1,2))
        v_1403 = model.gmflow.utils.split_feature(v_1402)
        v_1404 = torch.permute(input=v_1401, dims=(0,1,3,4,2))
        v_1405 = v_1404.view(1, 64, -1, 128)
        v_1406 = torch.permute(input=v_1399, dims=(0,1,3,4,2))
        v_1407 = v_1406.view(1, 64, -1, 128)
        v_1408 = torch.permute(input=v_1405, dims=(0,1,3,2))
        v_1409 = torch.matmul(input=v_1407, other=v_1408)
        v_1410 = (v_1409 / 11.313708)
        v_1411 = F.softmax(input=v_1410, dim=-1)
        v_1412 = torch.permute(input=v_1403, dims=(0,1,3,4,2))
        v_1413 = v_1412.view(1, 64, -1, 128)
        v_1414 = torch.matmul(input=v_1411, other=v_1413)
        v_1415 = v_1414.view(1, 64, 9, 15, 128)
        v_1416 = torch.permute(input=v_1415, dims=(0,1,4,2,3))
        v_1417 = model.gmflow.utils.merge_splits(v_1416)
        v_1418 = torch.permute(input=v_1417, dims=(0,2,3,1))
        v_1419 = v_1418.view(1, -1, 128)
        v_1420 = self.pnnx_unique_390(v_1419)
        v_1421 = self.pnnx_unique_391(v_1420)
        v_1422 = (v_1324 + v_1421)
        v_1423 = self.pnnx_unique_392(v_1422)
        v_1424 = self.pnnx_unique_393(v_1391)
        v_1425 = self.pnnx_unique_394(v_1391)
        v_1426 = v_1423.view(1, 72, 120, 128)
        v_1427 = v_1424.view(1, 72, 120, 128)
        v_1428 = v_1425.view(1, 72, 120, 128)
        v_1429 = torch.permute(input=v_1426, dims=(0,3,1,2))
        v_1430 = model.gmflow.utils.split_feature(v_1429)
        v_1431 = torch.permute(input=v_1427, dims=(0,3,1,2))
        v_1432 = model.gmflow.utils.split_feature(v_1431)
        v_1433 = torch.permute(input=v_1428, dims=(0,3,1,2))
        v_1434 = model.gmflow.utils.split_feature(v_1433)
        v_1435 = torch.permute(input=v_1432, dims=(0,1,3,4,2))
        v_1436 = v_1435.view(1, 64, -1, 128)
        v_1437 = torch.permute(input=v_1430, dims=(0,1,3,4,2))
        v_1438 = v_1437.view(1, 64, -1, 128)
        v_1439 = torch.permute(input=v_1436, dims=(0,1,3,2))
        v_1440 = torch.matmul(input=v_1438, other=v_1439)
        v_1441 = (v_1440 / 11.313708)
        v_1442 = F.softmax(input=v_1441, dim=-1)
        v_1443 = torch.permute(input=v_1434, dims=(0,1,3,4,2))
        v_1444 = v_1443.view(1, 64, -1, 128)
        v_1445 = torch.matmul(input=v_1442, other=v_1444)
        v_1446 = v_1445.view(1, 64, 9, 15, 128)
        v_1447 = torch.permute(input=v_1446, dims=(0,1,4,2,3))
        v_1448 = model.gmflow.utils.merge_splits(v_1447)
        v_1449 = torch.permute(input=v_1448, dims=(0,2,3,1))
        v_1450 = v_1449.view(1, -1, 128)
        v_1451 = self.pnnx_unique_399(v_1450)
        v_1452 = self.pnnx_unique_400(v_1451)
        v_1453 = torch.cat((v_1422, v_1452), dim=-1)
        v_1454 = self.pnnx_unique_401(v_1453)
        v_1455 = self.pnnx_unique_402(v_1454)
        v_1456 = self.pnnx_unique_403(v_1455)
        v_1457 = self.pnnx_unique_404(v_1456)
        v_1458 = (v_1422 + v_1457)
        v_1459 = self.pnnx_unique_405(v_1391)
        v_1460 = self.pnnx_unique_406(v_1391)
        v_1461 = self.pnnx_unique_407(v_1391)
        v_1462 = v_1459.view(1, 72, 120, 128)
        v_1463 = v_1460.view(1, 72, 120, 128)
        v_1464 = v_1461.view(1, 72, 120, 128)
        v_1465 = torch.permute(input=v_1462, dims=(0,3,1,2))
        v_1466 = model.gmflow.utils.split_feature(v_1465)
        v_1467 = torch.permute(input=v_1463, dims=(0,3,1,2))
        v_1468 = model.gmflow.utils.split_feature(v_1467)
        v_1469 = torch.permute(input=v_1464, dims=(0,3,1,2))
        v_1470 = model.gmflow.utils.split_feature(v_1469)
        v_1471 = torch.permute(input=v_1468, dims=(0,1,3,4,2))
        v_1472 = v_1471.view(1, 64, -1, 128)
        v_1473 = torch.permute(input=v_1466, dims=(0,1,3,4,2))
        v_1474 = v_1473.view(1, 64, -1, 128)
        v_1475 = torch.permute(input=v_1472, dims=(0,1,3,2))
        v_1476 = torch.matmul(input=v_1474, other=v_1475)
        v_1477 = (v_1476 / 11.313708)
        v_1478 = F.softmax(input=v_1477, dim=-1)
        v_1479 = torch.permute(input=v_1470, dims=(0,1,3,4,2))
        v_1480 = v_1479.view(1, 64, -1, 128)
        v_1481 = torch.matmul(input=v_1478, other=v_1480)
        v_1482 = v_1481.view(1, 64, 9, 15, 128)
        v_1483 = torch.permute(input=v_1482, dims=(0,1,4,2,3))
        v_1484 = model.gmflow.utils.merge_splits(v_1483)
        v_1485 = torch.permute(input=v_1484, dims=(0,2,3,1))
        v_1486 = v_1485.view(1, -1, 128)
        v_1487 = self.pnnx_unique_412(v_1486)
        v_1488 = self.pnnx_unique_413(v_1487)
        v_1489 = (v_1391 + v_1488)
        v_1490 = self.pnnx_unique_414(v_1489)
        v_1491 = self.pnnx_unique_415(v_1324)
        v_1492 = self.pnnx_unique_416(v_1324)
        v_1493 = v_1490.view(1, 72, 120, 128)
        v_1494 = v_1491.view(1, 72, 120, 128)
        v_1495 = v_1492.view(1, 72, 120, 128)
        v_1496 = torch.permute(input=v_1493, dims=(0,3,1,2))
        v_1497 = model.gmflow.utils.split_feature(v_1496)
        v_1498 = torch.permute(input=v_1494, dims=(0,3,1,2))
        v_1499 = model.gmflow.utils.split_feature(v_1498)
        v_1500 = torch.permute(input=v_1495, dims=(0,3,1,2))
        v_1501 = model.gmflow.utils.split_feature(v_1500)
        v_1502 = torch.permute(input=v_1499, dims=(0,1,3,4,2))
        v_1503 = v_1502.view(1, 64, -1, 128)
        v_1504 = torch.permute(input=v_1497, dims=(0,1,3,4,2))
        v_1505 = v_1504.view(1, 64, -1, 128)
        v_1506 = torch.permute(input=v_1503, dims=(0,1,3,2))
        v_1507 = torch.matmul(input=v_1505, other=v_1506)
        v_1508 = (v_1507 / 11.313708)
        v_1509 = F.softmax(input=v_1508, dim=-1)
        v_1510 = torch.permute(input=v_1501, dims=(0,1,3,4,2))
        v_1511 = v_1510.view(1, 64, -1, 128)
        v_1512 = torch.matmul(input=v_1509, other=v_1511)
        v_1513 = v_1512.view(1, 64, 9, 15, 128)
        v_1514 = torch.permute(input=v_1513, dims=(0,1,4,2,3))
        v_1515 = model.gmflow.utils.merge_splits(v_1514)
        v_1516 = torch.permute(input=v_1515, dims=(0,2,3,1))
        v_1517 = v_1516.view(1, -1, 128)
        v_1518 = self.pnnx_unique_421(v_1517)
        v_1519 = self.pnnx_unique_422(v_1518)
        v_1520 = torch.cat((v_1489, v_1519), dim=-1)
        v_1521 = self.pnnx_unique_423(v_1520)
        v_1522 = self.pnnx_unique_424(v_1521)
        v_1523 = self.pnnx_unique_425(v_1522)
        v_1524 = self.pnnx_unique_426(v_1523)
        v_1525 = (v_1489 + v_1524)
        v_1526 = self.pnnx_unique_427(v_1458)
        v_1527 = self.pnnx_unique_428(v_1458)
        v_1528 = self.pnnx_unique_429(v_1458)
        v_1529 = v_1526.view(1, 72, 120, 128)
        v_1530 = v_1527.view(1, 72, 120, 128)
        v_1531 = v_1528.view(1, 72, 120, 128)
        v_1532 = torch.permute(input=v_1529, dims=(0,3,1,2))
        v_1533 = model.gmflow.utils.split_feature(v_1532)
        v_1534 = torch.permute(input=v_1530, dims=(0,3,1,2))
        v_1535 = model.gmflow.utils.split_feature(v_1534)
        v_1536 = torch.permute(input=v_1531, dims=(0,3,1,2))
        v_1537 = model.gmflow.utils.split_feature(v_1536)
        v_1538 = torch.permute(input=v_1535, dims=(0,1,3,4,2))
        v_1539 = v_1538.view(1, 64, -1, 128)
        v_1540 = torch.permute(input=v_1533, dims=(0,1,3,4,2))
        v_1541 = v_1540.view(1, 64, -1, 128)
        v_1542 = torch.permute(input=v_1539, dims=(0,1,3,2))
        v_1543 = torch.matmul(input=v_1541, other=v_1542)
        v_1544 = (v_1543 / 11.313708)
        v_1545 = F.softmax(input=v_1544, dim=-1)
        v_1546 = torch.permute(input=v_1537, dims=(0,1,3,4,2))
        v_1547 = v_1546.view(1, 64, -1, 128)
        v_1548 = torch.matmul(input=v_1545, other=v_1547)
        v_1549 = v_1548.view(1, 64, 9, 15, 128)
        v_1550 = torch.permute(input=v_1549, dims=(0,1,4,2,3))
        v_1551 = model.gmflow.utils.merge_splits(v_1550)
        v_1552 = torch.permute(input=v_1551, dims=(0,2,3,1))
        v_1553 = v_1552.view(1, -1, 128)
        v_1554 = self.pnnx_unique_434(v_1553)
        v_1555 = self.pnnx_unique_435(v_1554)
        v_1556 = (v_1458 + v_1555)
        v_1557 = self.pnnx_unique_436(v_1556)
        v_1558 = self.pnnx_unique_437(v_1525)
        v_1559 = self.pnnx_unique_438(v_1525)
        v_1560 = v_1557.view(1, 72, 120, 128)
        v_1561 = v_1558.view(1, 72, 120, 128)
        v_1562 = v_1559.view(1, 72, 120, 128)
        v_1563 = torch.permute(input=v_1560, dims=(0,3,1,2))
        v_1564 = model.gmflow.utils.split_feature(v_1563)
        v_1565 = torch.permute(input=v_1561, dims=(0,3,1,2))
        v_1566 = model.gmflow.utils.split_feature(v_1565)
        v_1567 = torch.permute(input=v_1562, dims=(0,3,1,2))
        v_1568 = model.gmflow.utils.split_feature(v_1567)
        v_1569 = torch.permute(input=v_1566, dims=(0,1,3,4,2))
        v_1570 = v_1569.view(1, 64, -1, 128)
        v_1571 = torch.permute(input=v_1564, dims=(0,1,3,4,2))
        v_1572 = v_1571.view(1, 64, -1, 128)
        v_1573 = torch.permute(input=v_1570, dims=(0,1,3,2))
        v_1574 = torch.matmul(input=v_1572, other=v_1573)
        v_1575 = (v_1574 / 11.313708)
        v_1576 = F.softmax(input=v_1575, dim=-1)
        v_1577 = torch.permute(input=v_1568, dims=(0,1,3,4,2))
        v_1578 = v_1577.view(1, 64, -1, 128)
        v_1579 = torch.matmul(input=v_1576, other=v_1578)
        v_1580 = v_1579.view(1, 64, 9, 15, 128)
        v_1581 = torch.permute(input=v_1580, dims=(0,1,4,2,3))
        v_1582 = model.gmflow.utils.merge_splits(v_1581)
        v_1583 = torch.permute(input=v_1582, dims=(0,2,3,1))
        v_1584 = v_1583.view(1, -1, 128)
        v_1585 = self.pnnx_unique_443(v_1584)
        v_1586 = self.pnnx_unique_444(v_1585)
        v_1587 = torch.cat((v_1556, v_1586), dim=-1)
        v_1588 = self.pnnx_unique_445(v_1587)
        v_1589 = self.pnnx_unique_446(v_1588)
        v_1590 = self.pnnx_unique_447(v_1589)
        v_1591 = self.pnnx_unique_448(v_1590)
        v_1592 = (v_1556 + v_1591)
        v_1593 = self.pnnx_unique_449(v_1525)
        v_1594 = self.pnnx_unique_450(v_1525)
        v_1595 = self.pnnx_unique_451(v_1525)
        v_1596 = v_1593.view(1, 72, 120, 128)
        v_1597 = v_1594.view(1, 72, 120, 128)
        v_1598 = v_1595.view(1, 72, 120, 128)
        v_1599 = torch.permute(input=v_1596, dims=(0,3,1,2))
        v_1600 = model.gmflow.utils.split_feature(v_1599)
        v_1601 = torch.permute(input=v_1597, dims=(0,3,1,2))
        v_1602 = model.gmflow.utils.split_feature(v_1601)
        v_1603 = torch.permute(input=v_1598, dims=(0,3,1,2))
        v_1604 = model.gmflow.utils.split_feature(v_1603)
        v_1605 = torch.permute(input=v_1602, dims=(0,1,3,4,2))
        v_1606 = v_1605.view(1, 64, -1, 128)
        v_1607 = torch.permute(input=v_1600, dims=(0,1,3,4,2))
        v_1608 = v_1607.view(1, 64, -1, 128)
        v_1609 = torch.permute(input=v_1606, dims=(0,1,3,2))
        v_1610 = torch.matmul(input=v_1608, other=v_1609)
        v_1611 = (v_1610 / 11.313708)
        v_1612 = F.softmax(input=v_1611, dim=-1)
        v_1613 = torch.permute(input=v_1604, dims=(0,1,3,4,2))
        v_1614 = v_1613.view(1, 64, -1, 128)
        v_1615 = torch.matmul(input=v_1612, other=v_1614)
        v_1616 = v_1615.view(1, 64, 9, 15, 128)
        v_1617 = torch.permute(input=v_1616, dims=(0,1,4,2,3))
        v_1618 = model.gmflow.utils.merge_splits(v_1617)
        v_1619 = torch.permute(input=v_1618, dims=(0,2,3,1))
        v_1620 = v_1619.view(1, -1, 128)
        v_1621 = self.pnnx_unique_456(v_1620)
        v_1622 = self.pnnx_unique_457(v_1621)
        v_1623 = (v_1525 + v_1622)
        v_1624 = self.pnnx_unique_458(v_1623)
        v_1625 = self.pnnx_unique_459(v_1458)
        v_1626 = self.pnnx_unique_460(v_1458)
        v_1627 = v_1624.view(1, 72, 120, 128)
        v_1628 = v_1625.view(1, 72, 120, 128)
        v_1629 = v_1626.view(1, 72, 120, 128)
        v_1630 = torch.permute(input=v_1627, dims=(0,3,1,2))
        v_1631 = model.gmflow.utils.split_feature(v_1630)
        v_1632 = torch.permute(input=v_1628, dims=(0,3,1,2))
        v_1633 = model.gmflow.utils.split_feature(v_1632)
        v_1634 = torch.permute(input=v_1629, dims=(0,3,1,2))
        v_1635 = model.gmflow.utils.split_feature(v_1634)
        v_1636 = torch.permute(input=v_1633, dims=(0,1,3,4,2))
        v_1637 = v_1636.view(1, 64, -1, 128)
        v_1638 = torch.permute(input=v_1631, dims=(0,1,3,4,2))
        v_1639 = v_1638.view(1, 64, -1, 128)
        v_1640 = torch.permute(input=v_1637, dims=(0,1,3,2))
        v_1641 = torch.matmul(input=v_1639, other=v_1640)
        v_1642 = (v_1641 / 11.313708)
        v_1643 = F.softmax(input=v_1642, dim=-1)
        v_1644 = torch.permute(input=v_1635, dims=(0,1,3,4,2))
        v_1645 = v_1644.view(1, 64, -1, 128)
        v_1646 = torch.matmul(input=v_1643, other=v_1645)
        v_1647 = v_1646.view(1, 64, 9, 15, 128)
        v_1648 = torch.permute(input=v_1647, dims=(0,1,4,2,3))
        v_1649 = model.gmflow.utils.merge_splits(v_1648)
        v_1650 = torch.permute(input=v_1649, dims=(0,2,3,1))
        v_1651 = v_1650.view(1, -1, 128)
        v_1652 = self.pnnx_unique_465(v_1651)
        v_1653 = self.pnnx_unique_466(v_1652)
        v_1654 = torch.cat((v_1623, v_1653), dim=-1)
        v_1655 = self.pnnx_unique_467(v_1654)
        v_1656 = self.pnnx_unique_468(v_1655)
        v_1657 = self.pnnx_unique_469(v_1656)
        v_1658 = self.pnnx_unique_470(v_1657)
        v_1659 = (v_1623 + v_1658)
        v_1660 = self.pnnx_unique_471(v_1592)
        v_1661 = self.pnnx_unique_472(v_1592)
        v_1662 = self.pnnx_unique_473(v_1592)
        v_1663 = v_1660.view(1, 72, 120, 128)
        v_1664 = v_1661.view(1, 72, 120, 128)
        v_1665 = v_1662.view(1, 72, 120, 128)
        v_1666 = torch.permute(input=v_1663, dims=(0,3,1,2))
        v_1667 = model.gmflow.utils.split_feature(v_1666)
        v_1668 = torch.permute(input=v_1664, dims=(0,3,1,2))
        v_1669 = model.gmflow.utils.split_feature(v_1668)
        v_1670 = torch.permute(input=v_1665, dims=(0,3,1,2))
        v_1671 = model.gmflow.utils.split_feature(v_1670)
        v_1672 = torch.permute(input=v_1669, dims=(0,1,3,4,2))
        v_1673 = v_1672.view(1, 64, -1, 128)
        v_1674 = torch.permute(input=v_1667, dims=(0,1,3,4,2))
        v_1675 = v_1674.view(1, 64, -1, 128)
        v_1676 = torch.permute(input=v_1673, dims=(0,1,3,2))
        v_1677 = torch.matmul(input=v_1675, other=v_1676)
        v_1678 = (v_1677 / 11.313708)
        v_1679 = F.softmax(input=v_1678, dim=-1)
        v_1680 = torch.permute(input=v_1671, dims=(0,1,3,4,2))
        v_1681 = v_1680.view(1, 64, -1, 128)
        v_1682 = torch.matmul(input=v_1679, other=v_1681)
        v_1683 = v_1682.view(1, 64, 9, 15, 128)
        v_1684 = torch.permute(input=v_1683, dims=(0,1,4,2,3))
        v_1685 = model.gmflow.utils.merge_splits(v_1684)
        v_1686 = torch.permute(input=v_1685, dims=(0,2,3,1))
        v_1687 = v_1686.view(1, -1, 128)
        v_1688 = self.pnnx_unique_478(v_1687)
        v_1689 = self.pnnx_unique_479(v_1688)
        v_1690 = (v_1592 + v_1689)
        v_1691 = self.pnnx_unique_480(v_1690)
        v_1692 = self.pnnx_unique_481(v_1659)
        v_1693 = self.pnnx_unique_482(v_1659)
        v_1694 = v_1691.view(1, 72, 120, 128)
        v_1695 = v_1692.view(1, 72, 120, 128)
        v_1696 = v_1693.view(1, 72, 120, 128)
        v_1697 = torch.permute(input=v_1694, dims=(0,3,1,2))
        v_1698 = model.gmflow.utils.split_feature(v_1697)
        v_1699 = torch.permute(input=v_1695, dims=(0,3,1,2))
        v_1700 = model.gmflow.utils.split_feature(v_1699)
        v_1701 = torch.permute(input=v_1696, dims=(0,3,1,2))
        v_1702 = model.gmflow.utils.split_feature(v_1701)
        v_1703 = torch.permute(input=v_1700, dims=(0,1,3,4,2))
        v_1704 = v_1703.view(1, 64, -1, 128)
        v_1705 = torch.permute(input=v_1698, dims=(0,1,3,4,2))
        v_1706 = v_1705.view(1, 64, -1, 128)
        v_1707 = torch.permute(input=v_1704, dims=(0,1,3,2))
        v_1708 = torch.matmul(input=v_1706, other=v_1707)
        v_1709 = (v_1708 / 11.313708)
        v_1710 = F.softmax(input=v_1709, dim=-1)
        v_1711 = torch.permute(input=v_1702, dims=(0,1,3,4,2))
        v_1712 = v_1711.view(1, 64, -1, 128)
        v_1713 = torch.matmul(input=v_1710, other=v_1712)
        v_1714 = v_1713.view(1, 64, 9, 15, 128)
        v_1715 = torch.permute(input=v_1714, dims=(0,1,4,2,3))
        v_1716 = model.gmflow.utils.merge_splits(v_1715)
        v_1717 = torch.permute(input=v_1716, dims=(0,2,3,1))
        v_1718 = v_1717.view(1, -1, 128)
        v_1719 = self.pnnx_unique_487(v_1718)
        v_1720 = self.pnnx_unique_488(v_1719)
        v_1721 = torch.cat((v_1690, v_1720), dim=-1)
        v_1722 = self.pnnx_unique_489(v_1721)
        v_1723 = self.pnnx_unique_490(v_1722)
        v_1724 = self.pnnx_unique_491(v_1723)
        v_1725 = self.pnnx_unique_492(v_1724)
        v_1726 = (v_1690 + v_1725)
        v_1727 = self.pnnx_unique_493(v_1659)
        v_1728 = self.pnnx_unique_494(v_1659)
        v_1729 = self.pnnx_unique_495(v_1659)
        v_1730 = v_1727.view(1, 72, 120, 128)
        v_1731 = v_1728.view(1, 72, 120, 128)
        v_1732 = v_1729.view(1, 72, 120, 128)
        v_1733 = torch.permute(input=v_1730, dims=(0,3,1,2))
        v_1734 = model.gmflow.utils.split_feature(v_1733)
        v_1735 = torch.permute(input=v_1731, dims=(0,3,1,2))
        v_1736 = model.gmflow.utils.split_feature(v_1735)
        v_1737 = torch.permute(input=v_1732, dims=(0,3,1,2))
        v_1738 = model.gmflow.utils.split_feature(v_1737)
        v_1739 = torch.permute(input=v_1736, dims=(0,1,3,4,2))
        v_1740 = v_1739.view(1, 64, -1, 128)
        v_1741 = torch.permute(input=v_1734, dims=(0,1,3,4,2))
        v_1742 = v_1741.view(1, 64, -1, 128)
        v_1743 = torch.permute(input=v_1740, dims=(0,1,3,2))
        v_1744 = torch.matmul(input=v_1742, other=v_1743)
        v_1745 = (v_1744 / 11.313708)
        v_1746 = F.softmax(input=v_1745, dim=-1)
        v_1747 = torch.permute(input=v_1738, dims=(0,1,3,4,2))
        v_1748 = v_1747.view(1, 64, -1, 128)
        v_1749 = torch.matmul(input=v_1746, other=v_1748)
        v_1750 = v_1749.view(1, 64, 9, 15, 128)
        v_1751 = torch.permute(input=v_1750, dims=(0,1,4,2,3))
        v_1752 = model.gmflow.utils.merge_splits(v_1751)
        v_1753 = torch.permute(input=v_1752, dims=(0,2,3,1))
        v_1754 = v_1753.view(1, -1, 128)
        v_1755 = self.pnnx_unique_500(v_1754)
        v_1756 = self.pnnx_unique_501(v_1755)
        v_1757 = (v_1659 + v_1756)
        v_1758 = self.pnnx_unique_502(v_1757)
        v_1759 = self.pnnx_unique_503(v_1592)
        v_1760 = self.pnnx_unique_504(v_1592)
        v_1761 = v_1758.view(1, 72, 120, 128)
        v_1762 = v_1759.view(1, 72, 120, 128)
        v_1763 = v_1760.view(1, 72, 120, 128)
        v_1764 = torch.permute(input=v_1761, dims=(0,3,1,2))
        v_1765 = model.gmflow.utils.split_feature(v_1764)
        v_1766 = torch.permute(input=v_1762, dims=(0,3,1,2))
        v_1767 = model.gmflow.utils.split_feature(v_1766)
        v_1768 = torch.permute(input=v_1763, dims=(0,3,1,2))
        v_1769 = model.gmflow.utils.split_feature(v_1768)
        v_1770 = torch.permute(input=v_1767, dims=(0,1,3,4,2))
        v_1771 = v_1770.view(1, 64, -1, 128)
        v_1772 = torch.permute(input=v_1765, dims=(0,1,3,4,2))
        v_1773 = v_1772.view(1, 64, -1, 128)
        v_1774 = torch.permute(input=v_1771, dims=(0,1,3,2))
        v_1775 = torch.matmul(input=v_1773, other=v_1774)
        v_1776 = (v_1775 / 11.313708)
        v_1777 = F.softmax(input=v_1776, dim=-1)
        v_1778 = torch.permute(input=v_1769, dims=(0,1,3,4,2))
        v_1779 = v_1778.view(1, 64, -1, 128)
        v_1780 = torch.matmul(input=v_1777, other=v_1779)
        v_1781 = v_1780.view(1, 64, 9, 15, 128)
        v_1782 = torch.permute(input=v_1781, dims=(0,1,4,2,3))
        v_1783 = model.gmflow.utils.merge_splits(v_1782)
        v_1784 = torch.permute(input=v_1783, dims=(0,2,3,1))
        v_1785 = v_1784.view(1, -1, 128)
        v_1786 = self.pnnx_unique_509(v_1785)
        v_1787 = self.pnnx_unique_510(v_1786)
        v_1788 = torch.cat((v_1757, v_1787), dim=-1)
        v_1789 = self.pnnx_unique_511(v_1788)
        v_1790 = self.pnnx_unique_512(v_1789)
        v_1791 = self.pnnx_unique_513(v_1790)
        v_1792 = self.pnnx_unique_514(v_1791)
        v_1793 = (v_1757 + v_1792)
        v_1794 = v_1726.view(1, 72, 120, 128)
        v_1795 = v_1793.view(1, 72, 120, 128)
        v_1796 = torch.permute(input=v_1795, dims=(0,3,1,2))
        v_1797 = v_1796.contiguous(memory_format=torch.contiguous_format)
        v_1798 = torch.permute(input=v_1794, dims=(0,3,1,2))
        v_1799 = v_1798.contiguous(memory_format=torch.contiguous_format)
        v_1800 = self.pnnx_fold_coords_init_1_pnnx_fold_coords_init_1
        v_1801 = self.pnnx_fold_sample_coords_1_pnnx_fold_sample_coords_1
        v_1802 = self.pnnx_fold_grid_1_pnnx_fold_grid_1
        v_1803 = F.grid_sample(input=v_1797, grid=v_1802, align_corners=True, mode='bilinear', padding_mode='zeros')
        v_1804 = torch.permute(input=v_1799, dims=(0,2,3,1))
        v_1805 = v_1804.view(1, 8640, 1, 128)
        v_1806 = torch.permute(input=v_1803, dims=(0,2,1,3))
        v_1807 = torch.matmul(input=v_1805, other=v_1806)
        v_1808 = v_1807.view(1, 8640, -1)
        v_1809 = (v_1808 / 11.313708)
        v_1810 = F.softmax(input=v_1809, dim=-1)
        v_1811 = torch.unsqueeze(input=v_1810, dim=-2)
        v_1812 = torch.matmul(input=v_1811, other=v_1801)
        v_1813 = v_1812.reshape(1, 72, 120, 2)
        v_1814 = torch.permute(input=v_1813, dims=(0,3,1,2))
        v_1815 = (v_965 + (v_1814 - v_1800))
        v_1816 = v_1799.view(1, 128, -1)
        v_1817 = torch.permute(input=v_1816, dims=(0,2,1))
        v_1818 = self.pnnx_unique_515(v_1817)
        v_1819 = self.pnnx_unique_516(v_1817)
        v_1820 = torch.permute(input=v_1819, dims=(0,2,1))
        v_1821 = v_1820.reshape(1, 128, 72, 120)
        v_1822 = F.unfold(input=v_1821, dilation=(1,1), kernel_size=(3,3), padding=(1,1), stride=(1,1))
        v_1823 = v_1822.view(1, 128, 9, 72, 120)
        v_1824 = F.unfold(input=v_1815, dilation=(1,1), kernel_size=(3,3), padding=(1,1), stride=(1,1))
        v_1825 = v_1824.view(1, 2, 9, 72, 120)
        v_1826 = torch.permute(input=v_1823, dims=(0,3,4,1,2))
        v_1827 = v_1826.reshape(1, 8640, 128, 9)
        v_1828 = v_1818.reshape(1, 8640, 1, 128)
        v_1829 = torch.matmul(input=v_1828, other=v_1827)
        v_1830 = (v_1829 / 11.313708)
        v_1831 = F.softmax(input=v_1830, dim=-1)
        v_1832 = torch.permute(input=v_1825, dims=(0,3,4,2,1))
        v_1833 = v_1832.reshape(1, 8640, 9, 2)
        v_1834 = torch.matmul(input=v_1831, other=v_1833)
        v_1835 = v_1834.view(1, 72, 120, 2)
        v_1836 = torch.permute(input=v_1835, dims=(0,3,1,2))
        v_1837 = v_1836.contiguous(memory_format=torch.contiguous_format)
        v_1838 = torch.cat((v_1837, v_1799), dim=1)
        v_1839 = self.upsampler_0(v_1838)
        v_1840 = self.upsampler_1(v_1839)
        v_1841 = self.upsampler_2(v_1840)
        v_1842 = v_1841.view(1, 1, 9, -1)
        v_1843 = F.softmax(input=v_1842, dim=2)
        v_1844 = v_1843.repeat(1, 2, 1, 1)
        v_1845 = (v_1837 * 4)
        v_1846 = F.unfold(input=v_1845, dilation=(1,1), kernel_size=(3,3), padding=(1,1), stride=(1,1))
        v_1847 = v_1846.view(1, 18, 1, 8640)
        v_1848 = v_1847.repeat(1, 1, 16, 1)
        v_1849 = v_1848.view(1, 18, 16, 72, 120)
        v_1850 = v_1844.view(1, 18, 16, 72, 120)
        v_1851 = (v_1850 * v_1849)
        v_1852 = v_1851.view(1, 2, 9, -1)
        v_1853 = torch.sum(input=v_1852, dim=(2,), keepdim=False)
        v_1854 = v_1853.view(1, 2, 16, 8640)
        v_1855 = model.gmflow.utils.convex_upsampling(v_1837, v_1854)
        return v_1855

def export_torchscript():
    net = Model()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 288, 480, dtype=torch.float)
    v_1 = torch.rand(1, 3, 288, 480, dtype=torch.float)

    mod = torch.jit.trace(net, (v_0, v_1))
    mod.save("D:/60-fps-Project/VFI/GMFSS2NCNN/flownet_288_pnnx.py.pt")

def export_onnx():
    net = Model()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 288, 480, dtype=torch.float)
    v_1 = torch.rand(1, 3, 288, 480, dtype=torch.float)

    torch.onnx._export(net, (v_0, v_1), "D:/60-fps-Project/VFI/GMFSS2NCNN/flownet_288_pnnx.py.onnx", export_params=True, operator_export_type=torch.onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK, opset_version=13, input_names=['in0', 'in1'], output_names=['out0'])

def test_inference():
    net = Model()
    net.eval()

    torch.manual_seed(0)
    v_0 = torch.rand(1, 3, 288, 480, dtype=torch.float)
    v_1 = torch.rand(1, 3, 288, 480, dtype=torch.float)

    return net(v_0, v_1)
