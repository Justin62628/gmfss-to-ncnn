{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Check GMF integrity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start = time.time()\n",
    "assert os.system(\"python inference.py\") == 0\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read check.png and ref.png and compare them with np\n",
    "out = cv2.imread(\"check.png\")\n",
    "ref = cv2.imread(\"ref.png\")\n",
    "np.allclose(out, ref, atol=1, equal_nan=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmf_ncnn_out = cv2.imread(r\"D:\\Program\\VSsource\\research\\gmfss-ncnn-vulkan-demo\\images\\out.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gen pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28388/19489622.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"flownet_288.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"flownet_288.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"python gen_flow_pt.py\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pnnx flownet_288.pt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"flownet_288.pt\"):\n",
    "    os.remove(\"flownet_288.pt\")\n",
    "assert os.system(\"python gen_flow_pt.py\") == 0\n",
    "os.system(\"pnnx flownet_288.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "output = np.load(\"output.npy\")\n",
    "ref = np.load(\"ref_output.npy\")\n",
    "np.allclose(output, ref, atol=1, equal_nan=True)\n",
    "\n",
    "# import torchvision.models as models\n",
    "# models.swin_t()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    ".\\pnnx.exe D:/60-fps-Project/VFI/GMFSS2NCNN/flownet_288.pt inputshape=[1,3,288,480]f32,[1,3,288,480]f32 device=cpu moduleop=model.gmflow.utils.split_feature,model.gmflow.utils.merge_splits,model.gmflow.utils.convex_upsampling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Clean pnnx.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"flownet_288_pnnx.py\", 'r', encoding='utf-8') as r:\n",
    "    content = r.read()\n",
    "content = content.replace(\"\", \"\")\n",
    "with open(\"flownet_288_pnnx.py\", 'w', encoding='utf-8') as w:\n",
    "    w.write(content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit NCNN Param\n",
    "\n",
    "nn\\.InstanceNorm2d(\\s+)(.*?)(\\s+)([\\d+\\s]+)\n",
    "InstanceNorm$1$2$3$4 2=0\n",
    "\n",
    "after:\n",
    "```python\n",
    "v_964 = F.upsample(input=v_963, align_corners=True, mode='bilinear', scale_factor=(2.000000,2.000000))\n",
    "v_965 = (v_964 * 2)\n",
    "```\n",
    "all split, merge, s=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, re\n",
    "param_path = \"flownet_288.ncnn.param\"\n",
    "param_bak_path = \"flownet_288.ncnn_bak.param\"\n",
    "if os.path.exists(param_bak_path):\n",
    "    os.remove(param_bak_path)\n",
    "shutil.copy(param_path, param_bak_path)\n",
    "content = \"\"\n",
    "is_s_8 = False\n",
    "with open(param_bak_path, 'r', encoding='utf-8') as r:\n",
    "    for l in r.readlines():\n",
    "        if \"Interp\" in l:\n",
    "            is_s_8 = True\n",
    "        if re.search(\"nn.InstanceNorm2d\", l, re.I):\n",
    "                l = l.replace(\"nn.InstanceNorm2d\", \"InstanceNorm\")\n",
    "                l = f\"{l.strip()} 2=0\\n\"\n",
    "        if is_s_8:\n",
    "            if re.search(\"split_feature|merge_splits\", l, re.I):\n",
    "                l = f\"{l.strip()} 0=8\\n\"\n",
    "        if re.search(\"convex_upsampling\", l, re.I):\n",
    "            l = f\"{l.strip()} 0=4\\n\"\n",
    "        content += l\n",
    "\n",
    "with open(param_path, 'w', encoding='utf-8') as w:\n",
    "    w.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140530\n"
     ]
    }
   ],
   "source": [
    "print(len(content))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare for Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "torch_output_mat = \"debug0_in0_padded.txt\"\n",
    "ncnn_output_mat = \"out_ncnn.txt\"\n",
    "\n",
    "class PrintData:\n",
    "    def __init__(self, r) -> None:\n",
    "        shape_info = r.readline()  # shape 960 540 1 2\n",
    "        shape_info = re.findall(r\"shape (\\d+) (\\d+) (\\d+) (\\d+)\", shape_info)[0]\n",
    "        self.w, self.h, self.d, self.c = map(int, shape_info)\n",
    "        data = r.readline().split(' ')[:-1]\n",
    "        self.data = np.array(data).reshape(self.c, self.d, self.h, self.w).astype(np.float32)\n",
    "\n",
    "with open(torch_output_mat, 'r', encoding='utf-8') as r:\n",
    "    torch_output = PrintData(r)\n",
    "# with open(ncnn_output_mat, 'r', encoding='utf-8') as r:\n",
    "#     ncnn_output = PrintData(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.427, 1.427, 1.448, 1.449, 1.41 ], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_output.data[0, 0, 0, 0:5]\n",
    "# torch_output.data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "net = models.resnet18(pretrained=False)\n",
    "net = net.eval()\n",
    "\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "# You could try disabling checking when tracing raises error\n",
    "# mod = torch.jit.trace(net, x, check_trace=False)\n",
    "mod = torch.jit.trace(net, x)\n",
    "\n",
    "mod.save(\"resnet18.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
