{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Make PyTorch GT for reference\n",
    "Only Python 3.7 + pytorch11.7+cu117 is tested. Due to limited support of Softsplat op, other Python version may not work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  8.720263004302979\n"
     ]
    }
   ],
   "source": [
    "# make gt inference (540p) check.png\n",
    "# The inference.py is used to generate GMFSS inferenced output as gt for later comparison \n",
    "start = time.time()\n",
    "assert os.system(\"python inference.py\") == 0\n",
    "end = time.time()\n",
    "print(\"Time elapsed: \", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare ref\n",
    "# read check.png and ref.png and compare them with np\n",
    "out = cv2.imread(\"check.png\")\n",
    "ref = cv2.imread(\"ref.png\")\n",
    "np.allclose(out, ref, atol=1, equal_nan=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Traced TorchScript and use PNNX to export ncnn.param, ncnn.bin\n",
    "GMFSS(PG104, or Fortuna) is split into ReuseNet and InferNet. \n",
    "ReuseNet generates GMFlow and feature pyramids.\n",
    "InferNet performs Softsplat operation using output from ReuseNet and generates final output. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "(reusenet)\n",
    ".\\pnnx.exe D:/60-fps-Project/VFI/GMFSS2NCNN/reuse_576.pt inputshape=[1,3,576,960]f32,[1,3,576,960]f32 device=cpu moduleop=model.gmflow.utils.split_feature,model.gmflow.utils.merge_splits,model.gmflow.utils.convex_upsampling                      \n",
    "\n",
    "(infernet, note that pnnx's option customop contradicts with moduleop)\n",
    ".\\pnnx.exe D:/60-fps-Project/VFI/GMFSS2NCNN/infer_576.pt inputshape=[1,3,576,960]f32,[1,3,576,960]f32,[1,1,1,1]f32,[1,2,288,480]f32,[1,2,288,480]f32,[1,2,288,480]f32,[1,64,288,480]f32,[1,128,144,240]f32,[1,192,72,120]f32,[1,64,288,480]f32,[1,128,144,240]f32,[1,192,72,120]f32 device=gpu moduleop=model.gmflow.utils.split_feature,model.gmflow.utils.merge_splits,model.gmflow.utils.convex_upsampling,model customop=D:\\60-fps-Project\\VFI\\GMFSS2NCNN\\softsplat_cuda.pyd       \n",
    "\n",
    "(todo)\n",
    "ncnnoptimize.exe D:\\60-fps-Project\\VFI\\GMFSS2NCNN\\flownet_288.ncnn.param D:\\60-fps-Project\\VFI\\GMFSS2NCNN\\flownet_288.ncnn.bin D:\\60-fps-Project\\VFI\\GMFSS2NCNN\\flownet_288.ncnn.opt.param D:\\60-fps-Project\\VFI\\GMFSS2NCNN\\flownet_288.ncnn.opt.bin 1\n",
    "\n",
    "(no use)\n",
    ".\\pnnx.exe D:/60-fps-Project/VFI/GMFSS2NCNN/flownet_288.pt inputshape=[1,3,288,480]f32,[1,3,288,480]f32 device=cpu moduleop=model.gmflow.utils.split_feature,model.gmflow.utils.merge_splits,model.gmflow.utils.convex_upsampling\n",
    "\n",
    "```\n",
    "\n",
    "copy generated bin to model dir of gmfss-demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (should be useless)\n",
    "# compare pt with ref pt\n",
    "import numpy as np\n",
    "output = np.load(\"output.npy\")\n",
    "ref = np.load(\"ref_output.npy\")\n",
    "np.allclose(output, ref, atol=1, equal_nan=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Clean pnnx.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useless\n",
    "with open(\"flownet_288_pnnx.py\", 'r', encoding='utf-8') as r:\n",
    "    content = r.read()\n",
    "content = content.replace(\"\", \"\")\n",
    "with open(\"flownet_288_pnnx.py\", 'w', encoding='utf-8') as w:\n",
    "    w.write(content)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Edit NCNN Param\n",
    "\n",
    "The following part replaces incorrect node from PNNX (TorchScript -> NCNN Param).\n",
    "You don't need to understand the code(or you can), just execute and it'll generate usable ncnn.param.\n",
    "```python\n",
    "(Don't try to understand notes below):\n",
    "Replace InstanceNorm\n",
    "```\n",
    "nn\\.InstanceNorm2d(\\s+)(.*?)(\\s+)([\\d+\\s]+)\n",
    "InstanceNorm$1$2$3$4 2=0\n",
    "```\n",
    "\n",
    "after:\n",
    "```python\n",
    "v_964 = F.upsample(input=v_963, align_corners=True, mode='bilinear', scale_factor=(2.000000,2.000000))\n",
    "v_965 = (v_964 * 2)\n",
    "```\n",
    "all split, merge, s=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reusenet\n",
    "import os, shutil, re\n",
    "param_path = \"reuse_576.ncnn.param\"\n",
    "param_bak_path = \"reuse_576.ncnn_bak.param\"\n",
    "\n",
    "if os.path.exists(param_bak_path):\n",
    "    os.remove(param_bak_path)\n",
    "shutil.copy(param_path, param_bak_path)\n",
    "content = \"\"\n",
    "is_s_8 = False\n",
    "with open(param_bak_path, 'r', encoding='utf-8') as r:\n",
    "    for l in r.readlines():\n",
    "        if re.search(\"nn.InstanceNorm2d\", l, re.I):\n",
    "                l = l.replace(\"nn.InstanceNorm2d\", \"InstanceNorm\")\n",
    "                l = f\"{l.strip()} 2=0\\n\"\n",
    "        if \"upsample_122\" in l:  # flow01 s=8 part starts\n",
    "            is_s_8 = True\n",
    "        if \"model.gmflow.utils.convex_upsampling convex_upsampling\" in l:  # flow01 over, flow10 s=2 part starts\n",
    "            is_s_8 = False\n",
    "        if \"upsample_123\" in l: # flow10 s=8 part starts\n",
    "            is_s_8 = True\n",
    "        if is_s_8:\n",
    "            if re.search(\"split_feature|merge_splits\", l, re.I):\n",
    "                l = f\"{l.strip()} 0=8\\n\"\n",
    "        if re.search(\"convex_upsampling\", l, re.I):\n",
    "            l = f\"{l.strip()} 0=4\\n\"\n",
    "        content += l\n",
    "\n",
    "with open(param_path, 'w', encoding='utf-8') as w:\n",
    "    w.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infernet\n",
    "import os, shutil, re\n",
    "param_path = \"infer_576.ncnn.param\"\n",
    "param_bak_path = \"infer_576.ncnn_bak.param\"\n",
    "\n",
    "if os.path.exists(param_bak_path):\n",
    "    os.remove(param_bak_path)\n",
    "shutil.copy(param_path, param_bak_path)\n",
    "content = \"\"\n",
    "\n",
    "# edit input tag\n",
    "with open(param_bak_path, 'r', encoding='utf-8') as r:\n",
    "    # img0, img1, timestep, flow01, flow10, metric, feat11, feat12, feat13, feat21, feat22, feat23\n",
    "    content = r.read()\n",
    "    content = content.replace(\" in10\", \" feat22\")\n",
    "    content = content.replace(\" in11\", \" feat23\")\n",
    "    content = content.replace(\" in0\", \" img0\")\n",
    "    content = content.replace(\" in1\", \" img1\")\n",
    "    content = content.replace(\" in2\", \" timestep\")\n",
    "    content = content.replace(\" in3\", \" flow01\")\n",
    "    content = content.replace(\" in4\", \" flow10\")\n",
    "    content = content.replace(\" in5\", \" metric\")\n",
    "    content = content.replace(\" in6\", \" feat11\")\n",
    "    content = content.replace(\" in7\", \" feat12\")\n",
    "    content = content.replace(\" in8\", \" feat13\")\n",
    "    content = content.replace(\" in9\", \" feat21\")\n",
    "    \n",
    "# replace softsplat ir pattern\n",
    "ss_pattern = r\"(softsplat\\.forward.*?2 1 \\d+ \\d+ )\\d+\\nSplit.*?\\nCrop.*?\\nReshape.*?\\nBinaryOp.*?\\nReshape.*?\\nCrop.*?\\nBinaryOp.*?(\\d+) 0=3\\n\"\n",
    "ss_replacement = r\"\\1\\2\\n\"\n",
    "content = re.sub(ss_pattern, ss_replacement, content, flags=re.DOTALL)\n",
    "\n",
    "contents = content.splitlines()\n",
    "contents[1] = f\"{len(contents) - 2} {contents[1].split(' ')[1]}\"\n",
    "content = \"\\n\".join(contents)\n",
    "\n",
    "with open(param_path, 'w', encoding='utf-8') as w:\n",
    "    w.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pnnx_125\n",
      "pnnx_171\n",
      "pnnx_219\n",
      "pnnx_267\n",
      "pnnx_315\n",
      "pnnx_363\n",
      "pnnx_411\n",
      "pnnx_459\n"
     ]
    }
   ],
   "source": [
    "# search to locate debug output\n",
    "with open(\"infer_576.ncnn.param\", 'r', encoding='utf-8') as r:\n",
    "    for l in r.readlines():\n",
    "        if 'softsplat' in l:\n",
    "            print(l.split('        ')[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "softsplat.forward        pnnx_125                 2 1 54 20 63\n",
      "Crop                     slice_223                1 1 32 64 -23310=1,2 -23311=1,0 -23309=1,1\n",
      "Split                    splitncnn_8              1 3 64 65 66 67\n",
      "UnaryOp                  exp_14                   1 1 65 68 0=7\n",
      "Split                    splitncnn_9              1 4 68 69 70 71 72\n",
      "Interp                   upsample_14              1 1 img1 73 0=2 1=5.000000e-01 2=5.000000e-01 6=0\n",
      "Split                    splitncnn_10             1 2 73 74 75\n",
      "BinaryOp                 mul_15                   2 1 75 71 76 0=2\n",
      "Concat                   cat_1                    2 1 76 69 77 0=0\n",
      "softsplat.forward        pnnx_171                 2 1 77 26 86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# below for debug or test, don't need to execute\n",
    "# test ss pattern\n",
    "input_ir = \"\"\"\n",
    "softsplat.forward        pnnx_125                 2 1 54 20 55\n",
    "Split                    splitncnn_7              1 2 55 56 57\n",
    "Crop                     select_0                 1 1 56 58 -23310=1,0 -23311=1,0 -23309=1,-1\n",
    "Reshape                  reshape_204              1 1 58 59 0=480 1=288\n",
    "BinaryOp                 add_12                   1 1 59 60 0=0 1=1 2=1.000000e-05\n",
    "Reshape                  reshape_205              1 1 60 61 0=480 1=288\n",
    "Crop                     slice_222                1 1 57 62 -23310=1,-1 -23311=1,0 -23309=1,0\n",
    "BinaryOp                 div_13                   2 1 62 61 63 0=3\n",
    "Crop                     slice_223                1 1 32 64 -23310=1,2 -23311=1,0 -23309=1,1\n",
    "Split                    splitncnn_8              1 3 64 65 66 67\n",
    "UnaryOp                  exp_14                   1 1 65 68 0=7\n",
    "Split                    splitncnn_9              1 4 68 69 70 71 72\n",
    "Interp                   upsample_14              1 1 img1 73 0=2 1=5.000000e-01 2=5.000000e-01 6=0\n",
    "Split                    splitncnn_10             1 2 73 74 75\n",
    "BinaryOp                 mul_15                   2 1 75 71 76 0=2\n",
    "Concat                   cat_1                    2 1 76 69 77 0=0\n",
    "softsplat.forward        pnnx_171                 2 1 77 26 78\n",
    "Split                    splitncnn_11             1 2 78 79 80\n",
    "Crop                     select_1                 1 1 79 81 -23310=1,0 -23311=1,0 -23309=1,-1\n",
    "Reshape                  reshape_206              1 1 81 82 0=480 1=288\n",
    "BinaryOp                 add_16                   1 1 82 83 0=0 1=1 2=1.000000e-05\n",
    "Reshape                  reshape_207              1 1 83 84 0=480 1=288\n",
    "Crop                     slice_224                1 1 80 85 -23310=1,-1 -23311=1,0 -23309=1,0\n",
    "BinaryOp                 div_17                   2 1 85 84 86 0=3\n",
    "\"\"\"\n",
    "pattern = r\"(softsplat\\.forward.*?2 1 \\d+ \\d+ )\\d+\\nSplit.*?\\nCrop.*?\\nReshape.*?\\nBinaryOp.*?\\nReshape.*?\\nCrop.*?\\nBinaryOp.*?(\\d+) 0=3\\n\"\n",
    "replacement = r\"\\1\\2\\n\"\n",
    "print(re.sub(pattern, replacement, input_ir, flags=re.DOTALL))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Debug) Compare layer output with torchscript output (gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape 480 288 1 65\n",
      "0.314 0.179 0.215 0.203 0.213 0.203 0.205 0.204 0.199 0.191 0.184 0.183 0.184 0.187 0.192 0.195 0.205 0.211 0.213 0.238 0.280 0.338 0.290 0.254 0.211 0.237 0.327 0.398 0.410 0.439 0.401 0.371 0.360 0.398 0.418 0.423 0.419 0.423 0.418 0.401 0.406 0.396 0.398 0.389 0.363 0.390 0.391 0.387 0.405 0.433 0.459 0.473 0.477 0.472 0.465 0.437 0.424 0.441 0.440 0.424 0.413 0.408 0.405 0.410 0.407 0.405 0.396 0.407 0.406 0.400 0.394 0.397 0.409 0.425 0.460 0.442 0.415 0.395 0.408 0.384 0.380 0.381 0.381 0.378 0.376 0.367 0.365 0.367 0.358 0.363 0.368 0.377 0.386 0.342 0.403 0.403 0.373 0.344 0.331 0.330 0.329 0.331 0.333 0.332 0.336 0.340 0.339 0.332 0.325 0.327 0.332 0.337 0.363 0.382 0.372 0.388 0.325 0.312 0.341 0.359 0.358 0.359 0.357 0.358 0.371 0.395 0.402 0.396 0.396 0.422 0.470 0.556 0.496 0.437 0.406 0.356 0.257 0.206 0.131 0.105 0.102 0.108 0.126 0.154 0.178 0.201 0.216 0.214 0.192 0.194 0.268 0.416 0.494 0.330 0.269 0.302 0.338 0.358 0.353 0.360 0.383 0.378 0.445 0.4\n",
      "shape 480 288 1 65\n",
      "0.275 0.296 0.289 0.265 0.237 0.242 0.252 0.257 0.260 0.260 0.264 0.265 0.266 0.268 0.265 0.263 0.261 0.259 0.256 0.265 0.263 0.222 0.158 0.255 0.610 0.692 0.467 0.356 0.342 0.326 0.319 0.294 0.303 0.303 0.305 0.289 0.293 0.300 0.299 0.322 0.294 0.295 0.308 0.310 0.323 0.306 0.305 0.303 0.303 0.316 0.282 0.287 0.384 0.377 0.271 0.273 0.361 0.328 0.298 0.307 0.312 0.311 0.311 0.310 0.313 0.316 0.311 0.309 0.305 0.305 0.308 0.304 0.300 0.309 0.323 0.292 0.299 0.367 0.388 0.376 0.380 0.383 0.393 0.393 0.384 0.388 0.381 0.370 0.372 0.367 0.360 0.366 0.353 0.358 0.350 0.313 0.303 0.308 0.305 0.299 0.303 0.300 0.294 0.300 0.299 0.305 0.300 0.302 0.300 0.295 0.296 0.280 0.316 0.430 0.299 0.308 0.634 0.600 0.421 0.403 0.428 0.440 0.440 0.458 0.493 0.523 0.525 0.524 0.566 0.583 0.589 0.589 0.660 0.853 1.021 1.281 1.148 1.337 1.440 1.735 1.704 1.406 1.118 0.888 0.732 0.664 0.636 0.665 0.790 0.859 0.997 1.073 0.949 0.640 0.601 0.480 0.330 0.294 0.299 0.292 0.326 0.358 0.342 0.2\n"
     ]
    }
   ],
   "source": [
    "# reusenet\n",
    "import re\n",
    "import numpy as np\n",
    "torch_output_mat = r\"D:\\60-fps-Project\\VFI\\GMFSS2NCNN\\debug6_480.288.1.65_ss_in.txt\"\n",
    "ncnn_output_mat = r\"D:\\Program\\VSsource\\research\\gmfss-ncnn-vulkan-demo\\src\\out\\build\\x64-Debug\\debug10_480.288.1.65_pnnx_267_buttom0.txt\"\n",
    "with open(ncnn_output_mat, 'r', encoding='utf-8') as r:\n",
    "    print(r.read()[:1000])\n",
    "with open(torch_output_mat, 'r', encoding='utf-8') as r:\n",
    "    print(r.read()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failing: \n",
      "pad 0\n",
      "failing: \n",
      "pad 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5625211.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "torch_output_mat = r\"D:\\60-fps-Project\\VFI\\GMFSS2NCNN\\debug0_480.288.1.3_I2t.txt\"\n",
    "ncnn_output_mat = r\"D:\\Program\\VSsource\\research\\gmfss-ncnn-vulkan-demo\\src\\out\\build\\x64-Debug\\debug6_480.288.1.3_div_13_top0.txt\"\n",
    "\n",
    "class PrintData:\n",
    "    def __init__(self, r) -> None:\n",
    "        shape_info = r.readline()\n",
    "        shape_info = re.findall(r\"shape (\\d+) (\\d+) (\\d+) (\\d+)\", shape_info)[0]\n",
    "        self.w, self.h, self.d, self.c = map(int, shape_info)\n",
    "        data = r.readline().split(' ')\n",
    "        data_ = list()\n",
    "        for d in data:\n",
    "            try:\n",
    "                data_.append(float(d))\n",
    "            except:\n",
    "                print(f\"failing: {d}\")\n",
    "        self.data = np.array(data_).astype(np.float32)\n",
    "        self.pad = self.w * self.h * self.d * self.c - len(data_)\n",
    "        self.data = np.pad(self.data, ((0, self.pad),), 'constant', constant_values=(0, 0))\n",
    "        self.data = self.data[:self.w * self.h * self.d * self.c].reshape(self.c, self.d, self.h, self.w)\n",
    "        print(f\"pad {self.pad}\")\n",
    "\n",
    "with open(torch_output_mat, 'r', encoding='utf-8') as r:\n",
    "    torch_output = PrintData(r)\n",
    "with open(ncnn_output_mat, 'r', encoding='utf-8') as r:\n",
    "    ncnn_output = PrintData(r)\n",
    "\n",
    "cp_cnt = 10000\n",
    "np.abs(torch_output.data.flatten()[:cp_cnt] - ncnn_output.data.flatten()[:cp_cnt]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.545\n",
      "0.392\n"
     ]
    }
   ],
   "source": [
    "print(torch_output.data[0, 0, 0, 30])\n",
    "print(ncnn_output.data[0, 0, 0, 30])\n",
    "# torch_output.data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Debug) Param Conversion Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.load(\"train_log/flownet.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 0., 2.],\n",
      "        [2., 0., 2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.3333],\n",
       "        [1.3333]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]]).float()\n",
    "t2 = torch.tensor([[3, 2, 1], [6, 5, 4]]).float()\n",
    "t3 = F.l1_loss(t1, t2, reduction='none')\n",
    "print(t3)\n",
    "t3.mean(1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,2,288,480]f32,[1,2,288,480]f32,[1,1,288,480]f32,[1,1,288,480]f32,[1,64,288,480]f32,[1,128,144,240]f32,[1,192,72,120]f32,[1,64,288,480]f32,[1,128,144,240]f32,[1,192,72,120]f32\n",
      "torch.Size([1, 2, 288, 480]),torch.Size([1, 2, 288, 480]),torch.Size([1, 1, 288, 480]),torch.Size([1, 1, 288, 480]),torch.Size([1, 64, 288, 480]),torch.Size([1, 128, 144, 240]),torch.Size([1, 192, 72, 120]),torch.Size([1, 64, 288, 480]),torch.Size([1, 128, 144, 240]),torch.Size([1, 192, 72, 120])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open(\"reuse_output.pkl\", 'rb') as r:\n",
    "    reuse_output = pickle.load(r)\n",
    "print(','.join([f\"[{i.shape[0]},{i.shape[1]},{i.shape[2]},{i.shape[3]}]f32\" for i in reuse_output]))\n",
    "print(','.join([f\"{i.shape}\" for i in reuse_output]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Debug) Op Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpOverloadPacket(op='softsplat.forward')>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.ops.load_library(\"softsplat_cuda.pyd\")\n",
    "torch.ops.softsplat.forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[ 0,  1,  2],\n",
      "           [ 6,  7,  8],\n",
      "           [12, 13, 14]],\n",
      "\n",
      "          [[36, 37, 38],\n",
      "           [42, 43, 44],\n",
      "           [48, 49, 50]]],\n",
      "\n",
      "\n",
      "         [[[ 3,  4,  5],\n",
      "           [ 9, 10, 11],\n",
      "           [15, 16, 17]],\n",
      "\n",
      "          [[39, 40, 41],\n",
      "           [45, 46, 47],\n",
      "           [51, 52, 53]]],\n",
      "\n",
      "\n",
      "         [[[18, 19, 20],\n",
      "           [24, 25, 26],\n",
      "           [30, 31, 32]],\n",
      "\n",
      "          [[54, 55, 56],\n",
      "           [60, 61, 62],\n",
      "           [66, 67, 68]]],\n",
      "\n",
      "\n",
      "         [[[21, 22, 23],\n",
      "           [27, 28, 29],\n",
      "           [33, 34, 35]],\n",
      "\n",
      "          [[57, 58, 59],\n",
      "           [63, 64, 65],\n",
      "           [69, 70, 71]]]]])\n",
      "tensor([[[[ 0,  1,  2,  3,  4,  5],\n",
      "          [ 6,  7,  8,  9, 10, 11],\n",
      "          [12, 13, 14, 15, 16, 17],\n",
      "          [18, 19, 20, 21, 22, 23],\n",
      "          [24, 25, 26, 27, 28, 29],\n",
      "          [30, 31, 32, 33, 34, 35]],\n",
      "\n",
      "         [[36, 37, 38, 39, 40, 41],\n",
      "          [42, 43, 44, 45, 46, 47],\n",
      "          [48, 49, 50, 51, 52, 53],\n",
      "          [54, 55, 56, 57, 58, 59],\n",
      "          [60, 61, 62, 63, 64, 65],\n",
      "          [66, 67, 68, 69, 70, 71]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model.gmflow.utils import split_feature, merge_splits, convex_upsampling\n",
    "# generate (2,2,1,2) tensor\n",
    "feat = torch.arange(0, 72).reshape(1, 2, 6, 6)\n",
    "splits = split_feature()(feat, 2)\n",
    "print(splits)\n",
    "\n",
    "merged = merge_splits()(splits, 2)\n",
    "print(merged)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0,  1,  2,  3,  4,  5],\n",
      "          [ 6,  7,  8,  9, 10, 11],\n",
      "          [12, 13, 14, 15, 16, 17],\n",
      "          [18, 19, 20, 21, 22, 23]],\n",
      "\n",
      "         [[24, 25, 26, 27, 28, 29],\n",
      "          [30, 31, 32, 33, 34, 35],\n",
      "          [36, 37, 38, 39, 40, 41],\n",
      "          [42, 43, 44, 45, 46, 47]]]])\n",
      "tensor([[[[ 0,  6,  1,  7,  2,  8],\n",
      "          [12, 18, 13, 19, 14, 20],\n",
      "          [ 3,  9,  4, 10,  5, 11],\n",
      "          [15, 21, 16, 22, 17, 23]],\n",
      "\n",
      "         [[24, 30, 25, 31, 26, 32],\n",
      "          [36, 42, 37, 43, 38, 44],\n",
      "          [27, 33, 28, 34, 29, 35],\n",
      "          [39, 45, 40, 46, 41, 47]]]])\n"
     ]
    }
   ],
   "source": [
    "flow = torch.arange(0, 12).reshape(1, 2, 2, 3)\n",
    "up_flow = torch.arange(0, 48).reshape(1, 2, 2*2, 2*3)\n",
    "print(up_flow)\n",
    "up_flow = convex_upsampling(2)(flow, up_flow)\n",
    "print(up_flow)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "net = models.resnet18(pretrained=False)\n",
    "net = net.eval()\n",
    "\n",
    "x = torch.rand(1, 3, 224, 224)\n",
    "\n",
    "# You could try disabling checking when tracing raises error\n",
    "# mod = torch.jit.trace(net, x, check_trace=False)\n",
    "mod = torch.jit.trace(net, x)\n",
    "\n",
    "mod.save(\"resnet18.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
